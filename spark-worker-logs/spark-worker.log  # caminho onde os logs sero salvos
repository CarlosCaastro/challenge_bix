24/09/19 06:22:14 INFO Worker: Started daemon with process name: 1@57333b204df7
24/09/19 06:22:14 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:22:14 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:22:14 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:22:15 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:22:15 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:22:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:22:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:22:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:22:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:22:15 INFO Utils: Successfully started service 'sparkWorker' on port 33987.
24/09/19 06:22:15 INFO Worker: Worker decommissioning not enabled.
24/09/19 06:22:15 INFO Worker: Starting Spark worker 172.23.0.5:33987 with 2 cores, 1024.0 MiB RAM
24/09/19 06:22:15 INFO Worker: Running Spark version 3.5.2
24/09/19 06:22:15 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 06:22:15 INFO ResourceUtils: ==============================================================
24/09/19 06:22:15 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 06:22:15 INFO ResourceUtils: ==============================================================
24/09/19 06:22:16 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 06:22:16 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 06:22:16 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://57333b204df7:8081
24/09/19 06:22:16 INFO Worker: Connecting to master spark-master:7077...
24/09/19 06:22:16 INFO TransportClientFactory: Successfully created connection to spark-master/172.23.0.3:7077 after 29 ms (0 ms spent in bootstraps)
24/09/19 06:22:16 INFO Worker: Successfully registered with master spark://172.23.0.3:7077
24/09/19 06:22:55 INFO Worker: Asked to launch executor app-20240919062255-0000/0 for SimpleDataFrame
24/09/19 06:22:56 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:22:56 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:22:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:22:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:22:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:22:56 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33543" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:33543" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919062255-0000" "--worker-url" "spark://Worker@172.23.0.5:33987" "--resourceProfileId" "0"
24/09/19 06:22:57 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 125@57333b204df7
24/09/19 06:22:57 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:22:57 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:22:57 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:22:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:22:58 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:22:58 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:22:58 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:22:58 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:22:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:22:58 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33543 after 73 ms (0 ms spent in bootstraps)
24/09/19 06:22:58 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:22:58 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:22:58 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:22:58 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:22:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:22:59 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33543 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:22:59 INFO DiskBlockManager: Created local directory at /tmp/spark-57980072-ccb8-428d-a8ce-65d151c6b9cf/executor-907ca3f1-53ca-4933-864c-983031dd5c4f/blockmgr-1cfa5b43-eef0-44ff-a7bb-dbb19d2bb01a
24/09/19 06:22:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:22:59 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:33543
24/09/19 06:22:59 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:33987
24/09/19 06:22:59 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:33987 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:22:59 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:33987
24/09/19 06:22:59 INFO ResourceUtils: ==============================================================
24/09/19 06:22:59 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:22:59 INFO ResourceUtils: ==============================================================
24/09/19 06:22:59 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:22:59 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:22:59 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:22:59 INFO Executor: Java version 17.0.12
24/09/19 06:22:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44915.
24/09/19 06:22:59 INFO NettyBlockTransferService: Server created on 172.23.0.5:44915
24/09/19 06:22:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:22:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 44915, None)
24/09/19 06:22:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 44915, None)
24/09/19 06:22:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 44915, None)
24/09/19 06:22:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:22:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@52cc8023 for default.
24/09/19 06:23:00 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:23:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:23:00 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:23:00 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:40041 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:23:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:23:00 INFO TorrentBroadcast: Reading broadcast variable 0 took 123 ms
24/09/19 06:23:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:23:01 INFO CodeGenerator: Code generated in 179.684548 ms
24/09/19 06:23:01 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:23:01 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:23:01 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:23:01 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:23:01 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:23:01 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:23:01 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:23:01 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:23:01 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:23:01 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:23:02 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:23:02 INFO Worker: Asked to kill executor app-20240919062255-0000/0
24/09/19 06:23:02 INFO ExecutorRunner: Runner thread for executor app-20240919062255-0000/0 interrupted
24/09/19 06:23:02 INFO ExecutorRunner: Killing process!
24/09/19 06:23:02 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:23:02 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:23:02 INFO MemoryStore: MemoryStore cleared
24/09/19 06:23:02 INFO BlockManager: BlockManager stopped
24/09/19 06:23:02 INFO Worker: Executor app-20240919062255-0000/0 finished with state KILLED exitStatus 143
24/09/19 06:23:02 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:23:02 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919062255-0000, execId=0)
24/09/19 06:23:02 INFO ExternalShuffleBlockResolver: Application app-20240919062255-0000 removed, cleanupLocalDirs = true
24/09/19 06:23:02 INFO Worker: Cleaning up local directories for application app-20240919062255-0000
24/09/19 06:26:53 INFO Worker: Asked to launch executor app-20240919062653-0001/0 for SimpleDataFrame
24/09/19 06:26:53 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:26:53 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:26:53 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:26:53 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:26:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:26:53 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44183" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:44183" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919062653-0001" "--worker-url" "spark://Worker@172.23.0.5:33987" "--resourceProfileId" "0"
24/09/19 06:26:55 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 249@57333b204df7
24/09/19 06:26:55 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:26:55 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:26:55 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:26:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:26:55 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:26:55 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:26:55 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:26:55 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:26:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:26:56 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:44183 after 56 ms (0 ms spent in bootstraps)
24/09/19 06:26:56 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:26:56 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:26:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:26:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:26:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:26:56 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:44183 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:26:56 INFO DiskBlockManager: Created local directory at /tmp/spark-57980072-ccb8-428d-a8ce-65d151c6b9cf/executor-aca48833-1da4-4631-a6a7-43533ac42bd7/blockmgr-95f1b347-d966-454b-a211-b5ee9a3693c0
24/09/19 06:26:56 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:26:56 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:44183
24/09/19 06:26:56 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:33987
24/09/19 06:26:56 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:33987 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:26:56 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:33987
24/09/19 06:26:56 INFO ResourceUtils: ==============================================================
24/09/19 06:26:56 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:26:56 INFO ResourceUtils: ==============================================================
24/09/19 06:26:56 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:26:56 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:26:56 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:26:56 INFO Executor: Java version 17.0.12
24/09/19 06:26:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41629.
24/09/19 06:26:56 INFO NettyBlockTransferService: Server created on 172.23.0.5:41629
24/09/19 06:26:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:26:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 41629, None)
24/09/19 06:26:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 41629, None)
24/09/19 06:26:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 41629, None)
24/09/19 06:26:56 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:26:56 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 06:26:57 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:26:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:26:57 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:26:57 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:42791 after 1 ms (0 ms spent in bootstraps)
24/09/19 06:26:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:26:57 INFO TorrentBroadcast: Reading broadcast variable 0 took 109 ms
24/09/19 06:26:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:26:58 INFO CodeGenerator: Code generated in 184.399467 ms
24/09/19 06:26:58 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:26:58 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:26:58 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:26:58 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:26:58 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:26:58 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:26:58 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:26:58 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:26:58 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:26:58 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:26:59 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:26:59 INFO Worker: Asked to kill executor app-20240919062653-0001/0
24/09/19 06:26:59 INFO ExecutorRunner: Runner thread for executor app-20240919062653-0001/0 interrupted
24/09/19 06:26:59 INFO ExecutorRunner: Killing process!
24/09/19 06:26:59 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:26:59 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:26:59 INFO Worker: Executor app-20240919062653-0001/0 finished with state KILLED exitStatus 143
24/09/19 06:26:59 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:26:59 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919062653-0001, execId=0)
24/09/19 06:26:59 INFO ExternalShuffleBlockResolver: Application app-20240919062653-0001 removed, cleanupLocalDirs = true
24/09/19 06:26:59 INFO Worker: Cleaning up local directories for application app-20240919062653-0001
24/09/19 06:30:28 INFO Worker: Asked to launch executor app-20240919063028-0002/0 for SimpleDataFrame
24/09/19 06:30:28 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:30:28 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:30:28 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:30:28 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:30:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:30:28 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36771" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:36771" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919063028-0002" "--worker-url" "spark://Worker@172.23.0.5:33987" "--resourceProfileId" "0"
24/09/19 06:30:29 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 362@57333b204df7
24/09/19 06:30:29 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:30:29 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:30:29 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:30:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:30:29 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:30:29 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:30:29 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:30:29 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:30:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:30:30 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:36771 after 61 ms (0 ms spent in bootstraps)
24/09/19 06:30:30 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:30:30 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:30:30 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:30:30 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:30:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:30:30 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:36771 after 4 ms (0 ms spent in bootstraps)
24/09/19 06:30:30 INFO DiskBlockManager: Created local directory at /tmp/spark-57980072-ccb8-428d-a8ce-65d151c6b9cf/executor-58a62a18-8fc5-4c48-92c2-b0385e037f57/blockmgr-6037bac2-ac5a-4ed5-844b-2ca5c12ffc99
24/09/19 06:30:30 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:30:30 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:36771
24/09/19 06:30:30 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:33987
24/09/19 06:30:30 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:33987 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:30:30 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:33987
24/09/19 06:30:30 INFO ResourceUtils: ==============================================================
24/09/19 06:30:30 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:30:30 INFO ResourceUtils: ==============================================================
24/09/19 06:30:30 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:30:30 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:30:30 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:30:30 INFO Executor: Java version 17.0.12
24/09/19 06:30:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38783.
24/09/19 06:30:30 INFO NettyBlockTransferService: Server created on 172.23.0.5:38783
24/09/19 06:30:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:30:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 38783, None)
24/09/19 06:30:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 38783, None)
24/09/19 06:30:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 38783, None)
24/09/19 06:30:30 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:30:30 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e4e04a3 for default.
24/09/19 06:30:31 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:30:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:30:31 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:30:31 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33447 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:30:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:30:31 INFO TorrentBroadcast: Reading broadcast variable 0 took 115 ms
24/09/19 06:30:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:30:32 INFO CodeGenerator: Code generated in 170.892563 ms
24/09/19 06:30:32 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:30:32 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:30:32 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:30:33 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:30:33 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:30:33 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:30:33 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:30:33 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:30:33 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:30:33 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:30:33 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:30:33 INFO Worker: Asked to kill executor app-20240919063028-0002/0
24/09/19 06:30:33 INFO ExecutorRunner: Runner thread for executor app-20240919063028-0002/0 interrupted
24/09/19 06:30:33 INFO ExecutorRunner: Killing process!
24/09/19 06:30:33 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:30:33 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:30:33 INFO Worker: Executor app-20240919063028-0002/0 finished with state KILLED exitStatus 143
24/09/19 06:30:33 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:30:33 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919063028-0002, execId=0)
24/09/19 06:30:33 INFO ExternalShuffleBlockResolver: Application app-20240919063028-0002 removed, cleanupLocalDirs = true
24/09/19 06:30:33 INFO Worker: Cleaning up local directories for application app-20240919063028-0002
24/09/19 06:33:45 INFO Worker: Asked to launch executor app-20240919063345-0003/0 for SimpleDataFrame
24/09/19 06:33:45 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:33:45 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:33:45 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:33:45 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:33:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:33:45 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33393" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:33393" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919063345-0003" "--worker-url" "spark://Worker@172.23.0.5:33987" "--resourceProfileId" "0"
24/09/19 06:33:46 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 812@57333b204df7
24/09/19 06:33:46 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:33:46 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:33:46 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:33:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:33:47 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:33:47 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:33:47 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:33:47 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:33:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:33:47 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33393 after 61 ms (0 ms spent in bootstraps)
24/09/19 06:33:47 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 06:33:47 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 06:33:47 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:33:47 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:33:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 06:33:47 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33393 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:33:47 INFO DiskBlockManager: Created local directory at /tmp/spark-57980072-ccb8-428d-a8ce-65d151c6b9cf/executor-0efedffe-a0c3-4edc-ae15-17adb9bde9dc/blockmgr-63b1208b-4ea7-4c9c-86be-c5eaf2105235
24/09/19 06:33:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:33:48 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:33393
24/09/19 06:33:48 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:33987
24/09/19 06:33:48 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:33987 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:33:48 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:33987
24/09/19 06:33:48 INFO ResourceUtils: ==============================================================
24/09/19 06:33:48 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:33:48 INFO ResourceUtils: ==============================================================
24/09/19 06:33:48 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:33:48 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:33:48 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:33:48 INFO Executor: Java version 17.0.12
24/09/19 06:33:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43275.
24/09/19 06:33:48 INFO NettyBlockTransferService: Server created on 172.23.0.5:43275
24/09/19 06:33:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:33:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 43275, None)
24/09/19 06:33:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 43275, None)
24/09/19 06:33:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 43275, None)
24/09/19 06:33:48 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:33:48 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 06:33:48 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:33:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:33:49 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:33:49 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:39529 after 1 ms (0 ms spent in bootstraps)
24/09/19 06:33:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:33:49 INFO TorrentBroadcast: Reading broadcast variable 0 took 118 ms
24/09/19 06:33:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:33:50 INFO CodeGenerator: Code generated in 168.305021 ms
24/09/19 06:33:50 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:33:50 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:33:50 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:33:50 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:33:50 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:33:50 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:33:50 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:33:50 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:33:50 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:33:50 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:33:50 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:33:50 INFO Worker: Asked to kill executor app-20240919063345-0003/0
24/09/19 06:33:50 INFO ExecutorRunner: Runner thread for executor app-20240919063345-0003/0 interrupted
24/09/19 06:33:50 INFO ExecutorRunner: Killing process!
24/09/19 06:33:50 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:33:50 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:33:51 INFO Worker: Executor app-20240919063345-0003/0 finished with state KILLED exitStatus 143
24/09/19 06:33:51 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:33:51 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919063345-0003, execId=0)
24/09/19 06:33:51 INFO ExternalShuffleBlockResolver: Application app-20240919063345-0003 removed, cleanupLocalDirs = true
24/09/19 06:33:51 INFO Worker: Cleaning up local directories for application app-20240919063345-0003
24/09/19 06:39:33 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 06:39:33 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:39:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-57980072-ccb8-428d-a8ce-65d151c6b9cf
24/09/19 06:43:28 INFO Worker: Started daemon with process name: 1@01340e08e955
24/09/19 06:43:28 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:43:28 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:43:28 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:43:28 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 06:43:28 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 06:43:28 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:43:28 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:43:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 06:43:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:43:29 INFO Utils: Successfully started service 'sparkWorker' on port 42601.
24/09/19 06:43:29 INFO Worker: Worker decommissioning not enabled.
24/09/19 06:43:29 INFO Worker: Starting Spark worker 172.23.0.5:42601 with 2 cores, 1024.0 MiB RAM
24/09/19 06:43:29 INFO Worker: Running Spark version 3.5.2
24/09/19 06:43:29 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 06:43:29 INFO ResourceUtils: ==============================================================
24/09/19 06:43:29 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 06:43:29 INFO ResourceUtils: ==============================================================
24/09/19 06:43:29 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 06:43:29 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 06:43:30 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://01340e08e955:8081
24/09/19 06:43:30 INFO Worker: Connecting to master spark-master:7077...
24/09/19 06:43:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.23.0.2:7077 after 46 ms (0 ms spent in bootstraps)
24/09/19 06:43:30 INFO Worker: Successfully registered with master spark://172.23.0.2:7077
24/09/19 06:45:01 INFO Worker: Asked to launch executor app-20240919064501-0000/0 for SimpleDataFrame
24/09/19 06:45:01 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 06:45:01 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 06:45:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:45:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:45:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 06:45:01 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34129" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:34129" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919064501-0000" "--worker-url" "spark://Worker@172.23.0.5:42601" "--resourceProfileId" "0"
24/09/19 06:45:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 116@01340e08e955
24/09/19 06:45:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:45:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:45:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:45:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:45:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 06:45:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 06:45:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:45:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:45:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 06:45:07 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:34129 after 105 ms (0 ms spent in bootstraps)
24/09/19 06:45:07 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 06:45:07 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 06:45:07 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:45:07 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:45:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 06:45:07 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:34129 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:45:07 INFO DiskBlockManager: Created local directory at /tmp/spark-870c7bc8-cef8-4d93-907f-51f4219273c3/executor-e9b0b7b2-c8b3-4787-bb37-743ab31846f0/blockmgr-f21bade6-c053-47a8-ab10-40a9a4b6342e
24/09/19 06:45:07 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:45:08 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:34129
24/09/19 06:45:08 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:42601
24/09/19 06:45:08 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:42601 after 1 ms (0 ms spent in bootstraps)
24/09/19 06:45:08 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:42601
24/09/19 06:45:08 INFO ResourceUtils: ==============================================================
24/09/19 06:45:08 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:45:08 INFO ResourceUtils: ==============================================================
24/09/19 06:45:08 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:45:08 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:45:08 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:45:08 INFO Executor: Java version 17.0.12
24/09/19 06:45:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39803.
24/09/19 06:45:08 INFO NettyBlockTransferService: Server created on 172.23.0.5:39803
24/09/19 06:45:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:45:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 39803, None)
24/09/19 06:45:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 39803, None)
24/09/19 06:45:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 39803, None)
24/09/19 06:45:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:45:08 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@32184f2c for default.
24/09/19 06:45:08 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:45:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:45:08 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:45:08 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:46495 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:45:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:45:09 INFO TorrentBroadcast: Reading broadcast variable 0 took 171 ms
24/09/19 06:45:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:45:10 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:45:10 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:45:10 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:45:10 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:45:10 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:45:10 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:45:11 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:45:11 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:45:11 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:45:11 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:45:12 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:45:12 INFO Worker: Asked to kill executor app-20240919064501-0000/0
24/09/19 06:45:12 INFO ExecutorRunner: Runner thread for executor app-20240919064501-0000/0 interrupted
24/09/19 06:45:12 INFO ExecutorRunner: Killing process!
24/09/19 06:45:12 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:45:12 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:45:12 INFO Worker: Executor app-20240919064501-0000/0 finished with state KILLED exitStatus 143
24/09/19 06:45:12 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:45:12 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919064501-0000, execId=0)
24/09/19 06:45:12 INFO ExternalShuffleBlockResolver: Application app-20240919064501-0000 removed, cleanupLocalDirs = true
24/09/19 06:45:12 INFO Worker: Cleaning up local directories for application app-20240919064501-0000
24/09/19 06:57:41 INFO Worker: Asked to launch executor app-20240919065741-0001/0 for SimpleDataFrame
24/09/19 06:57:41 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 06:57:41 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 06:57:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:57:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:57:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 06:57:41 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33119" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:33119" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919065741-0001" "--worker-url" "spark://Worker@172.23.0.5:42601" "--resourceProfileId" "0"
24/09/19 06:57:43 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 250@01340e08e955
24/09/19 06:57:43 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:57:43 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:57:43 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:57:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:57:43 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 06:57:43 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 06:57:43 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:57:43 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:57:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 06:57:44 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33119 after 56 ms (0 ms spent in bootstraps)
24/09/19 06:57:44 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 06:57:44 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 06:57:44 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:57:44 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:57:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 06:57:44 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33119 after 3 ms (0 ms spent in bootstraps)
24/09/19 06:57:44 INFO DiskBlockManager: Created local directory at /tmp/spark-870c7bc8-cef8-4d93-907f-51f4219273c3/executor-bc8300bf-271b-446f-beee-5ef39e469749/blockmgr-0a4c96f9-5c55-4671-9140-b612a549b97b
24/09/19 06:57:44 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 06:57:44 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:33119
24/09/19 06:57:44 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:42601
24/09/19 06:57:44 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:42601 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:57:44 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:42601
24/09/19 06:57:44 INFO ResourceUtils: ==============================================================
24/09/19 06:57:44 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 06:57:44 INFO ResourceUtils: ==============================================================
24/09/19 06:57:44 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 06:57:44 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 06:57:44 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 06:57:44 INFO Executor: Java version 17.0.12
24/09/19 06:57:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39687.
24/09/19 06:57:44 INFO NettyBlockTransferService: Server created on 172.23.0.5:39687
24/09/19 06:57:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 06:57:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 39687, None)
24/09/19 06:57:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 39687, None)
24/09/19 06:57:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 39687, None)
24/09/19 06:57:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 06:57:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@b16db59 for default.
24/09/19 06:57:45 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 06:57:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 06:57:45 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 06:57:45 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:36233 after 2 ms (0 ms spent in bootstraps)
24/09/19 06:57:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 06:57:45 INFO TorrentBroadcast: Reading broadcast variable 0 took 114 ms
24/09/19 06:57:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 06:57:46 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:57:46 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 06:57:46 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 06:57:46 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:57:46 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 06:57:46 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 06:57:47 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:57:47 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 06:57:47 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 06:57:47 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "/usr/local/lib/python3.9/runpy.py", line 188, in _run_module_as_main
      mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
    File "/usr/local/lib/python3.9/runpy.py", line 111, in _get_module_details
      __import__(pkg_name)
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "<frozen zipimport>", line 259, in load_module
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
    File "/usr/local/lib/python3.9/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.9
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 06:57:47 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 06:57:47 INFO Worker: Asked to kill executor app-20240919065741-0001/0
24/09/19 06:57:47 INFO ExecutorRunner: Runner thread for executor app-20240919065741-0001/0 interrupted
24/09/19 06:57:47 INFO ExecutorRunner: Killing process!
24/09/19 06:57:47 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 06:57:47 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:57:48 INFO Worker: Executor app-20240919065741-0001/0 finished with state KILLED exitStatus 143
24/09/19 06:57:48 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 06:57:48 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919065741-0001, execId=0)
24/09/19 06:57:48 INFO ExternalShuffleBlockResolver: Application app-20240919065741-0001 removed, cleanupLocalDirs = true
24/09/19 06:57:48 INFO Worker: Cleaning up local directories for application app-20240919065741-0001
24/09/19 06:58:23 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 06:58:23 INFO ShutdownHookManager: Shutdown hook called
24/09/19 06:58:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-870c7bc8-cef8-4d93-907f-51f4219273c3
24/09/19 06:58:50 INFO Worker: Started daemon with process name: 1@c38cafd06531
24/09/19 06:58:50 INFO SignalUtils: Registering signal handler for TERM
24/09/19 06:58:50 INFO SignalUtils: Registering signal handler for HUP
24/09/19 06:58:50 INFO SignalUtils: Registering signal handler for INT
24/09/19 06:58:50 INFO SecurityManager: Changing view acls to: spark
24/09/19 06:58:50 INFO SecurityManager: Changing modify acls to: spark
24/09/19 06:58:50 INFO SecurityManager: Changing view acls groups to: 
24/09/19 06:58:50 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 06:58:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 06:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 06:58:51 INFO Utils: Successfully started service 'sparkWorker' on port 36477.
24/09/19 06:58:51 INFO Worker: Worker decommissioning not enabled.
24/09/19 06:58:51 INFO Worker: Starting Spark worker 172.23.0.5:36477 with 2 cores, 1024.0 MiB RAM
24/09/19 06:58:51 INFO Worker: Running Spark version 3.5.2
24/09/19 06:58:51 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 06:58:51 INFO ResourceUtils: ==============================================================
24/09/19 06:58:51 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 06:58:51 INFO ResourceUtils: ==============================================================
24/09/19 06:58:51 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 06:58:51 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 06:58:51 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://c38cafd06531:8081
24/09/19 06:58:51 INFO Worker: Connecting to master spark-master:7077...
24/09/19 06:58:51 INFO TransportClientFactory: Successfully created connection to spark-master/172.23.0.3:7077 after 28 ms (0 ms spent in bootstraps)
24/09/19 06:58:51 INFO Worker: Successfully registered with master spark://172.23.0.3:7077
24/09/19 07:00:52 INFO Worker: Asked to launch executor app-20240919070052-0000/0 for SimpleDataFrame
24/09/19 07:00:52 INFO SecurityManager: Changing view acls to: spark
24/09/19 07:00:52 INFO SecurityManager: Changing modify acls to: spark
24/09/19 07:00:52 INFO SecurityManager: Changing view acls groups to: 
24/09/19 07:00:52 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 07:00:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/19 07:00:52 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33239" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dd9f7aa6690e:33239" "--executor-id" "0" "--hostname" "172.23.0.5" "--cores" "2" "--app-id" "app-20240919070052-0000" "--worker-url" "spark://Worker@172.23.0.5:36477" "--resourceProfileId" "0"
24/09/19 07:00:54 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 131@c38cafd06531
24/09/19 07:00:54 INFO SignalUtils: Registering signal handler for TERM
24/09/19 07:00:54 INFO SignalUtils: Registering signal handler for HUP
24/09/19 07:00:54 INFO SignalUtils: Registering signal handler for INT
24/09/19 07:00:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 07:00:54 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 07:00:54 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 07:00:54 INFO SecurityManager: Changing view acls groups to: 
24/09/19 07:00:54 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 07:00:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 07:00:55 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33239 after 54 ms (0 ms spent in bootstraps)
24/09/19 07:00:55 INFO SecurityManager: Changing view acls to: spark,airflow
24/09/19 07:00:55 INFO SecurityManager: Changing modify acls to: spark,airflow
24/09/19 07:00:55 INFO SecurityManager: Changing view acls groups to: 
24/09/19 07:00:55 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 07:00:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
24/09/19 07:00:55 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:33239 after 3 ms (0 ms spent in bootstraps)
24/09/19 07:00:55 INFO DiskBlockManager: Created local directory at /tmp/spark-c936fb65-9e7f-4141-93f7-29075931e034/executor-181e3bf4-dd03-4b64-acee-3d6e4ee8a9a8/blockmgr-77e12acd-3f7a-407b-95dd-be4adc93cb12
24/09/19 07:00:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 07:00:55 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dd9f7aa6690e:33239
24/09/19 07:00:55 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.5:36477
24/09/19 07:00:55 INFO TransportClientFactory: Successfully created connection to /172.23.0.5:36477 after 2 ms (0 ms spent in bootstraps)
24/09/19 07:00:55 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.5:36477
24/09/19 07:00:55 INFO ResourceUtils: ==============================================================
24/09/19 07:00:55 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 07:00:55 INFO ResourceUtils: ==============================================================
24/09/19 07:00:55 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 07:00:55 INFO Executor: Starting executor ID 0 on host 172.23.0.5
24/09/19 07:00:55 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 07:00:55 INFO Executor: Java version 17.0.12
24/09/19 07:00:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32839.
24/09/19 07:00:55 INFO NettyBlockTransferService: Server created on 172.23.0.5:32839
24/09/19 07:00:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 07:00:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.5, 32839, None)
24/09/19 07:00:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.5, 32839, None)
24/09/19 07:00:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.5, 32839, None)
24/09/19 07:00:55 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 07:00:55 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 07:00:56 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 07:00:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 07:00:56 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 07:00:56 INFO TransportClientFactory: Successfully created connection to dd9f7aa6690e/172.23.0.4:44253 after 2 ms (0 ms spent in bootstraps)
24/09/19 07:00:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 07:00:56 INFO TorrentBroadcast: Reading broadcast variable 0 took 97 ms
24/09/19 07:00:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 07:00:58 INFO CodeGenerator: Code generated in 410.699918 ms
24/09/19 07:00:58 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 07:00:58 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 07:00:58 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 07:00:58 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 07:00:58 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 07:00:58 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 07:00:58 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 07:00:58 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 07:00:58 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 07:00:58 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/worker.py", line 1100, in main
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 12) than that in driver 3.11, PySpark cannot run with different minor versions.
Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 07:00:58 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 07:00:58 INFO Worker: Asked to kill executor app-20240919070052-0000/0
24/09/19 07:00:58 INFO ExecutorRunner: Runner thread for executor app-20240919070052-0000/0 interrupted
24/09/19 07:00:58 INFO ExecutorRunner: Killing process!
24/09/19 07:00:58 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 07:00:58 INFO ShutdownHookManager: Shutdown hook called
24/09/19 07:00:58 INFO MemoryStore: MemoryStore cleared
24/09/19 07:00:58 INFO BlockManager: BlockManager stopped
24/09/19 07:00:58 INFO Worker: Executor app-20240919070052-0000/0 finished with state KILLED exitStatus 143
24/09/19 07:00:58 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 07:00:58 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919070052-0000, execId=0)
24/09/19 07:00:58 INFO ExternalShuffleBlockResolver: Application app-20240919070052-0000 removed, cleanupLocalDirs = true
24/09/19 07:00:58 INFO Worker: Cleaning up local directories for application app-20240919070052-0000
24/09/19 07:01:26 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 07:01:26 INFO ShutdownHookManager: Shutdown hook called
24/09/19 07:01:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-c936fb65-9e7f-4141-93f7-29075931e034
24/09/19 13:50:49 INFO Worker: Started daemon with process name: 1@1b389e46c326
24/09/19 13:50:50 INFO SignalUtils: Registering signal handler for TERM
24/09/19 13:50:50 INFO SignalUtils: Registering signal handler for HUP
24/09/19 13:50:50 INFO SignalUtils: Registering signal handler for INT
24/09/19 13:50:51 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 13:50:51 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 13:50:51 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:50:51 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:50:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 13:50:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 13:51:01 INFO Utils: Successfully started service 'sparkWorker' on port 36603.
24/09/19 13:51:01 INFO Worker: Worker decommissioning not enabled.
24/09/19 13:51:02 INFO Worker: Starting Spark worker 172.18.0.4:36603 with 2 cores, 1024.0 MiB RAM
24/09/19 13:51:02 INFO Worker: Running Spark version 3.5.2
24/09/19 13:51:02 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 13:51:02 INFO ResourceUtils: ==============================================================
24/09/19 13:51:02 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 13:51:02 INFO ResourceUtils: ==============================================================
24/09/19 13:51:03 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 13:51:04 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 13:51:04 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://1b389e46c326:8081
24/09/19 13:51:04 INFO Worker: Connecting to master spark-master:7077...
24/09/19 13:51:05 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 294 ms (0 ms spent in bootstraps)
24/09/19 13:51:07 INFO Worker: Successfully registered with master spark://172.18.0.3:7077
24/09/19 13:55:51 INFO Worker: Asked to launch executor app-20240919135551-0000/0 for SimpleDataFrame
24/09/19 13:55:51 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 13:55:51 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 13:55:51 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:55:51 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:55:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 13:55:51 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46223" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@253efc7d020f:46223" "--executor-id" "0" "--hostname" "172.18.0.4" "--cores" "2" "--app-id" "app-20240919135551-0000" "--worker-url" "spark://Worker@172.18.0.4:36603" "--resourceProfileId" "0"
24/09/19 13:55:55 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 111@1b389e46c326
24/09/19 13:55:55 INFO SignalUtils: Registering signal handler for TERM
24/09/19 13:55:55 INFO SignalUtils: Registering signal handler for HUP
24/09/19 13:55:55 INFO SignalUtils: Registering signal handler for INT
24/09/19 13:55:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 13:55:56 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 13:55:56 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 13:55:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:55:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:55:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 13:55:56 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:46223 after 81 ms (0 ms spent in bootstraps)
24/09/19 13:55:56 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 13:55:56 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 13:55:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:55:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:55:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 13:55:56 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:46223 after 3 ms (0 ms spent in bootstraps)
24/09/19 13:55:56 INFO DiskBlockManager: Created local directory at /tmp/spark-75eccfa2-0df2-409b-8579-79f6710d9293/executor-010683d5-1c54-4498-85e7-d6593d937725/blockmgr-0f34087d-655b-4ece-ae92-99da218cda7b
24/09/19 13:55:56 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 13:55:57 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@253efc7d020f:46223
24/09/19 13:55:57 INFO WorkerWatcher: Connecting to worker spark://Worker@172.18.0.4:36603
24/09/19 13:55:57 INFO TransportClientFactory: Successfully created connection to /172.18.0.4:36603 after 3 ms (0 ms spent in bootstraps)
24/09/19 13:55:57 INFO WorkerWatcher: Successfully connected to spark://Worker@172.18.0.4:36603
24/09/19 13:55:57 INFO ResourceUtils: ==============================================================
24/09/19 13:55:57 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 13:55:57 INFO ResourceUtils: ==============================================================
24/09/19 13:55:57 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 13:55:57 INFO Executor: Starting executor ID 0 on host 172.18.0.4
24/09/19 13:55:57 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 13:55:57 INFO Executor: Java version 17.0.12
24/09/19 13:55:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41045.
24/09/19 13:55:57 INFO NettyBlockTransferService: Server created on 172.18.0.4:41045
24/09/19 13:55:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 13:55:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.18.0.4, 41045, None)
24/09/19 13:55:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.18.0.4, 41045, None)
24/09/19 13:55:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.18.0.4, 41045, None)
24/09/19 13:55:57 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 13:55:57 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 13:55:58 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 13:55:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 13:55:58 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 13:55:58 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:42323 after 8 ms (0 ms spent in bootstraps)
24/09/19 13:55:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 13:55:58 INFO TorrentBroadcast: Reading broadcast variable 0 took 158 ms
24/09/19 13:55:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 13:56:00 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:00 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 13:56:00 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 13:56:00 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:00 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 13:56:00 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 13:56:00 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:00 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 13:56:00 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 13:56:01 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:01 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 13:56:01 INFO MemoryStore: MemoryStore cleared
24/09/19 13:56:01 INFO BlockManager: BlockManager stopped
24/09/19 13:56:01 INFO ShutdownHookManager: Shutdown hook called
24/09/19 13:56:01 INFO Worker: Asked to kill executor app-20240919135551-0000/0
24/09/19 13:56:01 INFO ExecutorRunner: Runner thread for executor app-20240919135551-0000/0 interrupted
24/09/19 13:56:01 INFO ExecutorRunner: Killing process!
24/09/19 13:56:01 INFO Worker: Asked to launch executor app-20240919135551-0001/0 for SimpleDataFrame
24/09/19 13:56:01 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 13:56:01 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 13:56:01 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 13:56:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:56:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:56:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 13:56:01 INFO Worker: Executor app-20240919135551-0000/0 finished with state KILLED exitStatus 0
24/09/19 13:56:01 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=37667" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@253efc7d020f:37667" "--executor-id" "0" "--hostname" "172.18.0.4" "--cores" "2" "--app-id" "app-20240919135551-0001" "--worker-url" "spark://Worker@172.18.0.4:36603" "--resourceProfileId" "0"
24/09/19 13:56:01 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 13:56:01 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919135551-0000, execId=0)
24/09/19 13:56:01 INFO ExternalShuffleBlockResolver: Application app-20240919135551-0000 removed, cleanupLocalDirs = true
24/09/19 13:56:01 INFO Worker: Cleaning up local directories for application app-20240919135551-0000
24/09/19 13:56:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 197@1b389e46c326
24/09/19 13:56:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 13:56:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 13:56:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 13:56:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 13:56:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 13:56:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 13:56:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:56:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:56:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 13:56:06 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:37667 after 47 ms (0 ms spent in bootstraps)
24/09/19 13:56:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 13:56:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 13:56:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 13:56:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 13:56:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 13:56:06 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:37667 after 1 ms (0 ms spent in bootstraps)
24/09/19 13:56:06 INFO DiskBlockManager: Created local directory at /tmp/spark-75eccfa2-0df2-409b-8579-79f6710d9293/executor-f1c98831-febf-4065-b887-7a5caa885854/blockmgr-39672dcd-01ca-48c9-9f1d-f8a52ad32577
24/09/19 13:56:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 13:56:06 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@253efc7d020f:37667
24/09/19 13:56:06 INFO WorkerWatcher: Connecting to worker spark://Worker@172.18.0.4:36603
24/09/19 13:56:06 INFO TransportClientFactory: Successfully created connection to /172.18.0.4:36603 after 1 ms (0 ms spent in bootstraps)
24/09/19 13:56:06 INFO WorkerWatcher: Successfully connected to spark://Worker@172.18.0.4:36603
24/09/19 13:56:06 INFO ResourceUtils: ==============================================================
24/09/19 13:56:06 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 13:56:06 INFO ResourceUtils: ==============================================================
24/09/19 13:56:06 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 13:56:06 INFO Executor: Starting executor ID 0 on host 172.18.0.4
24/09/19 13:56:06 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 13:56:06 INFO Executor: Java version 17.0.12
24/09/19 13:56:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41949.
24/09/19 13:56:07 INFO NettyBlockTransferService: Server created on 172.18.0.4:41949
24/09/19 13:56:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 13:56:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.18.0.4, 41949, None)
24/09/19 13:56:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.18.0.4, 41949, None)
24/09/19 13:56:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.18.0.4, 41949, None)
24/09/19 13:56:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 13:56:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@b16db59 for default.
24/09/19 13:56:07 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 13:56:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 13:56:07 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 13:56:07 INFO TransportClientFactory: Successfully created connection to 253efc7d020f/172.18.0.5:36273 after 2 ms (0 ms spent in bootstraps)
24/09/19 13:56:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 13:56:07 INFO TorrentBroadcast: Reading broadcast variable 0 took 90 ms
24/09/19 13:56:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 13:56:08 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:08 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 13:56:08 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 13:56:08 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:08 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 13:56:08 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 13:56:08 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:08 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 13:56:08 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 13:56:09 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: 
Error from python worker:
  Traceback (most recent call last):
    File "<frozen runpy>", line 189, in _run_module_as_main
    File "<frozen runpy>", line 112, in _get_module_details
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/__init__.py", line 148, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/__init__.py", line 42, in <module>
    File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/types.py", line 28, in <module>
      
      ^
    File "/usr/local/lib/python3.11/ctypes/__init__.py", line 8, in <module>
      from _ctypes import Union, Structure, Array
  ModuleNotFoundError: No module named '_ctypes'
PYTHONPATH was:
  /opt/bitnami/spark/python/lib/pyspark.zip:/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/bitnami/spark/jars/spark-core_2.12-3.5.2.jar:/usr/local/bin/python3.11
org.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout.
	at org.apache.spark.errors.SparkCoreErrors$.eofExceptionWhileReadPortNumberError(SparkCoreErrors.scala:53)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:246)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 13:56:09 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 13:56:09 INFO Worker: Asked to kill executor app-20240919135551-0001/0
24/09/19 13:56:09 INFO ExecutorRunner: Runner thread for executor app-20240919135551-0001/0 interrupted
24/09/19 13:56:09 INFO ExecutorRunner: Killing process!
24/09/19 13:56:09 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 13:56:09 INFO ShutdownHookManager: Shutdown hook called
24/09/19 13:56:09 INFO Worker: Executor app-20240919135551-0001/0 finished with state KILLED exitStatus 143
24/09/19 13:56:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 13:56:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919135551-0001, execId=0)
24/09/19 13:56:09 INFO ExternalShuffleBlockResolver: Application app-20240919135551-0001 removed, cleanupLocalDirs = true
24/09/19 13:56:09 INFO Worker: Cleaning up local directories for application app-20240919135551-0001
24/09/19 13:58:44 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 13:58:44 INFO ShutdownHookManager: Shutdown hook called
24/09/19 13:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-75eccfa2-0df2-409b-8579-79f6710d9293
24/09/19 14:17:34 INFO Worker: Started daemon with process name: 1@4e13bb9ea7d3
24/09/19 14:17:34 INFO SignalUtils: Registering signal handler for TERM
24/09/19 14:17:34 INFO SignalUtils: Registering signal handler for HUP
24/09/19 14:17:34 INFO SignalUtils: Registering signal handler for INT
24/09/19 14:17:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 14:17:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 14:17:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:17:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:17:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 14:17:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 14:17:34 INFO Utils: Successfully started service 'sparkWorker' on port 45083.
24/09/19 14:17:34 INFO Worker: Worker decommissioning not enabled.
24/09/19 14:17:35 INFO Worker: Starting Spark worker 172.19.0.5:45083 with 2 cores, 1024.0 MiB RAM
24/09/19 14:17:35 INFO Worker: Running Spark version 3.5.2
24/09/19 14:17:35 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 14:17:35 INFO ResourceUtils: ==============================================================
24/09/19 14:17:35 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 14:17:35 INFO ResourceUtils: ==============================================================
24/09/19 14:17:35 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 14:17:35 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 14:17:35 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://4e13bb9ea7d3:8081
24/09/19 14:17:35 INFO Worker: Connecting to master spark-master:7077...
24/09/19 14:17:35 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 44 ms (0 ms spent in bootstraps)
24/09/19 14:17:35 INFO Worker: Successfully registered with master spark://172.19.0.3:7077
24/09/19 14:21:48 INFO Worker: Asked to launch executor app-20240919142147-0000/0 for SimpleDataFrame
24/09/19 14:21:49 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 14:21:49 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 14:21:49 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:21:49 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:21:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 14:21:49 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33689" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e793b96c0f03:33689" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919142147-0000" "--worker-url" "spark://Worker@172.19.0.5:45083" "--resourceProfileId" "0"
24/09/19 14:21:54 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 113@4e13bb9ea7d3
24/09/19 14:21:54 INFO SignalUtils: Registering signal handler for TERM
24/09/19 14:21:54 INFO SignalUtils: Registering signal handler for HUP
24/09/19 14:21:54 INFO SignalUtils: Registering signal handler for INT
24/09/19 14:21:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 14:21:56 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:21:56 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:21:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:21:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:21:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:21:57 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:33689 after 284 ms (0 ms spent in bootstraps)
24/09/19 14:21:58 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:21:58 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:21:58 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:21:58 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:21:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:21:58 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:33689 after 9 ms (0 ms spent in bootstraps)
24/09/19 14:21:59 INFO DiskBlockManager: Created local directory at /tmp/spark-1620725b-65c2-4677-a949-9726f1711781/executor-873eae0e-0b27-40e9-ad68-149b5cf73cf0/blockmgr-42ca116a-01b4-42a8-9598-6ac223c128c7
24/09/19 14:21:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 14:22:00 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e793b96c0f03:33689
24/09/19 14:22:00 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45083
24/09/19 14:22:00 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45083 after 7 ms (0 ms spent in bootstraps)
24/09/19 14:22:00 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45083
24/09/19 14:22:00 INFO ResourceUtils: ==============================================================
24/09/19 14:22:00 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 14:22:00 INFO ResourceUtils: ==============================================================
24/09/19 14:22:00 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 14:22:00 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 14:22:00 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 14:22:00 INFO Executor: Java version 17.0.12
24/09/19 14:22:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40143.
24/09/19 14:22:00 INFO NettyBlockTransferService: Server created on 172.19.0.5:40143
24/09/19 14:22:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 14:22:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 40143, None)
24/09/19 14:22:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 40143, None)
24/09/19 14:22:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 40143, None)
24/09/19 14:22:00 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 14:22:00 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@24155984 for default.
24/09/19 14:22:04 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 14:22:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 14:22:05 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 14:22:06 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:38665 after 23 ms (0 ms spent in bootstraps)
24/09/19 14:22:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 14:22:06 INFO TorrentBroadcast: Reading broadcast variable 0 took 902 ms
24/09/19 14:22:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 14:22:11 INFO CodeGenerator: Code generated in 544.313888 ms
24/09/19 14:22:11 INFO PythonRunner: Times: total = 3490, boot = 2840, init = 648, finish = 2
24/09/19 14:22:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2010 bytes result sent to driver
24/09/19 14:22:12 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 14:22:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 14:22:12 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 14:22:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 14:22:12 INFO TorrentBroadcast: Reading broadcast variable 1 took 36 ms
24/09/19 14:22:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 14:22:12 INFO PythonRunner: Times: total = 166, boot = -1276, init = 1442, finish = 0
24/09/19 14:22:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2013 bytes result sent to driver
24/09/19 14:22:17 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 14:22:18 INFO MemoryStore: MemoryStore cleared
24/09/19 14:22:18 INFO BlockManager: BlockManager stopped
24/09/19 14:22:18 INFO ShutdownHookManager: Shutdown hook called
24/09/19 14:22:18 INFO Worker: Executor app-20240919142147-0000/0 finished with state EXITED message Command exited with code 0 exitStatus 0
24/09/19 14:22:18 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 14:22:18 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919142147-0000, execId=0)
24/09/19 14:22:18 INFO Worker: Asked to kill unknown executor app-20240919142147-0000/0
24/09/19 14:22:18 INFO ExternalShuffleBlockResolver: Application app-20240919142147-0000 removed, cleanupLocalDirs = true
24/09/19 14:22:18 INFO Worker: Cleaning up local directories for application app-20240919142147-0000
24/09/19 14:33:03 INFO Worker: Asked to launch executor app-20240919143302-0001/0 for Employee API Requests
24/09/19 14:33:03 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 14:33:03 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 14:33:03 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:33:03 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:33:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 14:33:03 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34759" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e793b96c0f03:34759" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919143302-0001" "--worker-url" "spark://Worker@172.19.0.5:45083" "--resourceProfileId" "0"
24/09/19 14:33:04 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 213@4e13bb9ea7d3
24/09/19 14:33:04 INFO SignalUtils: Registering signal handler for TERM
24/09/19 14:33:04 INFO SignalUtils: Registering signal handler for HUP
24/09/19 14:33:04 INFO SignalUtils: Registering signal handler for INT
24/09/19 14:33:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 14:33:04 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:33:04 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:33:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:33:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:33:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:33:05 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:34759 after 44 ms (0 ms spent in bootstraps)
24/09/19 14:33:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:33:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:33:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:33:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:33:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:33:05 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:34759 after 2 ms (0 ms spent in bootstraps)
24/09/19 14:33:05 INFO DiskBlockManager: Created local directory at /tmp/spark-1620725b-65c2-4677-a949-9726f1711781/executor-0e123b85-2b92-4367-b167-4f48241e5837/blockmgr-0b365ae5-9db6-4da3-aa2e-78caa1b678b3
24/09/19 14:33:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 14:33:05 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e793b96c0f03:34759
24/09/19 14:33:05 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45083
24/09/19 14:33:05 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45083 after 2 ms (0 ms spent in bootstraps)
24/09/19 14:33:05 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45083
24/09/19 14:33:05 INFO ResourceUtils: ==============================================================
24/09/19 14:33:05 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 14:33:05 INFO ResourceUtils: ==============================================================
24/09/19 14:33:05 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 14:33:05 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 14:33:05 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 14:33:05 INFO Executor: Java version 17.0.12
24/09/19 14:33:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38747.
24/09/19 14:33:05 INFO NettyBlockTransferService: Server created on 172.19.0.5:38747
24/09/19 14:33:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 14:33:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 38747, None)
24/09/19 14:33:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 38747, None)
24/09/19 14:33:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 38747, None)
24/09/19 14:33:05 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 14:33:05 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 14:33:30 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 14:33:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 14:33:31 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 14:33:31 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:35609 after 1 ms (0 ms spent in bootstraps)
24/09/19 14:33:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 14:33:31 INFO TorrentBroadcast: Reading broadcast variable 0 took 105 ms
24/09/19 14:33:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 14:33:32 INFO CodeGenerator: Code generated in 228.03888 ms
24/09/19 14:33:32 INFO PythonRunner: Times: total = 1033, boot = 804, init = 228, finish = 1
24/09/19 14:33:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2029 bytes result sent to driver
24/09/19 14:33:32 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 14:33:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 14:33:32 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 14:33:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 14:33:32 INFO TorrentBroadcast: Reading broadcast variable 1 took 12 ms
24/09/19 14:33:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 14:33:32 INFO PythonRunner: Times: total = 96, boot = -211, init = 307, finish = 0
24/09/19 14:33:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2034 bytes result sent to driver
24/09/19 14:33:33 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 14:33:33 INFO Worker: Asked to kill executor app-20240919143302-0001/0
24/09/19 14:33:33 INFO ExecutorRunner: Runner thread for executor app-20240919143302-0001/0 interrupted
24/09/19 14:33:33 INFO ExecutorRunner: Killing process!
24/09/19 14:33:33 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 14:33:33 INFO ShutdownHookManager: Shutdown hook called
24/09/19 14:33:34 INFO Worker: Executor app-20240919143302-0001/0 finished with state KILLED exitStatus 143
24/09/19 14:33:34 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 14:33:34 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919143302-0001, execId=0)
24/09/19 14:33:34 INFO ExternalShuffleBlockResolver: Application app-20240919143302-0001 removed, cleanupLocalDirs = true
24/09/19 14:33:34 INFO Worker: Cleaning up local directories for application app-20240919143302-0001
24/09/19 14:59:39 INFO Worker: Asked to launch executor app-20240919145939-0002/0 for Employee API Requests
24/09/19 14:59:39 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 14:59:39 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 14:59:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:59:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:59:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 14:59:39 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33865" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e793b96c0f03:33865" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919145939-0002" "--worker-url" "spark://Worker@172.19.0.5:45083" "--resourceProfileId" "0"
24/09/19 14:59:40 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 322@4e13bb9ea7d3
24/09/19 14:59:40 INFO SignalUtils: Registering signal handler for TERM
24/09/19 14:59:40 INFO SignalUtils: Registering signal handler for HUP
24/09/19 14:59:40 INFO SignalUtils: Registering signal handler for INT
24/09/19 14:59:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 14:59:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:59:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:59:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:59:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:59:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:59:41 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:33865 after 57 ms (0 ms spent in bootstraps)
24/09/19 14:59:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 14:59:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 14:59:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 14:59:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 14:59:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 14:59:41 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:33865 after 2 ms (0 ms spent in bootstraps)
24/09/19 14:59:42 INFO DiskBlockManager: Created local directory at /tmp/spark-1620725b-65c2-4677-a949-9726f1711781/executor-a1fc10f4-8f28-4238-a417-1a311623b062/blockmgr-72f52404-76f9-4d3e-b9a7-a02a701d260f
24/09/19 14:59:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 14:59:42 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e793b96c0f03:33865
24/09/19 14:59:42 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45083
24/09/19 14:59:42 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45083 after 4 ms (0 ms spent in bootstraps)
24/09/19 14:59:42 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45083
24/09/19 14:59:42 INFO ResourceUtils: ==============================================================
24/09/19 14:59:42 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 14:59:42 INFO ResourceUtils: ==============================================================
24/09/19 14:59:42 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 14:59:42 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 14:59:42 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 14:59:42 INFO Executor: Java version 17.0.12
24/09/19 14:59:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40503.
24/09/19 14:59:42 INFO NettyBlockTransferService: Server created on 172.19.0.5:40503
24/09/19 14:59:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 14:59:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 40503, None)
24/09/19 14:59:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 40503, None)
24/09/19 14:59:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 40503, None)
24/09/19 14:59:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 14:59:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@42f90c0d for default.
24/09/19 15:00:05 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 15:00:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 15:00:05 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:00:05 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:44093 after 2 ms (0 ms spent in bootstraps)
24/09/19 15:00:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:00:05 INFO TorrentBroadcast: Reading broadcast variable 0 took 121 ms
24/09/19 15:00:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:00:07 INFO CodeGenerator: Code generated in 207.157314 ms
24/09/19 15:00:07 INFO PythonRunner: Times: total = 858, boot = 664, init = 193, finish = 1
24/09/19 15:00:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2045 bytes result sent to driver
24/09/19 15:00:07 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 15:00:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 15:00:07 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:00:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:00:07 INFO TorrentBroadcast: Reading broadcast variable 1 took 14 ms
24/09/19 15:00:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:00:07 INFO PythonRunner: Times: total = 103, boot = -197, init = 300, finish = 0
24/09/19 15:00:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2089 bytes result sent to driver
24/09/19 15:00:08 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 15:00:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 15:00:08 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:00:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:00:08 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 15:00:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:00:08 INFO PythonRunner: Times: total = 92, boot = -1019, init = 1111, finish = 0
24/09/19 15:00:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2045 bytes result sent to driver
24/09/19 15:00:08 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 15:00:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/09/19 15:00:08 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:00:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:00:08 INFO TorrentBroadcast: Reading broadcast variable 3 took 11 ms
24/09/19 15:00:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:00:08 INFO PythonRunner: Times: total = 86, boot = -51, init = 137, finish = 0
24/09/19 15:00:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2003 bytes result sent to driver
24/09/19 15:00:08 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 15:00:08 INFO Worker: Asked to kill executor app-20240919145939-0002/0
24/09/19 15:00:08 INFO ExecutorRunner: Runner thread for executor app-20240919145939-0002/0 interrupted
24/09/19 15:00:08 INFO ExecutorRunner: Killing process!
24/09/19 15:00:08 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 15:00:08 INFO ShutdownHookManager: Shutdown hook called
24/09/19 15:00:08 INFO CoarseGrainedExecutorBackend: Driver from e793b96c0f03:33865 disconnected during shutdown
24/09/19 15:00:09 INFO Worker: Executor app-20240919145939-0002/0 finished with state KILLED exitStatus 143
24/09/19 15:00:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 15:00:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919145939-0002, execId=0)
24/09/19 15:00:09 INFO ExternalShuffleBlockResolver: Application app-20240919145939-0002 removed, cleanupLocalDirs = true
24/09/19 15:00:09 INFO Worker: Cleaning up local directories for application app-20240919145939-0002
24/09/19 15:02:11 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 15:02:11 INFO ExecutorRunner: Killing process!
24/09/19 15:02:11 INFO ShutdownHookManager: Shutdown hook called
24/09/19 15:02:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-1620725b-65c2-4677-a949-9726f1711781
24/09/19 15:02:11 INFO Worker: Unknown Executor app-20240919142147-0000/0 finished with state EXITED message Worker shutting down exitStatus 0
24/09/19 15:06:23 INFO Worker: Started daemon with process name: 1@c380eb976822
24/09/19 15:06:23 INFO SignalUtils: Registering signal handler for TERM
24/09/19 15:06:23 INFO SignalUtils: Registering signal handler for HUP
24/09/19 15:06:23 INFO SignalUtils: Registering signal handler for INT
24/09/19 15:06:23 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 15:06:23 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 15:06:23 INFO SecurityManager: Changing view acls groups to: 
24/09/19 15:06:23 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 15:06:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 15:06:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 15:06:24 INFO Utils: Successfully started service 'sparkWorker' on port 36329.
24/09/19 15:06:24 INFO Worker: Worker decommissioning not enabled.
24/09/19 15:06:24 INFO Worker: Starting Spark worker 172.19.0.5:36329 with 2 cores, 1024.0 MiB RAM
24/09/19 15:06:24 INFO Worker: Running Spark version 3.5.2
24/09/19 15:06:24 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 15:06:24 INFO ResourceUtils: ==============================================================
24/09/19 15:06:24 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 15:06:24 INFO ResourceUtils: ==============================================================
24/09/19 15:06:24 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 15:06:24 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 15:06:25 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://c380eb976822:8081
24/09/19 15:06:25 INFO Worker: Connecting to master spark-master:7077...
24/09/19 15:06:25 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 29 ms (0 ms spent in bootstraps)
24/09/19 15:06:25 INFO Worker: Successfully registered with master spark://172.19.0.3:7077
24/09/19 15:22:07 INFO Worker: Asked to launch executor app-20240919152207-0000/0 for Employee API Requests
24/09/19 15:22:07 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 15:22:07 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 15:22:07 INFO SecurityManager: Changing view acls groups to: 
24/09/19 15:22:07 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 15:22:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 15:22:08 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35623" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e793b96c0f03:35623" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919152207-0000" "--worker-url" "spark://Worker@172.19.0.5:36329" "--resourceProfileId" "0"
24/09/19 15:22:09 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 105@c380eb976822
24/09/19 15:22:09 INFO SignalUtils: Registering signal handler for TERM
24/09/19 15:22:09 INFO SignalUtils: Registering signal handler for HUP
24/09/19 15:22:09 INFO SignalUtils: Registering signal handler for INT
24/09/19 15:22:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 15:22:09 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 15:22:09 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 15:22:09 INFO SecurityManager: Changing view acls groups to: 
24/09/19 15:22:09 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 15:22:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 15:22:09 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:35623 after 44 ms (0 ms spent in bootstraps)
24/09/19 15:22:09 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 15:22:09 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 15:22:09 INFO SecurityManager: Changing view acls groups to: 
24/09/19 15:22:09 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 15:22:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 15:22:09 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:35623 after 2 ms (0 ms spent in bootstraps)
24/09/19 15:22:09 INFO DiskBlockManager: Created local directory at /tmp/spark-1a5130da-8a6e-4c40-9127-326e3892f879/executor-cc269b4b-ae9b-4341-9b75-7f68dcbfda0b/blockmgr-d1a23d16-60b2-4fb0-8348-7ca6b20d7a04
24/09/19 15:22:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 15:22:10 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e793b96c0f03:35623
24/09/19 15:22:10 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:36329
24/09/19 15:22:10 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:36329 after 11 ms (0 ms spent in bootstraps)
24/09/19 15:22:10 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:36329
24/09/19 15:22:10 INFO ResourceUtils: ==============================================================
24/09/19 15:22:10 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 15:22:10 INFO ResourceUtils: ==============================================================
24/09/19 15:22:10 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 15:22:10 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 15:22:10 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 15:22:10 INFO Executor: Java version 17.0.12
24/09/19 15:22:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46705.
24/09/19 15:22:10 INFO NettyBlockTransferService: Server created on 172.19.0.5:46705
24/09/19 15:22:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 15:22:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 46705, None)
24/09/19 15:22:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 46705, None)
24/09/19 15:22:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 46705, None)
24/09/19 15:22:10 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 15:22:10 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 15:22:36 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 15:22:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 15:22:36 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:22:36 INFO TransportClientFactory: Successfully created connection to e793b96c0f03/172.19.0.4:36305 after 2 ms (0 ms spent in bootstraps)
24/09/19 15:22:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:22:36 INFO TorrentBroadcast: Reading broadcast variable 0 took 104 ms
24/09/19 15:22:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:22:37 INFO CodeGenerator: Code generated in 173.779388 ms
24/09/19 15:22:37 INFO PythonRunner: Times: total = 593, boot = 485, init = 108, finish = 0
24/09/19 15:22:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2045 bytes result sent to driver
24/09/19 15:22:37 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 15:22:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 15:22:37 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:22:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:22:37 INFO TorrentBroadcast: Reading broadcast variable 1 took 13 ms
24/09/19 15:22:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:22:37 INFO PythonRunner: Times: total = 80, boot = -288, init = 368, finish = 0
24/09/19 15:22:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2003 bytes result sent to driver
24/09/19 15:22:38 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 15:22:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 15:22:38 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:22:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:22:38 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 15:22:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:22:38 INFO PythonRunner: Times: total = 79, boot = -900, init = 979, finish = 0
24/09/19 15:22:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1959 bytes result sent to driver
24/09/19 15:22:38 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 15:22:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/09/19 15:22:38 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 15:22:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 15:22:38 INFO TorrentBroadcast: Reading broadcast variable 3 took 12 ms
24/09/19 15:22:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 15:22:38 INFO PythonRunner: Times: total = 83, boot = -47, init = 129, finish = 1
24/09/19 15:22:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2003 bytes result sent to driver
24/09/19 15:22:38 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 15:22:38 INFO CoarseGrainedExecutorBackend: Driver from e793b96c0f03:35623 disconnected during shutdown
24/09/19 15:22:38 INFO CoarseGrainedExecutorBackend: Driver from e793b96c0f03:35623 disconnected during shutdown
24/09/19 15:22:38 INFO MemoryStore: MemoryStore cleared
24/09/19 15:22:38 INFO BlockManager: BlockManager stopped
24/09/19 15:22:38 INFO Worker: Asked to kill executor app-20240919152207-0000/0
24/09/19 15:22:38 INFO ShutdownHookManager: Shutdown hook called
24/09/19 15:22:38 INFO ExecutorRunner: Runner thread for executor app-20240919152207-0000/0 interrupted
24/09/19 15:22:38 INFO ExecutorRunner: Killing process!
24/09/19 15:22:38 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 15:22:38 INFO Worker: Executor app-20240919152207-0000/0 finished with state KILLED exitStatus 0
24/09/19 15:22:38 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 15:22:38 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919152207-0000, execId=0)
24/09/19 15:22:38 INFO Worker: Cleaning up local directories for application app-20240919152207-0000
24/09/19 15:22:38 INFO ExternalShuffleBlockResolver: Application app-20240919152207-0000 removed, cleanupLocalDirs = true
24/09/19 16:33:24 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 16:33:24 INFO ShutdownHookManager: Shutdown hook called
24/09/19 16:33:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-1a5130da-8a6e-4c40-9127-326e3892f879
24/09/19 16:33:56 INFO Worker: Started daemon with process name: 1@c380eb976822
24/09/19 16:33:56 INFO SignalUtils: Registering signal handler for TERM
24/09/19 16:33:56 INFO SignalUtils: Registering signal handler for HUP
24/09/19 16:33:56 INFO SignalUtils: Registering signal handler for INT
24/09/19 16:33:56 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:33:56 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:33:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:33:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:33:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:33:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 16:33:57 INFO Utils: Successfully started service 'sparkWorker' on port 45729.
24/09/19 16:33:57 INFO Worker: Worker decommissioning not enabled.
24/09/19 16:33:57 INFO Worker: Starting Spark worker 172.19.0.5:45729 with 2 cores, 1024.0 MiB RAM
24/09/19 16:33:57 INFO Worker: Running Spark version 3.5.2
24/09/19 16:33:57 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 16:33:57 INFO ResourceUtils: ==============================================================
24/09/19 16:33:57 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 16:33:57 INFO ResourceUtils: ==============================================================
24/09/19 16:33:57 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 16:33:57 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 16:33:57 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://c380eb976822:8081
24/09/19 16:33:57 INFO Worker: Connecting to master spark-master:7077...
24/09/19 16:33:57 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 24 ms (0 ms spent in bootstraps)
24/09/19 16:33:58 INFO Worker: Successfully registered with master spark://172.19.0.3:7077
24/09/19 16:36:35 INFO Worker: Asked to launch executor app-20240919163635-0000/0 for Employee API Requests
24/09/19 16:36:36 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:36:36 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:36:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:36:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:36:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:36:36 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38775" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:38775" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919163635-0000" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:36:37 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 115@c380eb976822
24/09/19 16:36:37 INFO SignalUtils: Registering signal handler for TERM
24/09/19 16:36:37 INFO SignalUtils: Registering signal handler for HUP
24/09/19 16:36:37 INFO SignalUtils: Registering signal handler for INT
24/09/19 16:36:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 16:36:37 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 16:36:37 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 16:36:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:36:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:36:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 16:36:37 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:38775 after 43 ms (0 ms spent in bootstraps)
24/09/19 16:36:37 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 16:36:37 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 16:36:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:36:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:36:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 16:36:37 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:38775 after 1 ms (0 ms spent in bootstraps)
24/09/19 16:36:38 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-6eec6d2b-c26e-4b4c-b4f2-6fcfbc38cb93/blockmgr-c6593f58-ce0d-4234-9781-96ed049c8160
24/09/19 16:36:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 16:36:38 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:38775
24/09/19 16:36:38 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 16:36:38 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 16:36:38 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 16:36:38 INFO ResourceUtils: ==============================================================
24/09/19 16:36:38 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 16:36:38 INFO ResourceUtils: ==============================================================
24/09/19 16:36:38 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 16:36:38 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 16:36:38 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 16:36:38 INFO Executor: Java version 17.0.12
24/09/19 16:36:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40905.
24/09/19 16:36:38 INFO NettyBlockTransferService: Server created on 172.19.0.5:40905
24/09/19 16:36:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 16:36:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 40905, None)
24/09/19 16:36:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 40905, None)
24/09/19 16:36:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 40905, None)
24/09/19 16:36:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 16:36:38 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 16:37:00 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 16:37:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 16:37:00 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 16:37:00 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:35065 after 1 ms (0 ms spent in bootstraps)
24/09/19 16:37:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 16:37:00 INFO TorrentBroadcast: Reading broadcast variable 0 took 98 ms
24/09/19 16:37:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 16:37:01 INFO CodeGenerator: Code generated in 178.199935 ms
24/09/19 16:37:01 INFO PythonRunner: Times: total = 586, boot = 475, init = 110, finish = 1
24/09/19 16:37:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2045 bytes result sent to driver
24/09/19 16:37:01 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 16:37:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 16:37:01 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 16:37:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 16:37:01 INFO TorrentBroadcast: Reading broadcast variable 1 took 21 ms
24/09/19 16:37:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 16:37:01 INFO PythonRunner: Times: total = 88, boot = -305, init = 393, finish = 0
24/09/19 16:37:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2089 bytes result sent to driver
24/09/19 16:37:02 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 16:37:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 16:37:02 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 16:37:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 16:37:02 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 16:37:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 16:37:02 INFO PythonRunner: Times: total = 80, boot = -920, init = 1000, finish = 0
24/09/19 16:37:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2045 bytes result sent to driver
24/09/19 16:37:02 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 16:37:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/09/19 16:37:02 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 16:37:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 16:37:02 INFO TorrentBroadcast: Reading broadcast variable 3 took 13 ms
24/09/19 16:37:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.7 KiB, free 434.3 MiB)
24/09/19 16:37:02 INFO PythonRunner: Times: total = 82, boot = -51, init = 133, finish = 0
24/09/19 16:37:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2003 bytes result sent to driver
24/09/19 16:37:02 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 16:37:02 INFO Worker: Asked to kill executor app-20240919163635-0000/0
24/09/19 16:37:02 INFO ExecutorRunner: Runner thread for executor app-20240919163635-0000/0 interrupted
24/09/19 16:37:02 INFO ExecutorRunner: Killing process!
24/09/19 16:37:02 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 16:37:02 INFO ShutdownHookManager: Shutdown hook called
24/09/19 16:37:02 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:38775 disconnected during shutdown
24/09/19 16:37:02 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:38775 disconnected during shutdown
24/09/19 16:37:03 INFO Worker: Executor app-20240919163635-0000/0 finished with state KILLED exitStatus 143
24/09/19 16:37:03 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:37:03 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919163635-0000, execId=0)
24/09/19 16:37:03 INFO ExternalShuffleBlockResolver: Application app-20240919163635-0000 removed, cleanupLocalDirs = true
24/09/19 16:37:03 INFO Worker: Cleaning up local directories for application app-20240919163635-0000
24/09/19 16:37:22 INFO Worker: Asked to launch executor app-20240919163722-0001/0 for Escrita no banco Postgres
24/09/19 16:37:22 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:37:22 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:37:22 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:37:22 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:37:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:37:22 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41513" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:41513" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919163722-0001" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:37:22 INFO Worker: Asked to kill executor app-20240919163722-0001/0
24/09/19 16:37:22 INFO ExecutorRunner: Runner thread for executor app-20240919163722-0001/0 interrupted
24/09/19 16:37:22 INFO ExecutorRunner: Killing process!
24/09/19 16:37:23 INFO Worker: Executor app-20240919163722-0001/0 finished with state KILLED exitStatus 143
24/09/19 16:37:23 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:37:23 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919163722-0001, execId=0)
24/09/19 16:37:23 INFO Worker: Cleaning up local directories for application app-20240919163722-0001
24/09/19 16:37:23 INFO ExternalShuffleBlockResolver: Application app-20240919163722-0001 removed, cleanupLocalDirs = true
24/09/19 16:40:39 INFO Worker: Asked to launch executor app-20240919164039-0002/0 for Escrita no banco Postgres
24/09/19 16:40:39 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:40:39 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:40:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:40:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:40:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:40:39 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46751" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:46751" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919164039-0002" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:40:39 INFO Worker: Asked to kill executor app-20240919164039-0002/0
24/09/19 16:40:39 INFO ExecutorRunner: Runner thread for executor app-20240919164039-0002/0 interrupted
24/09/19 16:40:39 INFO ExecutorRunner: Killing process!
24/09/19 16:40:39 INFO Worker: Executor app-20240919164039-0002/0 finished with state KILLED exitStatus 143
24/09/19 16:40:39 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:40:39 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919164039-0002, execId=0)
24/09/19 16:40:39 INFO ExternalShuffleBlockResolver: Application app-20240919164039-0002 removed, cleanupLocalDirs = true
24/09/19 16:40:39 INFO Worker: Cleaning up local directories for application app-20240919164039-0002
24/09/19 16:45:45 INFO Worker: Asked to launch executor app-20240919164544-0003/0 for Escrita no banco Postgres
24/09/19 16:45:45 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:45:45 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:45:45 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:45:45 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:45:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:45:45 INFO Worker: Asked to kill executor app-20240919164544-0003/0
24/09/19 16:45:45 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38123" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:38123" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919164544-0003" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:45:45 INFO ExecutorRunner: Runner thread for executor app-20240919164544-0003/0 interrupted
24/09/19 16:45:45 INFO ExecutorRunner: Killing process!
24/09/19 16:45:45 INFO Worker: Executor app-20240919164544-0003/0 finished with state KILLED exitStatus 143
24/09/19 16:45:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:45:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919164544-0003, execId=0)
24/09/19 16:45:45 INFO ExternalShuffleBlockResolver: Application app-20240919164544-0003 removed, cleanupLocalDirs = true
24/09/19 16:45:45 INFO Worker: Cleaning up local directories for application app-20240919164544-0003
24/09/19 16:54:08 INFO Worker: Asked to launch executor app-20240919165408-0004/0 for Escrita no banco Postgres
24/09/19 16:54:08 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:54:08 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:54:08 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:54:08 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:54:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:54:08 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43927" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:43927" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919165408-0004" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:54:08 INFO Worker: Asked to kill executor app-20240919165408-0004/0
24/09/19 16:54:08 INFO ExecutorRunner: Runner thread for executor app-20240919165408-0004/0 interrupted
24/09/19 16:54:08 INFO ExecutorRunner: Killing process!
24/09/19 16:54:08 INFO Worker: Executor app-20240919165408-0004/0 finished with state KILLED exitStatus 143
24/09/19 16:54:08 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:54:08 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919165408-0004, execId=0)
24/09/19 16:54:08 INFO ExternalShuffleBlockResolver: Application app-20240919165408-0004 removed, cleanupLocalDirs = true
24/09/19 16:54:08 INFO Worker: Cleaning up local directories for application app-20240919165408-0004
24/09/19 16:56:01 INFO Worker: Asked to launch executor app-20240919165601-0005/0 for Escrita no banco Postgres
24/09/19 16:56:01 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:56:01 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:56:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:56:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:56:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:56:01 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36239" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:36239" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919165601-0005" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:56:02 INFO Worker: Asked to kill executor app-20240919165601-0005/0
24/09/19 16:56:02 INFO ExecutorRunner: Runner thread for executor app-20240919165601-0005/0 interrupted
24/09/19 16:56:02 INFO ExecutorRunner: Killing process!
24/09/19 16:56:02 INFO Worker: Executor app-20240919165601-0005/0 finished with state KILLED exitStatus 143
24/09/19 16:56:02 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:56:02 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919165601-0005, execId=0)
24/09/19 16:56:02 INFO ExternalShuffleBlockResolver: Application app-20240919165601-0005 removed, cleanupLocalDirs = true
24/09/19 16:56:02 INFO Worker: Cleaning up local directories for application app-20240919165601-0005
24/09/19 16:56:50 INFO Worker: Asked to launch executor app-20240919165650-0006/0 for Escrita no banco Postgres
24/09/19 16:56:50 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:56:50 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:56:50 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:56:50 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:56:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:56:50 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33643" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:33643" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919165650-0006" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:56:50 INFO Worker: Asked to kill executor app-20240919165650-0006/0
24/09/19 16:56:50 INFO ExecutorRunner: Runner thread for executor app-20240919165650-0006/0 interrupted
24/09/19 16:56:50 INFO ExecutorRunner: Killing process!
24/09/19 16:56:50 INFO Worker: Executor app-20240919165650-0006/0 finished with state KILLED exitStatus 143
24/09/19 16:56:50 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:56:50 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919165650-0006, execId=0)
24/09/19 16:56:50 INFO Worker: Cleaning up local directories for application app-20240919165650-0006
24/09/19 16:56:50 INFO ExternalShuffleBlockResolver: Application app-20240919165650-0006 removed, cleanupLocalDirs = true
24/09/19 16:57:39 INFO Worker: Asked to launch executor app-20240919165739-0007/0 for Escrita no banco Postgres
24/09/19 16:57:39 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 16:57:39 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 16:57:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 16:57:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 16:57:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 16:57:39 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41445" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:41445" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919165739-0007" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 16:57:40 INFO Worker: Asked to kill executor app-20240919165739-0007/0
24/09/19 16:57:40 INFO ExecutorRunner: Runner thread for executor app-20240919165739-0007/0 interrupted
24/09/19 16:57:40 INFO ExecutorRunner: Killing process!
24/09/19 16:57:40 INFO Worker: Executor app-20240919165739-0007/0 finished with state KILLED exitStatus 143
24/09/19 16:57:40 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 16:57:40 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919165739-0007, execId=0)
24/09/19 16:57:40 INFO ExternalShuffleBlockResolver: Application app-20240919165739-0007 removed, cleanupLocalDirs = true
24/09/19 16:57:40 INFO Worker: Cleaning up local directories for application app-20240919165739-0007
24/09/19 17:01:30 INFO Worker: Asked to launch executor app-20240919170130-0008/0 for Escrita no banco Postgres
24/09/19 17:01:30 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:01:30 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:01:30 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:01:30 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:01:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:01:30 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46671" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:46671" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919170130-0008" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:01:31 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 419@c380eb976822
24/09/19 17:01:31 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:01:32 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:01:32 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:01:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 17:01:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:01:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:01:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:01:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:01:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:01:34 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:46671 after 200 ms (0 ms spent in bootstraps)
24/09/19 17:01:34 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:01:34 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:01:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:01:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:01:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:01:35 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:46671 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:01:35 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-9717d938-a342-4960-b7a7-027551d8508f/blockmgr-0d7cfba2-09da-4197-9757-b50a9ca32f91
24/09/19 17:01:35 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 17:01:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:46671
24/09/19 17:01:36 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 17:01:36 INFO ResourceUtils: ==============================================================
24/09/19 17:01:36 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 17:01:36 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:01:36 INFO ResourceUtils: ==============================================================
24/09/19 17:01:36 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 17:01:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 17:01:36 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 17:01:36 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 17:01:36 INFO Executor: Java version 17.0.12
24/09/19 17:01:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37771.
24/09/19 17:01:36 INFO NettyBlockTransferService: Server created on 172.19.0.5:37771
24/09/19 17:01:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 17:01:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 37771, None)
24/09/19 17:01:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 37771, None)
24/09/19 17:01:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 37771, None)
24/09/19 17:01:36 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 17:01:36 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6e251bad for default.
24/09/19 17:01:57 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 17:01:57 INFO Worker: Asked to kill executor app-20240919170130-0008/0
24/09/19 17:01:57 INFO ExecutorRunner: Runner thread for executor app-20240919170130-0008/0 interrupted
24/09/19 17:01:57 INFO ExecutorRunner: Killing process!
24/09/19 17:01:57 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:01:57 INFO DiskBlockManager: Shutdown hook called
24/09/19 17:01:57 INFO ShutdownHookManager: Shutdown hook called
24/09/19 17:01:57 INFO MemoryStore: MemoryStore cleared
24/09/19 17:01:57 INFO BlockManager: BlockManager stopped
24/09/19 17:01:57 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:46671 disconnected during shutdown
24/09/19 17:01:57 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:46671 disconnected during shutdown
24/09/19 17:01:57 INFO Worker: Executor app-20240919170130-0008/0 finished with state KILLED exitStatus 143
24/09/19 17:01:57 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:01:57 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919170130-0008, execId=0)
24/09/19 17:01:57 INFO ExternalShuffleBlockResolver: Application app-20240919170130-0008 removed, cleanupLocalDirs = true
24/09/19 17:01:57 INFO Worker: Cleaning up local directories for application app-20240919170130-0008
24/09/19 17:08:56 INFO Worker: Asked to launch executor app-20240919170856-0009/0 for Escrita no banco Postgres
24/09/19 17:08:56 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:08:56 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:08:56 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:08:56 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:08:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:08:56 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41589" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:41589" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919170856-0009" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:08:57 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 517@c380eb976822
24/09/19 17:08:57 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:08:57 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:08:57 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:08:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 17:08:57 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:08:57 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:08:57 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:08:57 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:08:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:08:57 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:41589 after 44 ms (0 ms spent in bootstraps)
24/09/19 17:08:57 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:08:57 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:08:57 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:08:57 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:08:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:08:57 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:41589 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:08:58 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/blockmgr-bf35e2e7-c276-4f28-bf68-03312e577fb1
24/09/19 17:08:58 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 17:08:58 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:41589
24/09/19 17:08:58 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 17:08:58 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:08:58 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 17:08:58 INFO ResourceUtils: ==============================================================
24/09/19 17:08:58 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 17:08:58 INFO ResourceUtils: ==============================================================
24/09/19 17:08:58 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 17:08:58 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 17:08:58 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 17:08:58 INFO Executor: Java version 17.0.12
24/09/19 17:08:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39459.
24/09/19 17:08:58 INFO NettyBlockTransferService: Server created on 172.19.0.5:39459
24/09/19 17:08:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 17:08:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 39459, None)
24/09/19 17:08:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 39459, None)
24/09/19 17:08:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 39459, None)
24/09/19 17:08:58 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 17:08:58 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 17:08:58 INFO Executor: Fetching spark://e9e8ef25fbb7:41589/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726765735273
24/09/19 17:08:58 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:41589 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:08:58 INFO Utils: Fetching spark://e9e8ef25fbb7:41589/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/fetchFileTemp11265022269225099845.tmp
24/09/19 17:08:58 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/3744898561726765735273_cache to /opt/bitnami/spark/work/app-20240919170856-0009/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:08:58 INFO Executor: Fetching spark://e9e8ef25fbb7:41589/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726765735273
24/09/19 17:08:58 INFO Utils: Fetching spark://e9e8ef25fbb7:41589/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/fetchFileTemp3117297665035137857.tmp
24/09/19 17:08:58 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/19841266721726765735273_cache to /opt/bitnami/spark/work/app-20240919170856-0009/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:08:58 INFO Executor: Fetching spark://e9e8ef25fbb7:41589/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726765735273
24/09/19 17:08:58 INFO Utils: Fetching spark://e9e8ef25fbb7:41589/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/fetchFileTemp14329677932946754273.tmp
24/09/19 17:08:58 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/-17249154251726765735273_cache has been previously copied to /opt/bitnami/spark/work/app-20240919170856-0009/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:08:58 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919170856-0009/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 17:08:58 INFO Executor: Fetching spark://e9e8ef25fbb7:41589/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726765735273
24/09/19 17:08:58 INFO Utils: Fetching spark://e9e8ef25fbb7:41589/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/fetchFileTemp15395307313562489733.tmp
24/09/19 17:08:58 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a/-17887687531726765735273_cache has been previously copied to /opt/bitnami/spark/work/app-20240919170856-0009/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:08:58 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919170856-0009/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 17:09:21 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 17:09:21 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 17:09:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 17:09:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 17:09:21 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:09:21 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:42415 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:09:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.4 MiB)
24/09/19 17:09:21 INFO TorrentBroadcast: Reading broadcast variable 0 took 102 ms
24/09/19 17:09:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 29.9 KiB, free 434.4 MiB)
24/09/19 17:09:22 INFO CodeGenerator: Code generated in 149.423278 ms
24/09/19 17:09:23 INFO CodeGenerator: Code generated in 24.557886 ms
24/09/19 17:09:23 INFO PythonRunner: Times: total = 634, boot = 511, init = 123, finish = 0
24/09/19 17:09:23 INFO PythonRunner: Times: total = 627, boot = 508, init = 119, finish = 0
24/09/19 17:09:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 17:09:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 17:09:23 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 17:09:23 INFO Worker: Asked to kill executor app-20240919170856-0009/0
24/09/19 17:09:23 INFO ExecutorRunner: Runner thread for executor app-20240919170856-0009/0 interrupted
24/09/19 17:09:23 INFO ExecutorRunner: Killing process!
24/09/19 17:09:23 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:09:23 INFO ShutdownHookManager: Shutdown hook called
24/09/19 17:09:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-bedee691-6dd0-4f87-b194-2d79d1d514a1/spark-f29107bb-e7c4-49cf-99e0-c28215daab4a
24/09/19 17:09:23 INFO MemoryStore: MemoryStore cleared
24/09/19 17:09:23 INFO BlockManager: BlockManager stopped
24/09/19 17:09:24 INFO Worker: Executor app-20240919170856-0009/0 finished with state KILLED exitStatus 143
24/09/19 17:09:24 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:09:24 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919170856-0009, execId=0)
24/09/19 17:09:24 INFO ExternalShuffleBlockResolver: Application app-20240919170856-0009 removed, cleanupLocalDirs = true
24/09/19 17:09:24 INFO Worker: Cleaning up local directories for application app-20240919170856-0009
24/09/19 17:16:34 INFO Worker: Asked to launch executor app-20240919171634-0010/0 for Postgres to Postgres
24/09/19 17:16:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:16:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:16:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:16:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:16:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:16:34 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44965" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:44965" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919171634-0010" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:16:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 642@c380eb976822
24/09/19 17:16:35 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:16:35 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:16:35 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:16:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 17:16:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:16:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:16:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:16:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:16:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:16:36 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:44965 after 47 ms (0 ms spent in bootstraps)
24/09/19 17:16:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:16:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:16:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:16:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:16:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:16:36 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:44965 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:16:36 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/blockmgr-862f36e2-16a1-46a6-891f-2bc4f618cf04
24/09/19 17:16:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 17:16:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:44965
24/09/19 17:16:36 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 17:16:36 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:16:36 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 17:16:36 INFO ResourceUtils: ==============================================================
24/09/19 17:16:36 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 17:16:36 INFO ResourceUtils: ==============================================================
24/09/19 17:16:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 17:16:36 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 17:16:36 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 17:16:36 INFO Executor: Java version 17.0.12
24/09/19 17:16:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46739.
24/09/19 17:16:36 INFO NettyBlockTransferService: Server created on 172.19.0.5:46739
24/09/19 17:16:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 17:16:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 46739, None)
24/09/19 17:16:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 46739, None)
24/09/19 17:16:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 46739, None)
24/09/19 17:16:37 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 17:16:37 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 17:16:37 INFO Executor: Fetching spark://e9e8ef25fbb7:44965/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726766193759
24/09/19 17:16:37 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:44965 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:16:37 INFO Utils: Fetching spark://e9e8ef25fbb7:44965/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/fetchFileTemp1027027019743728449.tmp
24/09/19 17:16:37 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/4714475991726766193759_cache to /opt/bitnami/spark/work/app-20240919171634-0010/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:16:37 INFO Executor: Fetching spark://e9e8ef25fbb7:44965/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726766193759
24/09/19 17:16:37 INFO Utils: Fetching spark://e9e8ef25fbb7:44965/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/fetchFileTemp5484924539427636719.tmp
24/09/19 17:16:37 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/8001846071726766193759_cache to /opt/bitnami/spark/work/app-20240919171634-0010/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:16:37 INFO Executor: Fetching spark://e9e8ef25fbb7:44965/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726766193759
24/09/19 17:16:37 INFO Utils: Fetching spark://e9e8ef25fbb7:44965/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/fetchFileTemp13698135021601756219.tmp
24/09/19 17:16:37 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/-14979420001726766193759_cache has been previously copied to /opt/bitnami/spark/work/app-20240919171634-0010/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:16:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919171634-0010/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 17:16:37 INFO Executor: Fetching spark://e9e8ef25fbb7:44965/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726766193759
24/09/19 17:16:37 INFO Utils: Fetching spark://e9e8ef25fbb7:44965/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/fetchFileTemp5381037011195481406.tmp
24/09/19 17:16:37 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09/-16351641921726766193759_cache has been previously copied to /opt/bitnami/spark/work/app-20240919171634-0010/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:16:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919171634-0010/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 17:16:39 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 17:16:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 17:16:39 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:16:39 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:35141 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:16:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 17:16:39 INFO TorrentBroadcast: Reading broadcast variable 0 took 78 ms
24/09/19 17:16:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 17:16:42 INFO CodeGenerator: Code generated in 159.23743 ms
24/09/19 17:16:42 INFO JDBCRDD: closed connection
24/09/19 17:16:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 17:16:43 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 17:16:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 17:16:44 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:16:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 434.4 MiB)
24/09/19 17:16:44 INFO TorrentBroadcast: Reading broadcast variable 1 took 18 ms
24/09/19 17:16:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 22.3 KiB, free 434.4 MiB)
24/09/19 17:16:46 INFO CodeGenerator: Code generated in 11.366928 ms
24/09/19 17:16:46 INFO CodeGenerator: Code generated in 25.044185 ms
24/09/19 17:16:46 INFO JDBCRDD: closed connection
24/09/19 17:16:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1359 bytes result sent to driver
24/09/19 17:16:46 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 17:16:46 INFO Worker: Asked to kill executor app-20240919171634-0010/0
24/09/19 17:16:46 INFO ExecutorRunner: Runner thread for executor app-20240919171634-0010/0 interrupted
24/09/19 17:16:46 INFO ExecutorRunner: Killing process!
24/09/19 17:16:46 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:16:46 INFO ShutdownHookManager: Shutdown hook called
24/09/19 17:16:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b765b127-ddaa-4809-b0fb-4af1069040d1/spark-103d6649-57e4-4ef8-aabc-1f00e998af09
24/09/19 17:16:46 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:44965 disconnected during shutdown
24/09/19 17:16:46 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:44965 disconnected during shutdown
24/09/19 17:16:46 INFO MemoryStore: MemoryStore cleared
24/09/19 17:16:46 INFO BlockManager: BlockManager stopped
24/09/19 17:16:46 INFO Worker: Executor app-20240919171634-0010/0 finished with state KILLED exitStatus 143
24/09/19 17:16:46 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:16:46 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919171634-0010, execId=0)
24/09/19 17:16:46 INFO ExternalShuffleBlockResolver: Application app-20240919171634-0010 removed, cleanupLocalDirs = true
24/09/19 17:16:46 INFO Worker: Cleaning up local directories for application app-20240919171634-0010
24/09/19 17:25:12 INFO Worker: Asked to launch executor app-20240919172512-0011/0 for Postgres to Postgres
24/09/19 17:25:12 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:25:12 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:25:12 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:25:12 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:25:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:25:12 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38281" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:38281" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919172512-0011" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:25:13 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 763@c380eb976822
24/09/19 17:25:13 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:25:13 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:25:13 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:25:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 17:25:14 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:25:14 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:25:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:25:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:25:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:25:14 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:38281 after 42 ms (0 ms spent in bootstraps)
24/09/19 17:25:14 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:25:14 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:25:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:25:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:25:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:25:14 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:38281 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:25:14 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/blockmgr-e8d5a880-82ab-4e2a-91d3-e23a3654f11c
24/09/19 17:25:14 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 17:25:14 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:38281
24/09/19 17:25:14 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 17:25:14 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:25:14 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 17:25:14 INFO ResourceUtils: ==============================================================
24/09/19 17:25:14 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 17:25:14 INFO ResourceUtils: ==============================================================
24/09/19 17:25:14 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 17:25:14 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 17:25:14 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 17:25:14 INFO Executor: Java version 17.0.12
24/09/19 17:25:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35795.
24/09/19 17:25:14 INFO NettyBlockTransferService: Server created on 172.19.0.5:35795
24/09/19 17:25:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 17:25:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 35795, None)
24/09/19 17:25:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 35795, None)
24/09/19 17:25:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 35795, None)
24/09/19 17:25:14 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 17:25:14 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 17:25:14 INFO Executor: Fetching spark://e9e8ef25fbb7:38281/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726766711406
24/09/19 17:25:15 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:38281 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:25:15 INFO Utils: Fetching spark://e9e8ef25fbb7:38281/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/fetchFileTemp1977748945208904960.tmp
24/09/19 17:25:15 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/-7078105311726766711406_cache to /opt/bitnami/spark/work/app-20240919172512-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:25:15 INFO Executor: Fetching spark://e9e8ef25fbb7:38281/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726766711406
24/09/19 17:25:15 INFO Utils: Fetching spark://e9e8ef25fbb7:38281/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/fetchFileTemp4495079640038797803.tmp
24/09/19 17:25:15 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/-5417611391726766711406_cache to /opt/bitnami/spark/work/app-20240919172512-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:25:15 INFO Executor: Fetching spark://e9e8ef25fbb7:38281/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726766711406
24/09/19 17:25:15 INFO Utils: Fetching spark://e9e8ef25fbb7:38281/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/fetchFileTemp8433852902779725468.tmp
24/09/19 17:25:15 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/13748365301726766711406_cache has been previously copied to /opt/bitnami/spark/work/app-20240919172512-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:25:15 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919172512-0011/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 17:25:15 INFO Executor: Fetching spark://e9e8ef25fbb7:38281/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726766711406
24/09/19 17:25:15 INFO Utils: Fetching spark://e9e8ef25fbb7:38281/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/fetchFileTemp960713146099412350.tmp
24/09/19 17:25:15 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585/10911687381726766711406_cache has been previously copied to /opt/bitnami/spark/work/app-20240919172512-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:25:15 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919172512-0011/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 17:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 17:25:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 17:25:17 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:25:17 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:44063 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:25:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 17:25:17 INFO TorrentBroadcast: Reading broadcast variable 0 took 82 ms
24/09/19 17:25:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 17:25:20 INFO CodeGenerator: Code generated in 227.820008 ms
24/09/19 17:25:20 INFO JDBCRDD: closed connection
24/09/19 17:25:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 17:25:22 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 17:25:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 17:25:22 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:25:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 434.4 MiB)
24/09/19 17:25:22 INFO TorrentBroadcast: Reading broadcast variable 1 took 38 ms
24/09/19 17:25:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 22.3 KiB, free 434.4 MiB)
24/09/19 17:25:24 INFO CodeGenerator: Code generated in 12.344447 ms
24/09/19 17:25:24 INFO CodeGenerator: Code generated in 26.037867 ms
24/09/19 17:25:24 INFO JDBCRDD: closed connection
24/09/19 17:25:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1359 bytes result sent to driver
24/09/19 17:25:24 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 17:25:24 INFO Worker: Asked to kill executor app-20240919172512-0011/0
24/09/19 17:25:24 INFO ExecutorRunner: Runner thread for executor app-20240919172512-0011/0 interrupted
24/09/19 17:25:24 INFO ExecutorRunner: Killing process!
24/09/19 17:25:24 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:25:24 INFO ShutdownHookManager: Shutdown hook called
24/09/19 17:25:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-12cda9c8-471d-475f-91d1-0412d2cf0d10/spark-c3d16046-4a65-48c8-9a1c-66434ba35585
24/09/19 17:25:24 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:38281 disconnected during shutdown
24/09/19 17:25:24 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:38281 disconnected during shutdown
24/09/19 17:25:24 INFO MemoryStore: MemoryStore cleared
24/09/19 17:25:24 INFO BlockManager: BlockManager stopped
24/09/19 17:25:24 INFO Worker: Executor app-20240919172512-0011/0 finished with state KILLED exitStatus 143
24/09/19 17:25:24 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:25:24 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919172512-0011, execId=0)
24/09/19 17:25:24 INFO ExternalShuffleBlockResolver: Application app-20240919172512-0011 removed, cleanupLocalDirs = true
24/09/19 17:25:24 INFO Worker: Cleaning up local directories for application app-20240919172512-0011
24/09/19 17:28:42 INFO Worker: Asked to launch executor app-20240919172842-0012/0 for GCS to Postgres
24/09/19 17:28:42 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:28:42 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:28:42 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:28:42 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:28:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:28:42 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=37181" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:37181" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919172842-0012" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:28:43 INFO Worker: Asked to kill executor app-20240919172842-0012/0
24/09/19 17:28:43 INFO ExecutorRunner: Runner thread for executor app-20240919172842-0012/0 interrupted
24/09/19 17:28:43 INFO ExecutorRunner: Killing process!
24/09/19 17:28:43 INFO Worker: Executor app-20240919172842-0012/0 finished with state KILLED exitStatus 143
24/09/19 17:28:43 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:28:43 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919172842-0012, execId=0)
24/09/19 17:28:43 INFO ExternalShuffleBlockResolver: Application app-20240919172842-0012 removed, cleanupLocalDirs = true
24/09/19 17:28:43 INFO Worker: Cleaning up local directories for application app-20240919172842-0012
24/09/19 17:34:12 INFO Worker: Asked to launch executor app-20240919173412-0013/0 for GCS to Postgres
24/09/19 17:34:12 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:34:12 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:34:12 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:34:12 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:34:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:34:12 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=37653" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:37653" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919173412-0013" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:34:13 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 901@c380eb976822
24/09/19 17:34:13 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:34:13 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:34:13 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:34:14 INFO Worker: Asked to kill executor app-20240919173412-0013/0
24/09/19 17:34:14 INFO ExecutorRunner: Runner thread for executor app-20240919173412-0013/0 interrupted
24/09/19 17:34:14 INFO ExecutorRunner: Killing process!
24/09/19 17:34:14 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:34:14 INFO Worker: Executor app-20240919173412-0013/0 finished with state KILLED exitStatus 143
24/09/19 17:34:14 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:34:14 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919173412-0013, execId=0)
24/09/19 17:34:14 INFO ExternalShuffleBlockResolver: Application app-20240919173412-0013 removed, cleanupLocalDirs = true
24/09/19 17:34:14 INFO Worker: Cleaning up local directories for application app-20240919173412-0013
24/09/19 17:35:10 INFO Worker: Asked to launch executor app-20240919173510-0014/0 for GCS to Postgres
24/09/19 17:35:10 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:35:10 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:35:10 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:35:10 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:35:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:35:10 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41701" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:41701" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919173510-0014" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:35:12 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 934@c380eb976822
24/09/19 17:35:12 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:35:12 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:35:12 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:35:12 INFO Worker: Asked to kill executor app-20240919173510-0014/0
24/09/19 17:35:12 INFO ExecutorRunner: Runner thread for executor app-20240919173510-0014/0 interrupted
24/09/19 17:35:12 INFO ExecutorRunner: Killing process!
24/09/19 17:35:12 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:35:12 INFO Worker: Executor app-20240919173510-0014/0 finished with state KILLED exitStatus 143
24/09/19 17:35:12 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:35:12 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919173510-0014, execId=0)
24/09/19 17:35:12 INFO ExternalShuffleBlockResolver: Application app-20240919173510-0014 removed, cleanupLocalDirs = true
24/09/19 17:35:12 INFO Worker: Cleaning up local directories for application app-20240919173510-0014
24/09/19 17:36:59 INFO Worker: Asked to launch executor app-20240919173659-0015/0 for GCS to Postgres
24/09/19 17:36:59 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:36:59 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:36:59 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:36:59 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:36:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:36:59 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43765" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:43765" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919173659-0015" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:37:00 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 970@c380eb976822
24/09/19 17:37:00 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:37:00 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:37:00 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:37:00 INFO Worker: Asked to kill executor app-20240919173659-0015/0
24/09/19 17:37:00 INFO ExecutorRunner: Runner thread for executor app-20240919173659-0015/0 interrupted
24/09/19 17:37:00 INFO ExecutorRunner: Killing process!
24/09/19 17:37:00 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:37:00 INFO Worker: Executor app-20240919173659-0015/0 finished with state KILLED exitStatus 143
24/09/19 17:37:00 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:37:00 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919173659-0015, execId=0)
24/09/19 17:37:00 INFO ExternalShuffleBlockResolver: Application app-20240919173659-0015 removed, cleanupLocalDirs = true
24/09/19 17:37:00 INFO Worker: Cleaning up local directories for application app-20240919173659-0015
24/09/19 17:56:31 INFO Worker: Asked to launch executor app-20240919175631-0016/0 for GCS to Postgres
24/09/19 17:56:32 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:56:32 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:56:32 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:56:32 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:56:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:56:32 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34989" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:34989" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919175631-0016" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 17:56:33 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1004@c380eb976822
24/09/19 17:56:33 INFO SignalUtils: Registering signal handler for TERM
24/09/19 17:56:33 INFO SignalUtils: Registering signal handler for HUP
24/09/19 17:56:33 INFO SignalUtils: Registering signal handler for INT
24/09/19 17:56:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 17:56:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:56:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:56:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:56:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:56:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:56:34 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34989 after 56 ms (0 ms spent in bootstraps)
24/09/19 17:56:34 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 17:56:34 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 17:56:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:56:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:56:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 17:56:34 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34989 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:56:34 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/blockmgr-a3644fed-6c28-493a-a353-011a55f326dc
24/09/19 17:56:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 17:56:34 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:34989
24/09/19 17:56:34 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 17:56:34 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 17:56:34 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 17:56:34 INFO ResourceUtils: ==============================================================
24/09/19 17:56:34 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 17:56:34 INFO ResourceUtils: ==============================================================
24/09/19 17:56:34 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 17:56:34 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 17:56:34 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 17:56:34 INFO Executor: Java version 17.0.12
24/09/19 17:56:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38693.
24/09/19 17:56:34 INFO NettyBlockTransferService: Server created on 172.19.0.5:38693
24/09/19 17:56:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 17:56:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 38693, None)
24/09/19 17:56:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 38693, None)
24/09/19 17:56:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 38693, None)
24/09/19 17:56:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 17:56:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e4e04a3 for default.
24/09/19 17:56:34 INFO Executor: Fetching spark://e9e8ef25fbb7:34989/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726768591231
24/09/19 17:56:34 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34989 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:56:34 INFO Utils: Fetching spark://e9e8ef25fbb7:34989/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/fetchFileTemp981239569349902107.tmp
24/09/19 17:56:34 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/-1005149601726768591231_cache to /opt/bitnami/spark/work/app-20240919175631-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:56:34 INFO Executor: Fetching spark://e9e8ef25fbb7:34989/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726768591231
24/09/19 17:56:34 INFO Utils: Fetching spark://e9e8ef25fbb7:34989/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/fetchFileTemp2143339659171551146.tmp
24/09/19 17:56:34 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/18829270081726768591231_cache to /opt/bitnami/spark/work/app-20240919175631-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:56:34 INFO Executor: Fetching spark://e9e8ef25fbb7:34989/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726768591231
24/09/19 17:56:34 INFO Utils: Fetching spark://e9e8ef25fbb7:34989/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/fetchFileTemp4741258048510911084.tmp
24/09/19 17:56:34 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/-6317308331726768591231_cache has been previously copied to /opt/bitnami/spark/work/app-20240919175631-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 17:56:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919175631-0016/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 17:56:34 INFO Executor: Fetching spark://e9e8ef25fbb7:34989/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726768591231
24/09/19 17:56:34 INFO Utils: Fetching spark://e9e8ef25fbb7:34989/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/fetchFileTemp14494300597245930099.tmp
24/09/19 17:56:34 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781/-15150672651726768591231_cache has been previously copied to /opt/bitnami/spark/work/app-20240919175631-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 17:56:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919175631-0016/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 17:56:35 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 17:56:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 17:56:35 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 17:56:35 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:43081 after 1 ms (0 ms spent in bootstraps)
24/09/19 17:56:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 434.4 MiB)
24/09/19 17:56:35 INFO TorrentBroadcast: Reading broadcast variable 0 took 102 ms
24/09/19 17:56:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 17:56:35 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmpw_gjza70.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 17:56:35 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 17:56:35 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 17:56:35 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmpw_gjza70.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 17:56:35 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 17:56:35 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 17:56:35 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmpw_gjza70.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 17:56:35 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 17:56:35 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 17:56:35 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmpw_gjza70.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 17:56:36 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 17:56:36 INFO Worker: Asked to kill executor app-20240919175631-0016/0
24/09/19 17:56:36 INFO ExecutorRunner: Runner thread for executor app-20240919175631-0016/0 interrupted
24/09/19 17:56:36 INFO ExecutorRunner: Killing process!
24/09/19 17:56:36 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 17:56:36 INFO ShutdownHookManager: Shutdown hook called
24/09/19 17:56:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-b1f9569f-15c9-4506-b01d-92bcc778e783/spark-a44d85af-3f87-4084-a5cc-7353c5ffb781
24/09/19 17:56:36 INFO MemoryStore: MemoryStore cleared
24/09/19 17:56:36 INFO BlockManager: BlockManager stopped
24/09/19 17:56:36 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:34989 disconnected during shutdown
24/09/19 17:56:36 INFO CoarseGrainedExecutorBackend: Driver from e9e8ef25fbb7:34989 disconnected during shutdown
24/09/19 17:56:36 INFO Worker: Executor app-20240919175631-0016/0 finished with state KILLED exitStatus 143
24/09/19 17:56:36 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 17:56:36 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919175631-0016, execId=0)
24/09/19 17:56:36 INFO ExternalShuffleBlockResolver: Application app-20240919175631-0016 removed, cleanupLocalDirs = true
24/09/19 17:56:36 INFO Worker: Cleaning up local directories for application app-20240919175631-0016
24/09/19 17:59:58 INFO Worker: Asked to launch executor app-20240919175958-0017/0 for GCS to Postgres
24/09/19 17:59:58 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 17:59:58 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 17:59:58 INFO SecurityManager: Changing view acls groups to: 
24/09/19 17:59:58 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 17:59:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 17:59:58 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45935" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:45935" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919175958-0017" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 18:00:00 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1107@c380eb976822
24/09/19 18:00:00 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:00:00 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:00:00 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:00:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:00:00 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:00:00 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:00:00 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:00:00 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:00:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:00:01 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:45935 after 76 ms (0 ms spent in bootstraps)
24/09/19 18:00:01 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:00:01 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:00:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:00:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:00:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:00:01 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:45935 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:00:01 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/blockmgr-704fdbd3-524f-45a6-b16c-44e58025ea8f
24/09/19 18:00:01 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 18:00:02 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:45935
24/09/19 18:00:02 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 18:00:02 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:00:02 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 18:00:02 INFO ResourceUtils: ==============================================================
24/09/19 18:00:02 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 18:00:02 INFO ResourceUtils: ==============================================================
24/09/19 18:00:02 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 18:00:02 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 18:00:02 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 18:00:02 INFO Executor: Java version 17.0.12
24/09/19 18:00:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36297.
24/09/19 18:00:02 INFO NettyBlockTransferService: Server created on 172.19.0.5:36297
24/09/19 18:00:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 18:00:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 36297, None)
24/09/19 18:00:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 36297, None)
24/09/19 18:00:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 36297, None)
24/09/19 18:00:02 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 18:00:02 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7aeea835 for default.
24/09/19 18:00:02 INFO Executor: Fetching spark://e9e8ef25fbb7:45935/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726768797008
24/09/19 18:00:02 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:45935 after 1 ms (0 ms spent in bootstraps)
24/09/19 18:00:02 INFO Utils: Fetching spark://e9e8ef25fbb7:45935/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/fetchFileTemp13301430541376913336.tmp
24/09/19 18:00:02 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/-10693159351726768797008_cache to /opt/bitnami/spark/work/app-20240919175958-0017/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:00:02 INFO Executor: Fetching spark://e9e8ef25fbb7:45935/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726768797008
24/09/19 18:00:02 INFO Utils: Fetching spark://e9e8ef25fbb7:45935/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/fetchFileTemp7728532232104109787.tmp
24/09/19 18:00:02 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/6961032171726768797008_cache to /opt/bitnami/spark/work/app-20240919175958-0017/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:00:02 INFO Executor: Fetching spark://e9e8ef25fbb7:45935/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726768797008
24/09/19 18:00:02 INFO Utils: Fetching spark://e9e8ef25fbb7:45935/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/fetchFileTemp12960302303951661442.tmp
24/09/19 18:00:02 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/17668875021726768797008_cache has been previously copied to /opt/bitnami/spark/work/app-20240919175958-0017/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:00:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919175958-0017/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 18:00:02 INFO Executor: Fetching spark://e9e8ef25fbb7:45935/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726768797008
24/09/19 18:00:02 INFO Utils: Fetching spark://e9e8ef25fbb7:45935/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/fetchFileTemp15121822608407364086.tmp
24/09/19 18:00:02 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26/11430294061726768797008_cache has been previously copied to /opt/bitnami/spark/work/app-20240919175958-0017/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:00:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919175958-0017/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 18:00:02 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 18:00:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 18:00:02 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 18:00:02 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:43863 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:00:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 434.4 MiB)
24/09/19 18:00:03 INFO TorrentBroadcast: Reading broadcast variable 0 took 154 ms
24/09/19 18:00:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 18:00:03 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmptbf5z2ra.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:00:03 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 18:00:03 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 18:00:03 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmptbf5z2ra.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:00:03 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 18:00:03 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 18:00:03 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmptbf5z2ra.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:00:03 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 18:00:03 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 18:00:03 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/tmptbf5z2ra.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:00:04 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 18:00:04 INFO Worker: Asked to kill executor app-20240919175958-0017/0
24/09/19 18:00:04 INFO ExecutorRunner: Runner thread for executor app-20240919175958-0017/0 interrupted
24/09/19 18:00:04 INFO ExecutorRunner: Killing process!
24/09/19 18:00:04 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:00:04 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:00:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-f36e66d4-b75a-425e-8da4-6d671e89c138/spark-ac67f683-803d-44c3-90a4-d1b5f2013e26
24/09/19 18:00:04 INFO MemoryStore: MemoryStore cleared
24/09/19 18:00:04 INFO BlockManager: BlockManager stopped
24/09/19 18:00:04 INFO Worker: Executor app-20240919175958-0017/0 finished with state KILLED exitStatus 143
24/09/19 18:00:04 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:00:04 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919175958-0017, execId=0)
24/09/19 18:00:04 INFO ExternalShuffleBlockResolver: Application app-20240919175958-0017 removed, cleanupLocalDirs = true
24/09/19 18:00:04 INFO Worker: Cleaning up local directories for application app-20240919175958-0017
24/09/19 18:01:57 INFO Worker: Asked to launch executor app-20240919180157-0018/0 for GCS to Postgres
24/09/19 18:01:57 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:01:57 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:01:57 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:01:57 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:01:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:01:57 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32769" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:32769" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919180157-0018" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 18:01:58 INFO Worker: Asked to kill executor app-20240919180157-0018/0
24/09/19 18:01:58 INFO ExecutorRunner: Runner thread for executor app-20240919180157-0018/0 interrupted
24/09/19 18:01:58 INFO ExecutorRunner: Killing process!
24/09/19 18:01:59 INFO Worker: Executor app-20240919180157-0018/0 finished with state KILLED exitStatus 143
24/09/19 18:01:59 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:01:59 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919180157-0018, execId=0)
24/09/19 18:01:59 INFO ExternalShuffleBlockResolver: Application app-20240919180157-0018 removed, cleanupLocalDirs = true
24/09/19 18:01:59 INFO Worker: Cleaning up local directories for application app-20240919180157-0018
24/09/19 18:11:09 INFO Worker: Asked to launch executor app-20240919181109-0019/0 for GCS to Postgres
24/09/19 18:11:09 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:11:09 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:11:09 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:11:09 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:11:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:11:09 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34689" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@e9e8ef25fbb7:34689" "--executor-id" "0" "--hostname" "172.19.0.5" "--cores" "2" "--app-id" "app-20240919181109-0019" "--worker-url" "spark://Worker@172.19.0.5:45729" "--resourceProfileId" "0"
24/09/19 18:11:10 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1250@c380eb976822
24/09/19 18:11:10 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:11:10 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:11:10 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:11:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:11:11 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:11:11 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:11:11 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:11:11 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:11:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:11:11 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34689 after 59 ms (0 ms spent in bootstraps)
24/09/19 18:11:11 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:11:11 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:11:11 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:11:11 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:11:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:11:11 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34689 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:11:12 INFO DiskBlockManager: Created local directory at /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/blockmgr-b7b31c40-ae44-4719-bb13-49a13a4bd47e
24/09/19 18:11:12 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 18:11:12 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@e9e8ef25fbb7:34689
24/09/19 18:11:12 INFO WorkerWatcher: Connecting to worker spark://Worker@172.19.0.5:45729
24/09/19 18:11:12 INFO TransportClientFactory: Successfully created connection to /172.19.0.5:45729 after 1 ms (0 ms spent in bootstraps)
24/09/19 18:11:12 INFO WorkerWatcher: Successfully connected to spark://Worker@172.19.0.5:45729
24/09/19 18:11:12 INFO ResourceUtils: ==============================================================
24/09/19 18:11:12 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 18:11:12 INFO ResourceUtils: ==============================================================
24/09/19 18:11:12 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 18:11:12 INFO Executor: Starting executor ID 0 on host 172.19.0.5
24/09/19 18:11:12 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 18:11:12 INFO Executor: Java version 17.0.12
24/09/19 18:11:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36579.
24/09/19 18:11:12 INFO NettyBlockTransferService: Server created on 172.19.0.5:36579
24/09/19 18:11:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 18:11:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.19.0.5, 36579, None)
24/09/19 18:11:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.19.0.5, 36579, None)
24/09/19 18:11:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.19.0.5, 36579, None)
24/09/19 18:11:12 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 18:11:12 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@42f90c0d for default.
24/09/19 18:11:12 INFO Executor: Fetching spark://e9e8ef25fbb7:34689/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726769468804
24/09/19 18:11:12 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:34689 after 1 ms (0 ms spent in bootstraps)
24/09/19 18:11:12 INFO Utils: Fetching spark://e9e8ef25fbb7:34689/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/fetchFileTemp15303044486121096940.tmp
24/09/19 18:11:12 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/-9304076511726769468804_cache to /opt/bitnami/spark/work/app-20240919181109-0019/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:11:12 INFO Executor: Fetching spark://e9e8ef25fbb7:34689/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726769468804
24/09/19 18:11:12 INFO Utils: Fetching spark://e9e8ef25fbb7:34689/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/fetchFileTemp1875306473888377289.tmp
24/09/19 18:11:12 INFO Utils: Copying /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/-17183660351726769468804_cache to /opt/bitnami/spark/work/app-20240919181109-0019/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:11:12 INFO Executor: Fetching spark://e9e8ef25fbb7:34689/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726769468804
24/09/19 18:11:12 INFO Utils: Fetching spark://e9e8ef25fbb7:34689/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/fetchFileTemp2586627029707709320.tmp
24/09/19 18:11:12 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/20349746261726769468804_cache has been previously copied to /opt/bitnami/spark/work/app-20240919181109-0019/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:11:12 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919181109-0019/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 18:11:12 INFO Executor: Fetching spark://e9e8ef25fbb7:34689/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726769468804
24/09/19 18:11:12 INFO Utils: Fetching spark://e9e8ef25fbb7:34689/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/fetchFileTemp13624709201608872161.tmp
24/09/19 18:11:12 INFO Utils: /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad/13557264181726769468804_cache has been previously copied to /opt/bitnami/spark/work/app-20240919181109-0019/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:11:12 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919181109-0019/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 18:11:12 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 18:11:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 18:11:12 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 18:11:12 INFO TransportClientFactory: Successfully created connection to e9e8ef25fbb7/172.19.0.4:39313 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:11:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 434.4 MiB)
24/09/19 18:11:12 INFO TorrentBroadcast: Reading broadcast variable 0 took 100 ms
24/09/19 18:11:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 18:11:13 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:11:13 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 18:11:13 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 18:11:13 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:11:13 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 18:11:13 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 18:11:13 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:11:13 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 18:11:13 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 18:11:13 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/tmp/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:11:13 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 18:11:13 INFO Worker: Asked to kill executor app-20240919181109-0019/0
24/09/19 18:11:13 INFO ExecutorRunner: Runner thread for executor app-20240919181109-0019/0 interrupted
24/09/19 18:11:13 INFO ExecutorRunner: Killing process!
24/09/19 18:11:13 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:11:13 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:11:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d/executor-45862d05-edb2-423e-8b1d-ac26436ee7bc/spark-524a2655-0571-4f7f-8764-35bbe08129ad
24/09/19 18:11:13 INFO MemoryStore: MemoryStore cleared
24/09/19 18:11:13 INFO BlockManager: BlockManager stopped
24/09/19 18:11:13 INFO Worker: Executor app-20240919181109-0019/0 finished with state KILLED exitStatus 143
24/09/19 18:11:13 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:11:13 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919181109-0019, execId=0)
24/09/19 18:11:13 INFO Worker: Cleaning up local directories for application app-20240919181109-0019
24/09/19 18:11:13 INFO ExternalShuffleBlockResolver: Application app-20240919181109-0019 removed, cleanupLocalDirs = true
24/09/19 18:12:16 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 18:12:16 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:12:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-977aeff8-8d15-4054-bbc1-e5aeb20d317d
24/09/19 18:12:19 INFO Worker: Started daemon with process name: 1@c380eb976822
24/09/19 18:12:19 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:12:19 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:12:19 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:12:19 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:12:19 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:12:19 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:12:19 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:12:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:12:19 INFO Utils: Successfully started service 'sparkWorker' on port 40523.
24/09/19 18:12:19 INFO Worker: Worker decommissioning not enabled.
24/09/19 18:12:19 INFO Worker: Starting Spark worker 172.19.0.5:40523 with 2 cores, 1024.0 MiB RAM
24/09/19 18:12:19 INFO Worker: Running Spark version 3.5.2
24/09/19 18:12:19 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 18:12:19 INFO ResourceUtils: ==============================================================
24/09/19 18:12:19 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 18:12:19 INFO ResourceUtils: ==============================================================
24/09/19 18:12:20 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 18:12:20 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 18:12:20 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://c380eb976822:8081
24/09/19 18:12:20 INFO Worker: Connecting to master spark-master:7077...
24/09/19 18:12:20 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 23 ms (0 ms spent in bootstraps)
24/09/19 18:12:20 INFO Worker: Successfully registered with master spark://172.19.0.3:7077
24/09/19 18:12:28 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 18:12:49 INFO Worker: Started daemon with process name: 1@c380eb976822
24/09/19 18:12:49 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:12:49 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:12:49 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:12:50 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:12:50 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:12:50 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:12:50 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:12:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:12:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:12:50 INFO Utils: Successfully started service 'sparkWorker' on port 46531.
24/09/19 18:12:50 INFO Worker: Worker decommissioning not enabled.
24/09/19 18:12:50 INFO Worker: Starting Spark worker 172.19.0.5:46531 with 2 cores, 1024.0 MiB RAM
24/09/19 18:12:50 INFO Worker: Running Spark version 3.5.2
24/09/19 18:12:50 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 18:12:50 INFO ResourceUtils: ==============================================================
24/09/19 18:12:50 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 18:12:50 INFO ResourceUtils: ==============================================================
24/09/19 18:12:50 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 18:12:50 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 18:12:50 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://c380eb976822:8081
24/09/19 18:12:50 INFO Worker: Connecting to master spark-master:7077...
24/09/19 18:12:50 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.3:7077 after 31 ms (0 ms spent in bootstraps)
24/09/19 18:12:51 INFO Worker: Successfully registered with master spark://172.19.0.3:7077
24/09/19 18:23:10 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 18:23:33 INFO Worker: Started daemon with process name: 1@4d76aaf4f396
24/09/19 18:23:33 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:23:33 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:23:33 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:23:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:23:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:23:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:23:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:23:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:23:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:23:34 INFO Utils: Successfully started service 'sparkWorker' on port 38009.
24/09/19 18:23:34 INFO Worker: Worker decommissioning not enabled.
24/09/19 18:23:34 INFO Worker: Starting Spark worker 172.20.0.4:38009 with 2 cores, 1024.0 MiB RAM
24/09/19 18:23:34 INFO Worker: Running Spark version 3.5.2
24/09/19 18:23:34 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 18:23:34 INFO ResourceUtils: ==============================================================
24/09/19 18:23:34 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 18:23:34 INFO ResourceUtils: ==============================================================
24/09/19 18:23:34 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 18:23:34 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 18:23:35 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://4d76aaf4f396:8081
24/09/19 18:23:35 INFO Worker: Connecting to master spark-master:7077...
24/09/19 18:23:35 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.2:7077 after 34 ms (0 ms spent in bootstraps)
24/09/19 18:23:35 INFO Worker: Successfully registered with master spark://172.20.0.2:7077
24/09/19 18:37:34 INFO Worker: Asked to launch executor app-20240919183733-0000/0 for GCS to Postgres
24/09/19 18:37:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:37:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:37:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:37:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:37:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:37:34 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40799" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@351945988b8e:40799" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20240919183733-0000" "--worker-url" "spark://Worker@172.20.0.4:38009" "--resourceProfileId" "0"
24/09/19 18:37:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 127@4d76aaf4f396
24/09/19 18:37:35 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:37:35 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:37:35 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:37:35 INFO Worker: Asked to kill executor app-20240919183733-0000/0
24/09/19 18:37:35 INFO ExecutorRunner: Runner thread for executor app-20240919183733-0000/0 interrupted
24/09/19 18:37:35 INFO ExecutorRunner: Killing process!
24/09/19 18:37:35 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:37:35 INFO Worker: Executor app-20240919183733-0000/0 finished with state KILLED exitStatus 143
24/09/19 18:37:35 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:37:35 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919183733-0000, execId=0)
24/09/19 18:37:35 INFO Worker: Cleaning up local directories for application app-20240919183733-0000
24/09/19 18:37:35 INFO ExternalShuffleBlockResolver: Application app-20240919183733-0000 removed, cleanupLocalDirs = true
24/09/19 18:41:05 INFO Worker: Asked to launch executor app-20240919184105-0001/0 for GCS to Postgres
24/09/19 18:41:05 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:41:05 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:41:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:41:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:41:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:41:05 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=37741" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@351945988b8e:37741" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20240919184105-0001" "--worker-url" "spark://Worker@172.20.0.4:38009" "--resourceProfileId" "0"
24/09/19 18:41:06 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 165@4d76aaf4f396
24/09/19 18:41:06 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:41:06 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:41:06 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:41:06 INFO Worker: Asked to kill executor app-20240919184105-0001/0
24/09/19 18:41:06 INFO ExecutorRunner: Runner thread for executor app-20240919184105-0001/0 interrupted
24/09/19 18:41:06 INFO ExecutorRunner: Killing process!
24/09/19 18:41:06 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:41:06 INFO Worker: Executor app-20240919184105-0001/0 finished with state KILLED exitStatus 143
24/09/19 18:41:06 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:41:06 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919184105-0001, execId=0)
24/09/19 18:41:06 INFO Worker: Cleaning up local directories for application app-20240919184105-0001
24/09/19 18:41:06 INFO ExternalShuffleBlockResolver: Application app-20240919184105-0001 removed, cleanupLocalDirs = true
24/09/19 18:47:40 INFO Worker: Asked to launch executor app-20240919184740-0002/0 for GCS to Postgres
24/09/19 18:47:40 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:47:40 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:47:40 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:47:40 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:47:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:47:40 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46655" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@351945988b8e:46655" "--executor-id" "0" "--hostname" "172.20.0.4" "--cores" "2" "--app-id" "app-20240919184740-0002" "--worker-url" "spark://Worker@172.20.0.4:38009" "--resourceProfileId" "0"
24/09/19 18:47:41 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 196@4d76aaf4f396
24/09/19 18:47:41 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:47:41 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:47:41 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:47:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:47:42 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:47:42 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:47:42 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:47:42 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:47:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:47:42 INFO TransportClientFactory: Successfully created connection to 351945988b8e/172.20.0.5:46655 after 69 ms (0 ms spent in bootstraps)
24/09/19 18:47:42 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:47:42 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:47:42 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:47:42 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:47:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:47:42 INFO TransportClientFactory: Successfully created connection to 351945988b8e/172.20.0.5:46655 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:47:42 INFO DiskBlockManager: Created local directory at /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/blockmgr-83c7940e-4d47-4695-8c8c-0b951a67fed9
24/09/19 18:47:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 18:47:42 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@351945988b8e:46655
24/09/19 18:47:42 INFO WorkerWatcher: Connecting to worker spark://Worker@172.20.0.4:38009
24/09/19 18:47:42 INFO TransportClientFactory: Successfully created connection to /172.20.0.4:38009 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:47:42 INFO WorkerWatcher: Successfully connected to spark://Worker@172.20.0.4:38009
24/09/19 18:47:42 INFO ResourceUtils: ==============================================================
24/09/19 18:47:42 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 18:47:42 INFO ResourceUtils: ==============================================================
24/09/19 18:47:42 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 18:47:42 INFO Executor: Starting executor ID 0 on host 172.20.0.4
24/09/19 18:47:42 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 18:47:42 INFO Executor: Java version 17.0.12
24/09/19 18:47:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41511.
24/09/19 18:47:42 INFO NettyBlockTransferService: Server created on 172.20.0.4:41511
24/09/19 18:47:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 18:47:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.20.0.4, 41511, None)
24/09/19 18:47:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.20.0.4, 41511, None)
24/09/19 18:47:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.20.0.4, 41511, None)
24/09/19 18:47:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 18:47:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1635823e for default.
24/09/19 18:47:42 INFO Executor: Fetching spark://351945988b8e:46655/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726771659605
24/09/19 18:47:43 INFO TransportClientFactory: Successfully created connection to 351945988b8e/172.20.0.5:46655 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:47:43 INFO Utils: Fetching spark://351945988b8e:46655/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/fetchFileTemp3519739639473135373.tmp
24/09/19 18:47:43 INFO Utils: Copying /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/12252550081726771659605_cache to /opt/bitnami/spark/work/app-20240919184740-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:47:43 INFO Executor: Fetching spark://351945988b8e:46655/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726771659605
24/09/19 18:47:43 INFO Utils: Fetching spark://351945988b8e:46655/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/fetchFileTemp5546310559488504745.tmp
24/09/19 18:47:43 INFO Utils: Copying /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/-12420023841726771659605_cache to /opt/bitnami/spark/work/app-20240919184740-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:47:43 INFO Executor: Fetching spark://351945988b8e:46655/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726771659605
24/09/19 18:47:43 INFO Utils: Fetching spark://351945988b8e:46655/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/fetchFileTemp6633854033232936362.tmp
24/09/19 18:47:43 INFO Utils: /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/16346991991726771659605_cache has been previously copied to /opt/bitnami/spark/work/app-20240919184740-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:47:43 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919184740-0002/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 18:47:43 INFO Executor: Fetching spark://351945988b8e:46655/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726771659605
24/09/19 18:47:43 INFO Utils: Fetching spark://351945988b8e:46655/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/fetchFileTemp2275505463476403674.tmp
24/09/19 18:47:43 INFO Utils: /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370/12867165911726771659605_cache has been previously copied to /opt/bitnami/spark/work/app-20240919184740-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:47:43 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919184740-0002/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 18:47:43 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 18:47:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 18:47:43 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 18:47:43 INFO TransportClientFactory: Successfully created connection to 351945988b8e/172.20.0.5:38017 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:47:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 434.4 MiB)
24/09/19 18:47:43 INFO TorrentBroadcast: Reading broadcast variable 0 took 99 ms
24/09/19 18:47:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 18:47:43 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:47:43 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 18:47:43 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 18:47:43 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:47:43 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 18:47:43 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 18:47:44 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:47:44 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 18:47:44 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 18:47:44 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:47:44 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 18:47:44 INFO Worker: Asked to kill executor app-20240919184740-0002/0
24/09/19 18:47:44 INFO ExecutorRunner: Runner thread for executor app-20240919184740-0002/0 interrupted
24/09/19 18:47:44 INFO ExecutorRunner: Killing process!
24/09/19 18:47:44 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:47:44 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:47:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68/executor-59cffa37-6c83-4e64-a733-aacf7562e720/spark-091e83ea-d98f-410f-83df-9e6284748370
24/09/19 18:47:44 INFO MemoryStore: MemoryStore cleared
24/09/19 18:47:44 INFO BlockManager: BlockManager stopped
24/09/19 18:47:44 INFO Worker: Executor app-20240919184740-0002/0 finished with state KILLED exitStatus 143
24/09/19 18:47:44 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:47:44 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919184740-0002, execId=0)
24/09/19 18:47:44 INFO ExternalShuffleBlockResolver: Application app-20240919184740-0002 removed, cleanupLocalDirs = true
24/09/19 18:47:44 INFO Worker: Cleaning up local directories for application app-20240919184740-0002
24/09/19 18:49:30 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 18:49:30 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-364c64de-168a-4d1a-ac82-3676a5fceb68
24/09/19 18:50:11 INFO Worker: Started daemon with process name: 1@87736daba73c
24/09/19 18:50:11 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:50:11 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:50:11 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:50:12 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:50:12 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:50:12 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:50:12 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:50:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:50:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:50:12 INFO Utils: Successfully started service 'sparkWorker' on port 35615.
24/09/19 18:50:12 INFO Worker: Worker decommissioning not enabled.
24/09/19 18:50:12 INFO Worker: Starting Spark worker 172.21.0.4:35615 with 2 cores, 1024.0 MiB RAM
24/09/19 18:50:12 INFO Worker: Running Spark version 3.5.2
24/09/19 18:50:12 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 18:50:12 INFO ResourceUtils: ==============================================================
24/09/19 18:50:12 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 18:50:12 INFO ResourceUtils: ==============================================================
24/09/19 18:50:12 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 18:50:13 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 18:50:13 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://87736daba73c:8081
24/09/19 18:50:13 INFO Worker: Connecting to master spark-master:7077...
24/09/19 18:50:13 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.3:7077 after 26 ms (0 ms spent in bootstraps)
24/09/19 18:50:13 INFO Worker: Successfully registered with master spark://172.21.0.3:7077
24/09/19 18:53:29 INFO Worker: Asked to launch executor app-20240919185328-0000/0 for GCS to Postgres
24/09/19 18:53:29 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:53:29 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:53:29 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:53:29 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:53:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:53:29 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36491" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:36491" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919185328-0000" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 18:53:30 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 111@87736daba73c
24/09/19 18:53:30 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:53:30 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:53:30 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:53:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 18:53:30 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:53:30 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:53:30 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:53:30 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:53:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:53:31 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36491 after 59 ms (0 ms spent in bootstraps)
24/09/19 18:53:31 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 18:53:31 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 18:53:31 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:53:31 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:53:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 18:53:31 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36491 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:53:31 INFO DiskBlockManager: Created local directory at /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/blockmgr-1e9bf405-9b8e-4303-9f4a-f5d01873a715
24/09/19 18:53:31 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 18:53:31 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@91d7fe9a53b4:36491
24/09/19 18:53:31 INFO WorkerWatcher: Connecting to worker spark://Worker@172.21.0.4:35615
24/09/19 18:53:31 INFO TransportClientFactory: Successfully created connection to /172.21.0.4:35615 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:53:31 INFO WorkerWatcher: Successfully connected to spark://Worker@172.21.0.4:35615
24/09/19 18:53:31 INFO ResourceUtils: ==============================================================
24/09/19 18:53:31 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 18:53:31 INFO ResourceUtils: ==============================================================
24/09/19 18:53:31 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 18:53:31 INFO Executor: Starting executor ID 0 on host 172.21.0.4
24/09/19 18:53:31 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 18:53:31 INFO Executor: Java version 17.0.12
24/09/19 18:53:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36067.
24/09/19 18:53:31 INFO NettyBlockTransferService: Server created on 172.21.0.4:36067
24/09/19 18:53:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 18:53:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.21.0.4, 36067, None)
24/09/19 18:53:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.21.0.4, 36067, None)
24/09/19 18:53:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.21.0.4, 36067, None)
24/09/19 18:53:31 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 18:53:31 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 18:53:31 INFO Executor: Fetching spark://91d7fe9a53b4:36491/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772007606
24/09/19 18:53:31 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36491 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:53:31 INFO Utils: Fetching spark://91d7fe9a53b4:36491/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/fetchFileTemp13949550524825338947.tmp
24/09/19 18:53:31 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/19934511901726772007606_cache to /opt/bitnami/spark/work/app-20240919185328-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:53:31 INFO Executor: Fetching spark://91d7fe9a53b4:36491/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772007606
24/09/19 18:53:31 INFO Utils: Fetching spark://91d7fe9a53b4:36491/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/fetchFileTemp15294497777540496282.tmp
24/09/19 18:53:31 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/19491233341726772007606_cache to /opt/bitnami/spark/work/app-20240919185328-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:53:31 INFO Executor: Fetching spark://91d7fe9a53b4:36491/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772007606
24/09/19 18:53:31 INFO Utils: Fetching spark://91d7fe9a53b4:36491/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/fetchFileTemp9436041311371824747.tmp
24/09/19 18:53:31 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/13114971131726772007606_cache has been previously copied to /opt/bitnami/spark/work/app-20240919185328-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 18:53:31 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919185328-0000/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 18:53:32 INFO Executor: Fetching spark://91d7fe9a53b4:36491/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772007606
24/09/19 18:53:32 INFO Utils: Fetching spark://91d7fe9a53b4:36491/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/fetchFileTemp17959161414437357711.tmp
24/09/19 18:53:32 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a/3521654171726772007606_cache has been previously copied to /opt/bitnami/spark/work/app-20240919185328-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 18:53:32 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919185328-0000/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 18:53:32 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 18:53:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 18:53:32 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 18:53:32 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36151 after 2 ms (0 ms spent in bootstraps)
24/09/19 18:53:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 434.4 MiB)
24/09/19 18:53:32 INFO TorrentBroadcast: Reading broadcast variable 0 took 125 ms
24/09/19 18:53:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 18:53:32 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:53:32 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 18:53:32 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 18:53:32 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:53:32 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 18:53:32 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 18:53:32 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:53:32 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 18:53:32 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 18:53:32 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 18:53:33 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 18:53:33 INFO MemoryStore: MemoryStore cleared
24/09/19 18:53:33 INFO BlockManager: BlockManager stopped
24/09/19 18:53:33 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:36491 disconnected during shutdown
24/09/19 18:53:33 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:36491 disconnected during shutdown
24/09/19 18:53:33 INFO Worker: Asked to kill executor app-20240919185328-0000/0
24/09/19 18:53:33 INFO ShutdownHookManager: Shutdown hook called
24/09/19 18:53:33 INFO ExecutorRunner: Runner thread for executor app-20240919185328-0000/0 interrupted
24/09/19 18:53:33 INFO ExecutorRunner: Killing process!
24/09/19 18:53:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-984a522c-fe00-4377-8f9d-1b10d637c7c4/spark-b8b93de3-59d0-4cd6-927d-bc9922de2b7a
24/09/19 18:53:33 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:53:33 INFO Worker: Executor app-20240919185328-0000/0 finished with state KILLED exitStatus 0
24/09/19 18:53:33 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:53:33 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919185328-0000, execId=0)
24/09/19 18:53:33 INFO ExternalShuffleBlockResolver: Application app-20240919185328-0000 removed, cleanupLocalDirs = true
24/09/19 18:53:33 INFO Worker: Cleaning up local directories for application app-20240919185328-0000
24/09/19 18:56:44 INFO Worker: Asked to launch executor app-20240919185644-0001/0 for GCS to Postgres
24/09/19 18:56:45 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 18:56:45 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 18:56:45 INFO SecurityManager: Changing view acls groups to: 
24/09/19 18:56:45 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 18:56:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 18:56:45 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40755" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:40755" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919185644-0001" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 18:56:46 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 210@87736daba73c
24/09/19 18:56:46 INFO SignalUtils: Registering signal handler for TERM
24/09/19 18:56:46 INFO SignalUtils: Registering signal handler for HUP
24/09/19 18:56:46 INFO SignalUtils: Registering signal handler for INT
24/09/19 18:56:46 INFO Worker: Asked to kill executor app-20240919185644-0001/0
24/09/19 18:56:46 INFO ExecutorRunner: Runner thread for executor app-20240919185644-0001/0 interrupted
24/09/19 18:56:46 INFO ExecutorRunner: Killing process!
24/09/19 18:56:46 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 18:56:46 INFO Worker: Executor app-20240919185644-0001/0 finished with state KILLED exitStatus 143
24/09/19 18:56:46 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 18:56:46 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919185644-0001, execId=0)
24/09/19 18:56:46 INFO Worker: Cleaning up local directories for application app-20240919185644-0001
24/09/19 18:56:46 INFO ExternalShuffleBlockResolver: Application app-20240919185644-0001 removed, cleanupLocalDirs = true
24/09/19 19:00:02 INFO SparkContext: Running Spark version 3.5.2
24/09/19 19:00:02 INFO SparkContext: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:00:02 INFO SparkContext: Java version 17.0.12
24/09/19 19:00:02 INFO ResourceUtils: ==============================================================
24/09/19 19:00:02 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/19 19:00:02 INFO ResourceUtils: ==============================================================
24/09/19 19:00:02 INFO SparkContext: Submitted application: GCS to Postgres
24/09/19 19:00:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/19 19:00:03 INFO ResourceProfile: Limiting resource is cpu
24/09/19 19:00:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/19 19:00:03 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:00:03 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:00:03 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:00:03 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:00:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:00:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:00:03 INFO Utils: Successfully started service 'sparkDriver' on port 46677.
24/09/19 19:00:03 INFO SparkEnv: Registering MapOutputTracker
24/09/19 19:00:03 INFO SparkEnv: Registering BlockManagerMaster
24/09/19 19:00:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/19 19:00:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/19 19:00:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/19 19:00:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c3db49c-a2c0-48df-9d5f-a1cff6486fba
24/09/19 19:00:03 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:00:03 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/19 19:00:03 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/19 19:00:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/19 19:00:03 INFO Executor: Starting executor ID driver on host 87736daba73c
24/09/19 19:00:03 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:00:03 INFO Executor: Java version 17.0.12
24/09/19 19:00:03 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:00:03 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4bdb6412 for default.
24/09/19 19:00:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40175.
24/09/19 19:00:03 INFO NettyBlockTransferService: Server created on 87736daba73c:40175
24/09/19 19:00:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:00:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 87736daba73c, 40175, None)
24/09/19 19:00:03 INFO BlockManagerMasterEndpoint: Registering block manager 87736daba73c:40175 with 434.4 MiB RAM, BlockManagerId(driver, 87736daba73c, 40175, None)
24/09/19 19:00:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 87736daba73c, 40175, None)
24/09/19 19:00:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 87736daba73c, 40175, None)
24/09/19 19:00:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/09/19 19:00:04 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
24/09/19 19:00:04 INFO InMemoryFileIndex: It took 44 ms to list leaf files for 1 paths.
24/09/19 19:00:05 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
24/09/19 19:00:05 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/19 19:00:05 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
24/09/19 19:00:05 INFO DAGScheduler: Parents of final stage: List()
24/09/19 19:00:05 INFO DAGScheduler: Missing parents: List()
24/09/19 19:00:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/19 19:00:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.3 KiB, free 434.3 MiB)
24/09/19 19:00:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
24/09/19 19:00:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 87736daba73c:40175 (size: 37.2 KiB, free: 434.4 MiB)
24/09/19 19:00:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/09/19 19:00:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/19 19:00:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/09/19 19:00:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (87736daba73c, executor driver, partition 0, PROCESS_LOCAL, 9147 bytes) 
24/09/19 19:00:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:00:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1742 bytes result sent to driver
24/09/19 19:00:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 318 ms on 87736daba73c (executor driver) (1/1)
24/09/19 19:00:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/09/19 19:00:05 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.499 s
24/09/19 19:00:05 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/19 19:00:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/09/19 19:00:05 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.536953 s
24/09/19 19:00:05 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 87736daba73c:40175 in memory (size: 37.2 KiB, free: 434.4 MiB)
24/09/19 19:00:06 INFO FileSourceStrategy: Pushed Filters: 
24/09/19 19:00:06 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/19 19:00:06 INFO CodeGenerator: Code generated in 162.235673 ms
24/09/19 19:00:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 201.0 KiB, free 434.2 MiB)
24/09/19 19:00:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 434.2 MiB)
24/09/19 19:00:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 87736daba73c:40175 (size: 34.9 KiB, free: 434.4 MiB)
24/09/19 19:00:06 INFO SparkContext: Created broadcast 1 from showString at NativeMethodAccessorImpl.java:0
24/09/19 19:00:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/19 19:00:06 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/19 19:00:06 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/19 19:00:06 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
24/09/19 19:00:06 INFO DAGScheduler: Parents of final stage: List()
24/09/19 19:00:06 INFO DAGScheduler: Missing parents: List()
24/09/19 19:00:06 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/19 19:00:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.8 KiB, free 434.2 MiB)
24/09/19 19:00:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)
24/09/19 19:00:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 87736daba73c:40175 (size: 6.4 KiB, free: 434.4 MiB)
24/09/19 19:00:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/09/19 19:00:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/19 19:00:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/09/19 19:00:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (87736daba73c, executor driver, partition 0, PROCESS_LOCAL, 9617 bytes) 
24/09/19 19:00:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:00:06 INFO CodeGenerator: Code generated in 20.259968 ms
24/09/19 19:00:06 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/jobs/python/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:00:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1989 bytes result sent to driver
24/09/19 19:00:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 256 ms on 87736daba73c (executor driver) (1/1)
24/09/19 19:00:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/09/19 19:00:07 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.293 s
24/09/19 19:00:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/19 19:00:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/09/19 19:00:07 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.302322 s
24/09/19 19:00:07 INFO CodeGenerator: Code generated in 16.523902 ms
24/09/19 19:00:07 INFO SparkContext: Invoking stop() from shutdown hook
24/09/19 19:00:07 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/09/19 19:00:07 INFO SparkUI: Stopped Spark web UI at http://87736daba73c:4040
24/09/19 19:00:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/09/19 19:00:07 INFO MemoryStore: MemoryStore cleared
24/09/19 19:00:07 INFO BlockManager: BlockManager stopped
24/09/19 19:00:07 INFO BlockManagerMaster: BlockManagerMaster stopped
24/09/19 19:00:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/09/19 19:00:07 INFO SparkContext: Successfully stopped SparkContext
24/09/19 19:00:07 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-2170eaa8-840a-4e4b-ad71-f13da8ce93fd
24/09/19 19:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5e54adb-1296-49c0-bb5c-826ecf48e389
24/09/19 19:00:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-2170eaa8-840a-4e4b-ad71-f13da8ce93fd/pyspark-bf76c324-1c4a-435e-ac7e-af069199d971
24/09/19 19:01:36 INFO Worker: Asked to launch executor app-20240919190136-0002/0 for Postgres to Postgres
24/09/19 19:01:36 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:01:36 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:01:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:01:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:01:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:01:36 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36327" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:36327" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919190136-0002" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:01:37 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 437@87736daba73c
24/09/19 19:01:37 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:01:37 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:01:37 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:01:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:01:37 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:01:37 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:01:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:01:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:01:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:01:38 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36327 after 54 ms (0 ms spent in bootstraps)
24/09/19 19:01:38 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:01:38 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:01:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:01:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:01:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:01:38 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36327 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:01:38 INFO DiskBlockManager: Created local directory at /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/blockmgr-304eccd8-c95e-497e-b81a-f334bde0063b
24/09/19 19:01:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:01:38 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@91d7fe9a53b4:36327
24/09/19 19:01:38 INFO WorkerWatcher: Connecting to worker spark://Worker@172.21.0.4:35615
24/09/19 19:01:38 INFO TransportClientFactory: Successfully created connection to /172.21.0.4:35615 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:01:38 INFO WorkerWatcher: Successfully connected to spark://Worker@172.21.0.4:35615
24/09/19 19:01:38 INFO ResourceUtils: ==============================================================
24/09/19 19:01:38 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:01:38 INFO ResourceUtils: ==============================================================
24/09/19 19:01:38 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:01:38 INFO Executor: Starting executor ID 0 on host 172.21.0.4
24/09/19 19:01:38 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:01:38 INFO Executor: Java version 17.0.12
24/09/19 19:01:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34637.
24/09/19 19:01:38 INFO NettyBlockTransferService: Server created on 172.21.0.4:34637
24/09/19 19:01:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:01:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.21.0.4, 34637, None)
24/09/19 19:01:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.21.0.4, 34637, None)
24/09/19 19:01:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.21.0.4, 34637, None)
24/09/19 19:01:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:01:38 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@355523d2 for default.
24/09/19 19:01:38 INFO Executor: Fetching spark://91d7fe9a53b4:36327/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772495551
24/09/19 19:01:38 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:36327 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:01:38 INFO Utils: Fetching spark://91d7fe9a53b4:36327/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/fetchFileTemp17816421370148755134.tmp
24/09/19 19:01:38 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/-19428279181726772495551_cache to /opt/bitnami/spark/work/app-20240919190136-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:01:38 INFO Executor: Fetching spark://91d7fe9a53b4:36327/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772495551
24/09/19 19:01:38 INFO Utils: Fetching spark://91d7fe9a53b4:36327/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/fetchFileTemp17014278853720359364.tmp
24/09/19 19:01:38 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/10389706581726772495551_cache to /opt/bitnami/spark/work/app-20240919190136-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:01:38 INFO Executor: Fetching spark://91d7fe9a53b4:36327/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772495551
24/09/19 19:01:38 INFO Utils: Fetching spark://91d7fe9a53b4:36327/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/fetchFileTemp6909766188506665906.tmp
24/09/19 19:01:38 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/-2433132351726772495551_cache has been previously copied to /opt/bitnami/spark/work/app-20240919190136-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:01:38 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919190136-0002/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:01:38 INFO Executor: Fetching spark://91d7fe9a53b4:36327/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772495551
24/09/19 19:01:38 INFO Utils: Fetching spark://91d7fe9a53b4:36327/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/fetchFileTemp8403107265065561794.tmp
24/09/19 19:01:39 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037/-12974020511726772495551_cache has been previously copied to /opt/bitnami/spark/work/app-20240919190136-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:01:39 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919190136-0002/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:01:41 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:01:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:01:41 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:01:41 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:45949 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:01:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 19:01:41 INFO TorrentBroadcast: Reading broadcast variable 0 took 81 ms
24/09/19 19:01:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 19:01:44 INFO CodeGenerator: Code generated in 146.884744 ms
24/09/19 19:01:44 INFO JDBCRDD: closed connection
24/09/19 19:01:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 19:01:45 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:01:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:01:45 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:01:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 434.4 MiB)
24/09/19 19:01:45 INFO TorrentBroadcast: Reading broadcast variable 1 took 17 ms
24/09/19 19:01:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 22.3 KiB, free 434.4 MiB)
24/09/19 19:01:47 INFO CodeGenerator: Code generated in 14.670589 ms
24/09/19 19:01:48 INFO CodeGenerator: Code generated in 32.576828 ms
24/09/19 19:01:48 INFO JDBCRDD: closed connection
24/09/19 19:01:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1359 bytes result sent to driver
24/09/19 19:01:48 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:01:48 INFO Worker: Asked to kill executor app-20240919190136-0002/0
24/09/19 19:01:48 INFO ExecutorRunner: Runner thread for executor app-20240919190136-0002/0 interrupted
24/09/19 19:01:48 INFO ExecutorRunner: Killing process!
24/09/19 19:01:48 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:01:48 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:01:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-ae43c216-8a1b-4ae9-81ad-6f63890d5cdd/spark-b3f92d40-3530-4830-9aad-3c0563e1c037
24/09/19 19:01:48 INFO MemoryStore: MemoryStore cleared
24/09/19 19:01:48 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:36327 disconnected during shutdown
24/09/19 19:01:48 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:36327 disconnected during shutdown
24/09/19 19:01:48 INFO BlockManager: BlockManager stopped
24/09/19 19:01:48 INFO Worker: Executor app-20240919190136-0002/0 finished with state KILLED exitStatus 143
24/09/19 19:01:48 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:01:48 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919190136-0002, execId=0)
24/09/19 19:01:48 INFO ExternalShuffleBlockResolver: Application app-20240919190136-0002 removed, cleanupLocalDirs = true
24/09/19 19:01:48 INFO Worker: Cleaning up local directories for application app-20240919190136-0002
24/09/19 19:02:03 INFO Worker: Asked to launch executor app-20240919190203-0003/0 for Escrita no banco Postgres
24/09/19 19:02:03 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:02:03 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:02:03 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:02:03 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:02:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:02:03 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44443" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:44443" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919190203-0003" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:02:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 555@87736daba73c
24/09/19 19:02:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:02:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:02:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:02:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:02:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:02:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:02:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:02:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:02:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:02:05 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:44443 after 44 ms (0 ms spent in bootstraps)
24/09/19 19:02:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:02:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:02:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:02:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:02:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:02:05 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:44443 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:02:05 INFO DiskBlockManager: Created local directory at /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/blockmgr-000e5a50-3f8d-4a99-8334-5e89921c439c
24/09/19 19:02:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:02:06 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@91d7fe9a53b4:44443
24/09/19 19:02:06 INFO WorkerWatcher: Connecting to worker spark://Worker@172.21.0.4:35615
24/09/19 19:02:06 INFO TransportClientFactory: Successfully created connection to /172.21.0.4:35615 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:02:06 INFO WorkerWatcher: Successfully connected to spark://Worker@172.21.0.4:35615
24/09/19 19:02:06 INFO ResourceUtils: ==============================================================
24/09/19 19:02:06 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:02:06 INFO ResourceUtils: ==============================================================
24/09/19 19:02:06 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:02:06 INFO Executor: Starting executor ID 0 on host 172.21.0.4
24/09/19 19:02:06 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:02:06 INFO Executor: Java version 17.0.12
24/09/19 19:02:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38281.
24/09/19 19:02:06 INFO NettyBlockTransferService: Server created on 172.21.0.4:38281
24/09/19 19:02:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:02:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.21.0.4, 38281, None)
24/09/19 19:02:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.21.0.4, 38281, None)
24/09/19 19:02:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.21.0.4, 38281, None)
24/09/19 19:02:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:02:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@b16db59 for default.
24/09/19 19:02:06 INFO Executor: Fetching spark://91d7fe9a53b4:44443/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772523135
24/09/19 19:02:06 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:44443 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:02:06 INFO Utils: Fetching spark://91d7fe9a53b4:44443/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/fetchFileTemp16878665635524929528.tmp
24/09/19 19:02:06 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/2313560001726772523135_cache to /opt/bitnami/spark/work/app-20240919190203-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:02:06 INFO Executor: Fetching spark://91d7fe9a53b4:44443/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772523135
24/09/19 19:02:06 INFO Utils: Fetching spark://91d7fe9a53b4:44443/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/fetchFileTemp7258065721032670258.tmp
24/09/19 19:02:06 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/-17775098401726772523135_cache to /opt/bitnami/spark/work/app-20240919190203-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:02:06 INFO Executor: Fetching spark://91d7fe9a53b4:44443/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726772523135
24/09/19 19:02:06 INFO Utils: Fetching spark://91d7fe9a53b4:44443/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/fetchFileTemp970669021323412914.tmp
24/09/19 19:02:06 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/-5464599851726772523135_cache has been previously copied to /opt/bitnami/spark/work/app-20240919190203-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:02:06 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919190203-0003/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:02:06 INFO Executor: Fetching spark://91d7fe9a53b4:44443/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726772523135
24/09/19 19:02:06 INFO Utils: Fetching spark://91d7fe9a53b4:44443/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/fetchFileTemp3741400750644263362.tmp
24/09/19 19:02:06 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59/-4607852171726772523135_cache has been previously copied to /opt/bitnami/spark/work/app-20240919190203-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:02:06 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919190203-0003/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:02:32 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:02:32 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:02:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 19:02:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:02:32 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:02:32 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:44133 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:02:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.4 MiB)
24/09/19 19:02:33 INFO TorrentBroadcast: Reading broadcast variable 0 took 79 ms
24/09/19 19:02:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 29.9 KiB, free 434.4 MiB)
24/09/19 19:02:34 INFO CodeGenerator: Code generated in 163.419469 ms
24/09/19 19:02:35 INFO CodeGenerator: Code generated in 21.705322 ms
24/09/19 19:02:35 INFO PythonRunner: Times: total = 566, boot = 466, init = 100, finish = 0
24/09/19 19:02:35 INFO PythonRunner: Times: total = 567, boot = 463, init = 104, finish = 0
24/09/19 19:02:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 19:02:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 19:02:35 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:02:35 INFO Worker: Asked to kill executor app-20240919190203-0003/0
24/09/19 19:02:35 INFO ExecutorRunner: Runner thread for executor app-20240919190203-0003/0 interrupted
24/09/19 19:02:35 INFO ExecutorRunner: Killing process!
24/09/19 19:02:35 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:02:35 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:02:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-944f7bb8-2412-4b8a-98ad-8bf5a992a75d/spark-8a170c09-a547-4a14-8711-8567e84a3f59
24/09/19 19:02:35 INFO MemoryStore: MemoryStore cleared
24/09/19 19:02:35 INFO BlockManager: BlockManager stopped
24/09/19 19:02:35 INFO Worker: Executor app-20240919190203-0003/0 finished with state KILLED exitStatus 143
24/09/19 19:02:35 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:02:35 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919190203-0003, execId=0)
24/09/19 19:02:35 INFO ExternalShuffleBlockResolver: Application app-20240919190203-0003 removed, cleanupLocalDirs = true
24/09/19 19:02:35 INFO Worker: Cleaning up local directories for application app-20240919190203-0003
24/09/19 19:03:16 INFO Worker: Asked to launch executor app-20240919190316-0004/0 for GCS to Postgres
24/09/19 19:03:16 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:03:16 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:03:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:03:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:03:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:03:16 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40767" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:40767" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919190316-0004" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:03:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 677@87736daba73c
24/09/19 19:03:17 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:03:17 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:03:17 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:03:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:03:17 INFO Worker: Asked to kill executor app-20240919190316-0004/0
24/09/19 19:03:17 INFO ExecutorRunner: Runner thread for executor app-20240919190316-0004/0 interrupted
24/09/19 19:03:17 INFO ExecutorRunner: Killing process!
24/09/19 19:03:17 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:03:18 INFO Worker: Executor app-20240919190316-0004/0 finished with state KILLED exitStatus 143
24/09/19 19:03:18 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:03:18 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919190316-0004, execId=0)
24/09/19 19:03:18 INFO ExternalShuffleBlockResolver: Application app-20240919190316-0004 removed, cleanupLocalDirs = true
24/09/19 19:03:18 INFO Worker: Cleaning up local directories for application app-20240919190316-0004
24/09/19 19:10:02 INFO Worker: Asked to launch executor app-20240919191002-0005/0 for Postgres to Postgres
24/09/19 19:10:02 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:10:02 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:10:02 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:10:02 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:10:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:10:02 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34333" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:34333" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919191002-0005" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:10:03 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 720@87736daba73c
24/09/19 19:10:03 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:10:03 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:10:03 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:10:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:10:04 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:10:04 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:10:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:10:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:10:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:10:04 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34333 after 40 ms (0 ms spent in bootstraps)
24/09/19 19:10:04 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:10:04 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:10:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:10:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:10:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:10:04 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34333 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:10:04 INFO DiskBlockManager: Created local directory at /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/blockmgr-43f563bc-2d7c-4c98-900a-abd8e5eb2f97
24/09/19 19:10:04 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:10:04 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@91d7fe9a53b4:34333
24/09/19 19:10:04 INFO WorkerWatcher: Connecting to worker spark://Worker@172.21.0.4:35615
24/09/19 19:10:04 INFO TransportClientFactory: Successfully created connection to /172.21.0.4:35615 after 10 ms (0 ms spent in bootstraps)
24/09/19 19:10:04 INFO WorkerWatcher: Successfully connected to spark://Worker@172.21.0.4:35615
24/09/19 19:10:04 INFO ResourceUtils: ==============================================================
24/09/19 19:10:04 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:10:04 INFO ResourceUtils: ==============================================================
24/09/19 19:10:05 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:10:05 INFO Executor: Starting executor ID 0 on host 172.21.0.4
24/09/19 19:10:05 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:10:05 INFO Executor: Java version 17.0.12
24/09/19 19:10:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44307.
24/09/19 19:10:05 INFO NettyBlockTransferService: Server created on 172.21.0.4:44307
24/09/19 19:10:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:10:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.21.0.4, 44307, None)
24/09/19 19:10:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.21.0.4, 44307, None)
24/09/19 19:10:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.21.0.4, 44307, None)
24/09/19 19:10:05 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:10:05 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@42f90c0d for default.
24/09/19 19:10:05 INFO Executor: Fetching spark://91d7fe9a53b4:34333/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726773001961
24/09/19 19:10:05 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34333 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:10:05 INFO Utils: Fetching spark://91d7fe9a53b4:34333/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/fetchFileTemp2265607247834865165.tmp
24/09/19 19:10:05 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/17376246551726773001961_cache to /opt/bitnami/spark/work/app-20240919191002-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:10:05 INFO Executor: Fetching spark://91d7fe9a53b4:34333/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726773001961
24/09/19 19:10:05 INFO Utils: Fetching spark://91d7fe9a53b4:34333/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/fetchFileTemp17649400278585778437.tmp
24/09/19 19:10:05 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/6943265911726773001961_cache to /opt/bitnami/spark/work/app-20240919191002-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:10:05 INFO Executor: Fetching spark://91d7fe9a53b4:34333/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726773001961
24/09/19 19:10:05 INFO Utils: Fetching spark://91d7fe9a53b4:34333/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/fetchFileTemp7522366508107882594.tmp
24/09/19 19:10:05 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/14537215361726773001961_cache has been previously copied to /opt/bitnami/spark/work/app-20240919191002-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:10:05 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919191002-0005/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:10:05 INFO Executor: Fetching spark://91d7fe9a53b4:34333/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726773001961
24/09/19 19:10:05 INFO Utils: Fetching spark://91d7fe9a53b4:34333/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/fetchFileTemp2596485337171066516.tmp
24/09/19 19:10:05 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef/14081372001726773001961_cache has been previously copied to /opt/bitnami/spark/work/app-20240919191002-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:10:05 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919191002-0005/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:10:07 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:10:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:10:07 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:10:07 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:33645 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:10:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 19:10:07 INFO TorrentBroadcast: Reading broadcast variable 0 took 89 ms
24/09/19 19:10:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 19:10:10 INFO CodeGenerator: Code generated in 151.195472 ms
24/09/19 19:10:10 INFO JDBCRDD: closed connection
24/09/19 19:10:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 19:10:11 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:10:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:10:11 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:10:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 434.4 MiB)
24/09/19 19:10:11 INFO TorrentBroadcast: Reading broadcast variable 1 took 16 ms
24/09/19 19:10:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 22.3 KiB, free 434.4 MiB)
24/09/19 19:10:13 INFO CodeGenerator: Code generated in 12.871919 ms
24/09/19 19:10:13 INFO CodeGenerator: Code generated in 26.035064 ms
24/09/19 19:10:14 INFO JDBCRDD: closed connection
24/09/19 19:10:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1359 bytes result sent to driver
24/09/19 19:10:14 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:10:14 INFO Worker: Asked to kill executor app-20240919191002-0005/0
24/09/19 19:10:14 INFO ExecutorRunner: Runner thread for executor app-20240919191002-0005/0 interrupted
24/09/19 19:10:14 INFO ExecutorRunner: Killing process!
24/09/19 19:10:14 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:10:14 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:10:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-1a3ad491-b948-464c-bf1b-057c46cdcb04/spark-446e3cb3-3531-47a6-aa40-68f24d0bc3ef
24/09/19 19:10:14 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:34333 disconnected during shutdown
24/09/19 19:10:14 INFO CoarseGrainedExecutorBackend: Driver from 91d7fe9a53b4:34333 disconnected during shutdown
24/09/19 19:10:14 INFO MemoryStore: MemoryStore cleared
24/09/19 19:10:14 INFO BlockManager: BlockManager stopped
24/09/19 19:10:14 INFO Worker: Executor app-20240919191002-0005/0 finished with state KILLED exitStatus 143
24/09/19 19:10:14 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:10:14 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919191002-0005, execId=0)
24/09/19 19:10:14 INFO ExternalShuffleBlockResolver: Application app-20240919191002-0005 removed, cleanupLocalDirs = true
24/09/19 19:10:14 INFO Worker: Cleaning up local directories for application app-20240919191002-0005
24/09/19 19:12:21 INFO Worker: Asked to launch executor app-20240919191221-0006/0 for GCS to Postgres
24/09/19 19:12:21 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:12:21 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:12:21 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:12:21 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:12:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:12:21 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38817" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:38817" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919191221-0006" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:12:22 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 836@87736daba73c
24/09/19 19:12:22 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:12:22 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:12:22 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:12:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:12:23 INFO Worker: Asked to kill executor app-20240919191221-0006/0
24/09/19 19:12:23 INFO ExecutorRunner: Runner thread for executor app-20240919191221-0006/0 interrupted
24/09/19 19:12:23 INFO ExecutorRunner: Killing process!
24/09/19 19:12:23 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:12:23 INFO Worker: Executor app-20240919191221-0006/0 finished with state KILLED exitStatus 143
24/09/19 19:12:23 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:12:23 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919191221-0006, execId=0)
24/09/19 19:12:23 INFO Worker: Cleaning up local directories for application app-20240919191221-0006
24/09/19 19:12:23 INFO ExternalShuffleBlockResolver: Application app-20240919191221-0006 removed, cleanupLocalDirs = true
24/09/19 19:14:14 INFO Worker: Asked to launch executor app-20240919191414-0007/0 for GCS to Postgres
24/09/19 19:14:14 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:14:14 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:14:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:14:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:14:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:14:14 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34507" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:34507" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919191414-0007" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:14:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 882@87736daba73c
24/09/19 19:14:17 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:14:17 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:14:17 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:14:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:14:18 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:14:18 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:14:18 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:14:18 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:14:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:14:18 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34507 after 55 ms (0 ms spent in bootstraps)
24/09/19 19:14:18 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:14:18 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:14:18 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:14:18 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:14:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:14:18 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34507 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:14:18 INFO DiskBlockManager: Created local directory at /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/blockmgr-e67dceee-552a-4610-8ffe-1590f8720ae2
24/09/19 19:14:19 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:14:19 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@91d7fe9a53b4:34507
24/09/19 19:14:19 INFO WorkerWatcher: Connecting to worker spark://Worker@172.21.0.4:35615
24/09/19 19:14:19 INFO TransportClientFactory: Successfully created connection to /172.21.0.4:35615 after 3 ms (0 ms spent in bootstraps)
24/09/19 19:14:19 INFO WorkerWatcher: Successfully connected to spark://Worker@172.21.0.4:35615
24/09/19 19:14:19 INFO ResourceUtils: ==============================================================
24/09/19 19:14:19 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:14:19 INFO ResourceUtils: ==============================================================
24/09/19 19:14:19 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:14:19 INFO Executor: Starting executor ID 0 on host 172.21.0.4
24/09/19 19:14:19 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:14:19 INFO Executor: Java version 17.0.12
24/09/19 19:14:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42613.
24/09/19 19:14:19 INFO NettyBlockTransferService: Server created on 172.21.0.4:42613
24/09/19 19:14:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:14:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.21.0.4, 42613, None)
24/09/19 19:14:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.21.0.4, 42613, None)
24/09/19 19:14:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.21.0.4, 42613, None)
24/09/19 19:14:19 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:14:19 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@300f28ca for default.
24/09/19 19:14:19 INFO Executor: Fetching spark://91d7fe9a53b4:34507/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726773253780
24/09/19 19:14:19 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:34507 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:14:19 INFO Utils: Fetching spark://91d7fe9a53b4:34507/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/fetchFileTemp2104972629240234557.tmp
24/09/19 19:14:19 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/-9314877041726773253780_cache to /opt/bitnami/spark/work/app-20240919191414-0007/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:14:19 INFO Executor: Fetching spark://91d7fe9a53b4:34507/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726773253780
24/09/19 19:14:19 INFO Utils: Fetching spark://91d7fe9a53b4:34507/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/fetchFileTemp2292181036429124786.tmp
24/09/19 19:14:19 INFO Utils: Copying /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/-18683837521726773253780_cache to /opt/bitnami/spark/work/app-20240919191414-0007/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:14:19 INFO Executor: Fetching spark://91d7fe9a53b4:34507/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726773253780
24/09/19 19:14:19 INFO Utils: Fetching spark://91d7fe9a53b4:34507/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/fetchFileTemp4254349654395241989.tmp
24/09/19 19:14:19 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/904726951726773253780_cache has been previously copied to /opt/bitnami/spark/work/app-20240919191414-0007/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:14:19 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919191414-0007/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:14:19 INFO Executor: Fetching spark://91d7fe9a53b4:34507/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726773253780
24/09/19 19:14:19 INFO Utils: Fetching spark://91d7fe9a53b4:34507/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/fetchFileTemp3386581816891603714.tmp
24/09/19 19:14:19 INFO Utils: /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63/-14152550651726773253780_cache has been previously copied to /opt/bitnami/spark/work/app-20240919191414-0007/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:14:19 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919191414-0007/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:14:19 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:14:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:14:19 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:14:19 INFO TransportClientFactory: Successfully created connection to 91d7fe9a53b4/172.21.0.5:39045 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:14:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 434.4 MiB)
24/09/19 19:14:19 INFO TorrentBroadcast: Reading broadcast variable 0 took 96 ms
24/09/19 19:14:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 19:14:20 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 19:14:20 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:14:20 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 19:14:20 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 19:14:20 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 19:14:20 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 19:14:20 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 19:14:20 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 19:14:20 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 19:14:20 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.util.ThreadUtils$.parmap(ThreadUtils.scala:387)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readParquetFootersInParallel(ParquetFileFormat.scala:443)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:485)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:80)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.FileNotFoundException: File file:/opt/airflow/jobs/python/categoria.parquet does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:160)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)
	at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:69)
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:796)
	at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:450)
	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:384)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1395)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
24/09/19 19:14:21 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:14:21 INFO Worker: Asked to kill executor app-20240919191414-0007/0
24/09/19 19:14:21 INFO ExecutorRunner: Runner thread for executor app-20240919191414-0007/0 interrupted
24/09/19 19:14:21 INFO ExecutorRunner: Killing process!
24/09/19 19:14:21 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:14:21 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:14:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129/executor-fdb17225-b9a6-4ce2-b842-baa95a496bf9/spark-d73a99ec-b905-40c2-82ef-62c369756a63
24/09/19 19:14:21 INFO MemoryStore: MemoryStore cleared
24/09/19 19:14:21 INFO BlockManager: BlockManager stopped
24/09/19 19:14:21 INFO Worker: Executor app-20240919191414-0007/0 finished with state KILLED exitStatus 143
24/09/19 19:14:21 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:14:21 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919191414-0007, execId=0)
24/09/19 19:14:21 INFO ExternalShuffleBlockResolver: Application app-20240919191414-0007 removed, cleanupLocalDirs = true
24/09/19 19:14:21 INFO Worker: Cleaning up local directories for application app-20240919191414-0007
24/09/19 19:18:54 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:18:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-6a64af73-612f-4fb2-8ce6-bcd7e4bae1b0
24/09/19 19:19:42 INFO SparkContext: Running Spark version 3.5.2
24/09/19 19:19:42 INFO SparkContext: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:19:42 INFO SparkContext: Java version 17.0.12
24/09/19 19:19:42 INFO ResourceUtils: ==============================================================
24/09/19 19:19:42 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/19 19:19:42 INFO ResourceUtils: ==============================================================
24/09/19 19:19:42 INFO SparkContext: Submitted application: GCS to Postgres
24/09/19 19:19:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/19 19:19:42 INFO ResourceProfile: Limiting resource is cpu
24/09/19 19:19:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/19 19:19:42 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:19:42 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:19:42 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:19:42 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:19:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:19:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:19:42 INFO Utils: Successfully started service 'sparkDriver' on port 46273.
24/09/19 19:19:42 INFO SparkEnv: Registering MapOutputTracker
24/09/19 19:19:42 INFO SparkEnv: Registering BlockManagerMaster
24/09/19 19:19:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/19 19:19:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/19 19:19:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/19 19:19:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5bad900d-3dcd-4509-91c5-5dcfca4238b1
24/09/19 19:19:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:19:42 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/19 19:19:42 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/19 19:19:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/19 19:19:43 INFO Executor: Starting executor ID driver on host 87736daba73c
24/09/19 19:19:43 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:19:43 INFO Executor: Java version 17.0.12
24/09/19 19:19:43 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:19:43 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4917ca55 for default.
24/09/19 19:19:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41153.
24/09/19 19:19:43 INFO NettyBlockTransferService: Server created on 87736daba73c:41153
24/09/19 19:19:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:19:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 87736daba73c, 41153, None)
24/09/19 19:19:43 INFO BlockManagerMasterEndpoint: Registering block manager 87736daba73c:41153 with 434.4 MiB RAM, BlockManagerId(driver, 87736daba73c, 41153, None)
24/09/19 19:19:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 87736daba73c, 41153, None)
24/09/19 19:19:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 87736daba73c, 41153, None)
24/09/19 19:19:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/09/19 19:19:43 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
24/09/19 19:19:44 INFO SparkContext: Invoking stop() from shutdown hook
24/09/19 19:19:44 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/09/19 19:19:44 INFO SparkUI: Stopped Spark web UI at http://87736daba73c:4040
24/09/19 19:19:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/09/19 19:19:44 INFO MemoryStore: MemoryStore cleared
24/09/19 19:19:44 INFO BlockManager: BlockManager stopped
24/09/19 19:19:44 INFO BlockManagerMaster: BlockManagerMaster stopped
24/09/19 19:19:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/09/19 19:19:44 INFO SparkContext: Successfully stopped SparkContext
24/09/19 19:19:44 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:19:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-1466377a-5815-4908-b4a3-03111cc23117/pyspark-80ac3b88-40e1-4586-9786-403f7672be0d
24/09/19 19:19:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-1466377a-5815-4908-b4a3-03111cc23117
24/09/19 19:19:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-62482c31-ca6a-41ae-85b6-aeea650fe341
24/09/19 19:20:41 INFO SparkContext: Running Spark version 3.5.2
24/09/19 19:20:41 INFO SparkContext: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:20:41 INFO SparkContext: Java version 17.0.12
24/09/19 19:20:41 INFO ResourceUtils: ==============================================================
24/09/19 19:20:41 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/19 19:20:41 INFO ResourceUtils: ==============================================================
24/09/19 19:20:41 INFO SparkContext: Submitted application: GCS to Postgres
24/09/19 19:20:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/19 19:20:41 INFO ResourceProfile: Limiting resource is cpu
24/09/19 19:20:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/19 19:20:41 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:20:41 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:20:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:20:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:20:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:20:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:20:41 INFO Utils: Successfully started service 'sparkDriver' on port 40961.
24/09/19 19:20:41 INFO SparkEnv: Registering MapOutputTracker
24/09/19 19:20:41 INFO SparkEnv: Registering BlockManagerMaster
24/09/19 19:20:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/19 19:20:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/19 19:20:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/19 19:20:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7215b4e4-560b-43f7-9673-fdc2bce03859
24/09/19 19:20:41 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:20:41 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/19 19:20:41 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/19 19:20:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/19 19:20:41 INFO Executor: Starting executor ID driver on host 87736daba73c
24/09/19 19:20:41 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:20:41 INFO Executor: Java version 17.0.12
24/09/19 19:20:41 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:20:41 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4917ca55 for default.
24/09/19 19:20:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43743.
24/09/19 19:20:41 INFO NettyBlockTransferService: Server created on 87736daba73c:43743
24/09/19 19:20:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:20:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 87736daba73c, 43743, None)
24/09/19 19:20:41 INFO BlockManagerMasterEndpoint: Registering block manager 87736daba73c:43743 with 434.4 MiB RAM, BlockManagerId(driver, 87736daba73c, 43743, None)
24/09/19 19:20:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 87736daba73c, 43743, None)
24/09/19 19:20:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 87736daba73c, 43743, None)
24/09/19 19:20:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/09/19 19:20:42 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
24/09/19 19:20:42 INFO InMemoryFileIndex: It took 57 ms to list leaf files for 1 paths.
24/09/19 19:20:43 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
24/09/19 19:20:43 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/19 19:20:43 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
24/09/19 19:20:43 INFO DAGScheduler: Parents of final stage: List()
24/09/19 19:20:43 INFO DAGScheduler: Missing parents: List()
24/09/19 19:20:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/19 19:20:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.3 KiB, free 434.3 MiB)
24/09/19 19:20:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
24/09/19 19:20:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 87736daba73c:43743 (size: 37.2 KiB, free: 434.4 MiB)
24/09/19 19:20:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/09/19 19:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/19 19:20:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/09/19 19:20:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (87736daba73c, executor driver, partition 0, PROCESS_LOCAL, 9147 bytes) 
24/09/19 19:20:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:20:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1742 bytes result sent to driver
24/09/19 19:20:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 885 ms on 87736daba73c (executor driver) (1/1)
24/09/19 19:20:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/09/19 19:20:44 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.069 s
24/09/19 19:20:44 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/19 19:20:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/09/19 19:20:44 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.139433 s
24/09/19 19:20:44 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 87736daba73c:43743 in memory (size: 37.2 KiB, free: 434.4 MiB)
24/09/19 19:20:46 INFO FileSourceStrategy: Pushed Filters: 
24/09/19 19:20:46 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/19 19:20:47 INFO CodeGenerator: Code generated in 289.321407 ms
24/09/19 19:20:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 201.0 KiB, free 434.2 MiB)
24/09/19 19:20:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 434.2 MiB)
24/09/19 19:20:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 87736daba73c:43743 (size: 34.9 KiB, free: 434.4 MiB)
24/09/19 19:20:47 INFO SparkContext: Created broadcast 1 from showString at NativeMethodAccessorImpl.java:0
24/09/19 19:20:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/19 19:20:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/19 19:20:47 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/19 19:20:47 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
24/09/19 19:20:47 INFO DAGScheduler: Parents of final stage: List()
24/09/19 19:20:47 INFO DAGScheduler: Missing parents: List()
24/09/19 19:20:47 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/19 19:20:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.8 KiB, free 434.2 MiB)
24/09/19 19:20:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)
24/09/19 19:20:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 87736daba73c:43743 (size: 6.4 KiB, free: 434.4 MiB)
24/09/19 19:20:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/09/19 19:20:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/19 19:20:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/09/19 19:20:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (87736daba73c, executor driver, partition 0, PROCESS_LOCAL, 9617 bytes) 
24/09/19 19:20:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:20:47 INFO CodeGenerator: Code generated in 20.09267 ms
24/09/19 19:20:47 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/jobs/python/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:20:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1989 bytes result sent to driver
24/09/19 19:20:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 560 ms on 87736daba73c (executor driver) (1/1)
24/09/19 19:20:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/09/19 19:20:47 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.613 s
24/09/19 19:20:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/19 19:20:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/09/19 19:20:47 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.623309 s
24/09/19 19:20:48 INFO CodeGenerator: Code generated in 14.057395 ms
24/09/19 19:20:49 INFO FileSourceStrategy: Pushed Filters: 
24/09/19 19:20:49 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/19 19:20:49 INFO CodeGenerator: Code generated in 15.542437 ms
24/09/19 19:20:49 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 201.0 KiB, free 434.0 MiB)
24/09/19 19:20:49 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.9 MiB)
24/09/19 19:20:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 87736daba73c:43743 (size: 34.9 KiB, free: 434.3 MiB)
24/09/19 19:20:49 INFO SparkContext: Created broadcast 3 from jdbc at NativeMethodAccessorImpl.java:0
24/09/19 19:20:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/19 19:20:49 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 87736daba73c:43743 in memory (size: 6.4 KiB, free: 434.3 MiB)
24/09/19 19:20:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 87736daba73c:43743 in memory (size: 34.9 KiB, free: 434.4 MiB)
24/09/19 19:20:49 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
24/09/19 19:20:49 INFO DAGScheduler: Got job 2 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/19 19:20:49 INFO DAGScheduler: Final stage: ResultStage 2 (jdbc at NativeMethodAccessorImpl.java:0)
24/09/19 19:20:49 INFO DAGScheduler: Parents of final stage: List()
24/09/19 19:20:49 INFO DAGScheduler: Missing parents: List()
24/09/19 19:20:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/19 19:20:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 31.9 KiB, free 434.1 MiB)
24/09/19 19:20:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 434.1 MiB)
24/09/19 19:20:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 87736daba73c:43743 (size: 14.2 KiB, free: 434.4 MiB)
24/09/19 19:20:49 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
24/09/19 19:20:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/19 19:20:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/09/19 19:20:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (87736daba73c, executor driver, partition 0, PROCESS_LOCAL, 9617 bytes) 
24/09/19 19:20:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 19:20:49 INFO CodeGenerator: Code generated in 18.149607 ms
24/09/19 19:20:49 INFO CodeGenerator: Code generated in 9.619755 ms
24/09/19 19:20:49 INFO FileScanRDD: Reading File path: file:///opt/bitnami/spark/jobs/python/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:20:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1757 bytes result sent to driver
24/09/19 19:20:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 160 ms on 87736daba73c (executor driver) (1/1)
24/09/19 19:20:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/09/19 19:20:49 INFO DAGScheduler: ResultStage 2 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.199 s
24/09/19 19:20:49 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/19 19:20:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/09/19 19:20:49 INFO DAGScheduler: Job 2 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.209935 s
24/09/19 19:20:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/09/19 19:20:49 INFO SparkUI: Stopped Spark web UI at http://87736daba73c:4040
24/09/19 19:20:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/09/19 19:20:49 INFO MemoryStore: MemoryStore cleared
24/09/19 19:20:49 INFO BlockManager: BlockManager stopped
24/09/19 19:20:49 INFO BlockManagerMaster: BlockManagerMaster stopped
24/09/19 19:20:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/09/19 19:20:49 INFO SparkContext: Successfully stopped SparkContext
24/09/19 19:20:50 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:20:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-11fe2329-4ead-43bf-9d4b-164d157d9270
24/09/19 19:20:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-f4a5967e-30d4-4cfd-90c2-0eaac794a662
24/09/19 19:20:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-f4a5967e-30d4-4cfd-90c2-0eaac794a662/pyspark-258904da-4e44-4e91-a33b-f5a1aac22d40
24/09/19 19:30:18 INFO Worker: Asked to launch executor app-20240919193018-0008/0 for GCS to Postgres
24/09/19 19:30:18 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:30:18 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:30:18 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:30:18 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:30:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:30:18 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36403" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:36403" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919193018-0008" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:30:20 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1432@87736daba73c
24/09/19 19:30:20 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:30:20 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:30:20 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:30:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:30:20 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:30:20 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:30:20 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:30:20 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:30:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:30:20 INFO Worker: Asked to kill executor app-20240919193018-0008/0
24/09/19 19:30:20 INFO ExecutorRunner: Runner thread for executor app-20240919193018-0008/0 interrupted
24/09/19 19:30:20 INFO ExecutorRunner: Killing process!
24/09/19 19:30:20 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:30:20 INFO Worker: Executor app-20240919193018-0008/0 finished with state KILLED exitStatus 143
24/09/19 19:30:20 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:30:20 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919193018-0008, execId=0)
24/09/19 19:30:20 INFO ExternalShuffleBlockResolver: Application app-20240919193018-0008 removed, cleanupLocalDirs = true
24/09/19 19:30:20 INFO Worker: Cleaning up local directories for application app-20240919193018-0008
24/09/19 19:36:37 INFO Worker: Asked to launch executor app-20240919193637-0009/0 for HTTPS Request with Spark
24/09/19 19:36:37 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:36:37 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:36:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:36:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:36:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:36:37 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44219" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@91d7fe9a53b4:44219" "--executor-id" "0" "--hostname" "172.21.0.4" "--cores" "2" "--app-id" "app-20240919193637-0009" "--worker-url" "spark://Worker@172.21.0.4:35615" "--resourceProfileId" "0"
24/09/19 19:36:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1480@87736daba73c
24/09/19 19:36:38 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:36:38 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:36:38 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:36:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:36:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:36:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:36:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:36:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:36:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:36:39 INFO Worker: Asked to kill executor app-20240919193637-0009/0
24/09/19 19:36:39 INFO ExecutorRunner: Runner thread for executor app-20240919193637-0009/0 interrupted
24/09/19 19:36:39 INFO ExecutorRunner: Killing process!
24/09/19 19:36:39 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:36:39 INFO Worker: Executor app-20240919193637-0009/0 finished with state KILLED exitStatus 143
24/09/19 19:36:39 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:36:39 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919193637-0009, execId=0)
24/09/19 19:36:39 INFO ExternalShuffleBlockResolver: Application app-20240919193637-0009 removed, cleanupLocalDirs = true
24/09/19 19:36:39 INFO Worker: Cleaning up local directories for application app-20240919193637-0009
24/09/19 19:39:32 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 19:39:32 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:39:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-0a7c3269-f2f5-408a-92c8-cacc2948f129
24/09/19 19:39:59 INFO Worker: Started daemon with process name: 1@81fa745d0ef3
24/09/19 19:39:59 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:39:59 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:39:59 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:39:59 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:39:59 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:39:59 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:39:59 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:39:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:39:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:39:59 INFO Utils: Successfully started service 'sparkWorker' on port 36297.
24/09/19 19:39:59 INFO Worker: Worker decommissioning not enabled.
24/09/19 19:40:00 INFO Worker: Starting Spark worker 172.22.0.4:36297 with 2 cores, 1024.0 MiB RAM
24/09/19 19:40:00 INFO Worker: Running Spark version 3.5.2
24/09/19 19:40:00 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 19:40:00 INFO ResourceUtils: ==============================================================
24/09/19 19:40:00 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 19:40:00 INFO ResourceUtils: ==============================================================
24/09/19 19:40:00 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 19:40:00 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 19:40:00 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://81fa745d0ef3:8081
24/09/19 19:40:00 INFO Worker: Connecting to master spark-master:7077...
24/09/19 19:40:00 INFO TransportClientFactory: Successfully created connection to spark-master/172.22.0.2:7077 after 30 ms (0 ms spent in bootstraps)
24/09/19 19:40:00 INFO Worker: Successfully registered with master spark://172.22.0.2:7077
24/09/19 19:43:03 INFO Worker: Asked to launch executor app-20240919194303-0000/0 for GCS to Postgres
24/09/19 19:43:03 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:43:03 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:43:03 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:43:03 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:43:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:43:03 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40659" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40659" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919194303-0000" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:43:04 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 113@81fa745d0ef3
24/09/19 19:43:04 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:43:04 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:43:04 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:43:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:43:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:43:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:43:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:43:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:43:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:43:05 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40659 after 50 ms (0 ms spent in bootstraps)
24/09/19 19:43:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:43:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:43:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:43:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:43:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:43:05 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40659 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:43:05 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/blockmgr-3dc5eca7-d961-4a0a-b69d-9d8e80209363
24/09/19 19:43:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:43:06 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40659
24/09/19 19:43:06 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:43:06 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:43:06 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:43:06 INFO ResourceUtils: ==============================================================
24/09/19 19:43:06 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:43:06 INFO ResourceUtils: ==============================================================
24/09/19 19:43:06 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:43:06 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:43:06 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:43:06 INFO Executor: Java version 17.0.12
24/09/19 19:43:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39763.
24/09/19 19:43:06 INFO NettyBlockTransferService: Server created on 172.22.0.4:39763
24/09/19 19:43:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:43:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 39763, None)
24/09/19 19:43:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 39763, None)
24/09/19 19:43:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 39763, None)
24/09/19 19:43:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:43:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@52cc8023 for default.
24/09/19 19:43:06 INFO Executor: Fetching spark://dc42800f0e25:40659/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726774982269
24/09/19 19:43:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40659 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:43:06 INFO Utils: Fetching spark://dc42800f0e25:40659/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/fetchFileTemp650373327970429594.tmp
24/09/19 19:43:06 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/19134853241726774982269_cache to /opt/bitnami/spark/work/app-20240919194303-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:43:06 INFO Executor: Fetching spark://dc42800f0e25:40659/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726774982269
24/09/19 19:43:06 INFO Utils: Fetching spark://dc42800f0e25:40659/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/fetchFileTemp10296630415122546476.tmp
24/09/19 19:43:06 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/9331212441726774982269_cache to /opt/bitnami/spark/work/app-20240919194303-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:43:06 INFO Executor: Fetching spark://dc42800f0e25:40659/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726774982269
24/09/19 19:43:06 INFO Utils: Fetching spark://dc42800f0e25:40659/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/fetchFileTemp1914891590550182974.tmp
24/09/19 19:43:06 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/-7692924131726774982269_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194303-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:43:06 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194303-0000/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:43:06 INFO Executor: Fetching spark://dc42800f0e25:40659/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726774982269
24/09/19 19:43:06 INFO Utils: Fetching spark://dc42800f0e25:40659/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/fetchFileTemp1829623676620050927.tmp
24/09/19 19:43:06 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d/-7889875011726774982269_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194303-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:43:06 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194303-0000/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:43:06 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:43:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:43:06 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:43:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45081 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:43:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 434.4 MiB)
24/09/19 19:43:06 INFO TorrentBroadcast: Reading broadcast variable 0 took 125 ms
24/09/19 19:43:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 19:43:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1785 bytes result sent to driver
24/09/19 19:43:09 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:43:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:43:09 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:43:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 434.4 MiB)
24/09/19 19:43:09 INFO TorrentBroadcast: Reading broadcast variable 2 took 19 ms
24/09/19 19:43:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.8 KiB, free 434.4 MiB)
24/09/19 19:43:09 INFO CodeGenerator: Code generated in 247.60988 ms
24/09/19 19:43:11 INFO CodeGenerator: Code generated in 17.750749 ms
24/09/19 19:43:11 INFO FileScanRDD: Reading File path: file:///opt/data/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:43:11 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:43:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.3 MiB)
24/09/19 19:43:11 INFO TorrentBroadcast: Reading broadcast variable 1 took 13 ms
24/09/19 19:43:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 373.4 KiB, free 434.0 MiB)
24/09/19 19:43:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1843 bytes result sent to driver
24/09/19 19:43:11 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:43:11 INFO Worker: Asked to kill executor app-20240919194303-0000/0
24/09/19 19:43:11 INFO ExecutorRunner: Runner thread for executor app-20240919194303-0000/0 interrupted
24/09/19 19:43:11 INFO ExecutorRunner: Killing process!
24/09/19 19:43:11 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:43:11 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:43:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-bf58b522-ae20-4b58-a58b-02e13fa47f5f/spark-33d9e7fd-4905-4ac3-9ac2-0a5355f7ec1d
24/09/19 19:43:11 WARN Dispatcher: Message RemoteProcessDisconnected(dc42800f0e25:40659) dropped. Could not find BlockManagerEndpoint1.
24/09/19 19:43:11 INFO MemoryStore: MemoryStore cleared
24/09/19 19:43:11 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40659 disconnected during shutdown
24/09/19 19:43:11 INFO BlockManager: BlockManager stopped
24/09/19 19:43:11 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40659 disconnected during shutdown
24/09/19 19:43:11 INFO Worker: Executor app-20240919194303-0000/0 finished with state KILLED exitStatus 143
24/09/19 19:43:11 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:43:11 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919194303-0000, execId=0)
24/09/19 19:43:11 INFO ExternalShuffleBlockResolver: Application app-20240919194303-0000 removed, cleanupLocalDirs = true
24/09/19 19:43:11 INFO Worker: Cleaning up local directories for application app-20240919194303-0000
24/09/19 19:44:17 INFO Worker: Asked to launch executor app-20240919194417-0001/0 for Postgres to Postgres
24/09/19 19:44:17 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:44:17 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:44:17 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:17 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:44:17 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34541" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:34541" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919194417-0001" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:44:20 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 209@81fa745d0ef3
24/09/19 19:44:20 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:44:20 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:44:20 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:44:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:44:20 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:44:20 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:44:20 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:20 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:44:21 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34541 after 73 ms (0 ms spent in bootstraps)
24/09/19 19:44:21 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:44:21 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:44:21 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:21 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:44:21 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34541 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:44:21 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/blockmgr-f9410707-93a3-4d48-a822-a9dfaa339e69
24/09/19 19:44:21 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:44:21 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:34541
24/09/19 19:44:21 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:44:21 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:44:21 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:44:21 INFO ResourceUtils: ==============================================================
24/09/19 19:44:21 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:44:21 INFO ResourceUtils: ==============================================================
24/09/19 19:44:22 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:44:22 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:44:22 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:44:22 INFO Executor: Java version 17.0.12
24/09/19 19:44:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42465.
24/09/19 19:44:22 INFO NettyBlockTransferService: Server created on 172.22.0.4:42465
24/09/19 19:44:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:44:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 42465, None)
24/09/19 19:44:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 42465, None)
24/09/19 19:44:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 42465, None)
24/09/19 19:44:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:44:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@42f90c0d for default.
24/09/19 19:44:22 INFO Executor: Fetching spark://dc42800f0e25:34541/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775056316
24/09/19 19:44:22 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34541 after 3 ms (0 ms spent in bootstraps)
24/09/19 19:44:22 INFO Utils: Fetching spark://dc42800f0e25:34541/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/fetchFileTemp6939737885285904635.tmp
24/09/19 19:44:22 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/-6420635211726775056316_cache to /opt/bitnami/spark/work/app-20240919194417-0001/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:44:22 INFO Executor: Fetching spark://dc42800f0e25:34541/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775056316
24/09/19 19:44:22 INFO Utils: Fetching spark://dc42800f0e25:34541/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/fetchFileTemp1209300693748192689.tmp
24/09/19 19:44:22 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/4576671831726775056316_cache to /opt/bitnami/spark/work/app-20240919194417-0001/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:44:22 INFO Executor: Fetching spark://dc42800f0e25:34541/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775056316
24/09/19 19:44:22 INFO Utils: Fetching spark://dc42800f0e25:34541/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/fetchFileTemp4943806718630270213.tmp
24/09/19 19:44:22 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/-2975401441726775056316_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194417-0001/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:44:22 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194417-0001/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:44:22 INFO Executor: Fetching spark://dc42800f0e25:34541/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775056316
24/09/19 19:44:22 INFO Utils: Fetching spark://dc42800f0e25:34541/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/fetchFileTemp8197807410803651137.tmp
24/09/19 19:44:22 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4/269592641726775056316_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194417-0001/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:44:22 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194417-0001/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:44:22 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:44:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:44:22 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:44:22 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42337 after 3 ms (0 ms spent in bootstraps)
24/09/19 19:44:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 434.4 MiB)
24/09/19 19:44:22 INFO TorrentBroadcast: Reading broadcast variable 0 took 110 ms
24/09/19 19:44:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 22.1 KiB, free 434.4 MiB)
24/09/19 19:44:26 INFO CodeGenerator: Code generated in 159.788968 ms
24/09/19 19:44:26 INFO CodeGenerator: Code generated in 40.404439 ms
24/09/19 19:44:26 INFO JDBCRDD: closed connection
24/09/19 19:44:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 19:44:26 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:44:26 INFO Worker: Asked to kill executor app-20240919194417-0001/0
24/09/19 19:44:26 INFO ExecutorRunner: Runner thread for executor app-20240919194417-0001/0 interrupted
24/09/19 19:44:26 INFO ExecutorRunner: Killing process!
24/09/19 19:44:26 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:44:26 INFO DiskBlockManager: Shutdown hook called
24/09/19 19:44:26 INFO Worker: Asked to launch executor app-20240919194417-0002/0 for Escrita no banco Postgres
24/09/19 19:44:26 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:44:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-9a5ad9f0-6538-4859-a0d5-d1d64894d2b3/spark-04979520-4c43-4556-8bb8-29cb3313a2d4
24/09/19 19:44:26 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:44:26 INFO MemoryStore: MemoryStore cleared
24/09/19 19:44:26 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:44:26 INFO BlockManager: BlockManager stopped
24/09/19 19:44:26 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:26 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:44:26 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41625" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:41625" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919194417-0002" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:44:26 INFO Worker: Executor app-20240919194417-0001/0 finished with state KILLED exitStatus 143
24/09/19 19:44:26 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:44:26 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919194417-0001, execId=0)
24/09/19 19:44:26 INFO Worker: Cleaning up local directories for application app-20240919194417-0001
24/09/19 19:44:26 INFO ExternalShuffleBlockResolver: Application app-20240919194417-0001 removed, cleanupLocalDirs = true
24/09/19 19:44:27 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 320@81fa745d0ef3
24/09/19 19:44:27 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:44:27 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:44:27 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:44:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:44:28 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:44:28 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:44:28 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:28 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:44:28 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41625 after 43 ms (0 ms spent in bootstraps)
24/09/19 19:44:28 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:44:28 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:44:28 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:44:28 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:44:28 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41625 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:44:28 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/blockmgr-c64c8ed3-0f66-49bb-961d-6d33321fb370
24/09/19 19:44:28 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:44:28 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:41625
24/09/19 19:44:28 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:44:28 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:44:28 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:44:28 INFO ResourceUtils: ==============================================================
24/09/19 19:44:28 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:44:28 INFO ResourceUtils: ==============================================================
24/09/19 19:44:28 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:44:28 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:44:28 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:44:28 INFO Executor: Java version 17.0.12
24/09/19 19:44:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38721.
24/09/19 19:44:28 INFO NettyBlockTransferService: Server created on 172.22.0.4:38721
24/09/19 19:44:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:44:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 38721, None)
24/09/19 19:44:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 38721, None)
24/09/19 19:44:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 38721, None)
24/09/19 19:44:28 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:44:28 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 19:44:28 INFO Executor: Fetching spark://dc42800f0e25:41625/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775056501
24/09/19 19:44:28 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41625 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:44:28 INFO Utils: Fetching spark://dc42800f0e25:41625/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/fetchFileTemp7437034985831246810.tmp
24/09/19 19:44:28 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/-6291958141726775056501_cache to /opt/bitnami/spark/work/app-20240919194417-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:44:28 INFO Executor: Fetching spark://dc42800f0e25:41625/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775056501
24/09/19 19:44:28 INFO Utils: Fetching spark://dc42800f0e25:41625/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/fetchFileTemp994117945013246486.tmp
24/09/19 19:44:28 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/-1938102941726775056501_cache to /opt/bitnami/spark/work/app-20240919194417-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:44:29 INFO Executor: Fetching spark://dc42800f0e25:41625/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775056501
24/09/19 19:44:29 INFO Utils: Fetching spark://dc42800f0e25:41625/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/fetchFileTemp16808787050797242886.tmp
24/09/19 19:44:29 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/17930144851726775056501_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194417-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:44:29 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194417-0002/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:44:29 INFO Executor: Fetching spark://dc42800f0e25:41625/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775056501
24/09/19 19:44:29 INFO Utils: Fetching spark://dc42800f0e25:41625/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/fetchFileTemp7040156547364737046.tmp
24/09/19 19:44:29 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38/-8372696911726775056501_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194417-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:44:29 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194417-0002/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:44:42 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:44:42 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:44:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 19:44:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:44:42 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:44:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36727 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:44:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.4 MiB)
24/09/19 19:44:42 INFO TorrentBroadcast: Reading broadcast variable 0 took 92 ms
24/09/19 19:44:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 29.9 KiB, free 434.4 MiB)
24/09/19 19:44:44 INFO CodeGenerator: Code generated in 162.876929 ms
24/09/19 19:44:45 INFO CodeGenerator: Code generated in 25.01319 ms
24/09/19 19:44:45 INFO PythonRunner: Times: total = 692, boot = 594, init = 98, finish = 0
24/09/19 19:44:45 INFO PythonRunner: Times: total = 696, boot = 591, init = 104, finish = 1
24/09/19 19:44:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 19:44:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 19:44:45 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:44:45 INFO Worker: Asked to kill executor app-20240919194417-0002/0
24/09/19 19:44:45 INFO ExecutorRunner: Runner thread for executor app-20240919194417-0002/0 interrupted
24/09/19 19:44:45 INFO ExecutorRunner: Killing process!
24/09/19 19:44:45 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:44:45 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:44:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-e883edc2-6530-4387-b135-ea1410bfbbba/spark-d9b40db6-0051-478f-b864-399930ab7b38
24/09/19 19:44:45 INFO MemoryStore: MemoryStore cleared
24/09/19 19:44:45 INFO BlockManager: BlockManager stopped
24/09/19 19:44:45 INFO Worker: Executor app-20240919194417-0002/0 finished with state KILLED exitStatus 143
24/09/19 19:44:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:44:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919194417-0002, execId=0)
24/09/19 19:44:45 INFO ExternalShuffleBlockResolver: Application app-20240919194417-0002 removed, cleanupLocalDirs = true
24/09/19 19:44:45 INFO Worker: Cleaning up local directories for application app-20240919194417-0002
24/09/19 19:47:53 INFO Worker: Asked to launch executor app-20240919194753-0003/0 for Escrita no banco Postgres
24/09/19 19:47:53 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:47:53 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:47:53 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:47:53 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:47:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:47:53 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43075" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:43075" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919194753-0003" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:47:54 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 440@81fa745d0ef3
24/09/19 19:47:54 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:47:54 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:47:54 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:47:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:47:54 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:47:54 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:47:54 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:47:54 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:47:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:47:54 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43075 after 43 ms (0 ms spent in bootstraps)
24/09/19 19:47:54 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:47:54 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:47:54 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:47:54 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:47:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:47:54 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43075 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:47:55 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/blockmgr-28a2e883-6d11-4337-a8e8-aa7b2f3be807
24/09/19 19:47:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:47:55 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:43075
24/09/19 19:47:55 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:47:55 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:47:55 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:47:55 INFO ResourceUtils: ==============================================================
24/09/19 19:47:55 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:47:55 INFO ResourceUtils: ==============================================================
24/09/19 19:47:55 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:47:55 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:47:55 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:47:55 INFO Executor: Java version 17.0.12
24/09/19 19:47:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40433.
24/09/19 19:47:55 INFO NettyBlockTransferService: Server created on 172.22.0.4:40433
24/09/19 19:47:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:47:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 40433, None)
24/09/19 19:47:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 40433, None)
24/09/19 19:47:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 40433, None)
24/09/19 19:47:55 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:47:55 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e4e04a3 for default.
24/09/19 19:47:55 INFO Executor: Fetching spark://dc42800f0e25:43075/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775272443
24/09/19 19:47:55 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43075 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:47:55 INFO Utils: Fetching spark://dc42800f0e25:43075/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/fetchFileTemp12299057635959122494.tmp
24/09/19 19:47:55 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/7474621891726775272443_cache to /opt/bitnami/spark/work/app-20240919194753-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:47:55 INFO Executor: Fetching spark://dc42800f0e25:43075/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775272443
24/09/19 19:47:55 INFO Utils: Fetching spark://dc42800f0e25:43075/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/fetchFileTemp6084205768533359638.tmp
24/09/19 19:47:55 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/-10986105311726775272443_cache to /opt/bitnami/spark/work/app-20240919194753-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:47:55 INFO Executor: Fetching spark://dc42800f0e25:43075/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775272443
24/09/19 19:47:55 INFO Utils: Fetching spark://dc42800f0e25:43075/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/fetchFileTemp1697739374248651621.tmp
24/09/19 19:47:55 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/6575638581726775272443_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194753-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:47:55 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194753-0003/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:47:55 INFO Executor: Fetching spark://dc42800f0e25:43075/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775272443
24/09/19 19:47:55 INFO Utils: Fetching spark://dc42800f0e25:43075/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/fetchFileTemp17721171521805053493.tmp
24/09/19 19:47:55 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959/363074901726775272443_cache has been previously copied to /opt/bitnami/spark/work/app-20240919194753-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:47:55 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919194753-0003/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:48:17 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:48:17 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:48:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 19:48:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:48:17 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:48:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42115 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:48:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.4 MiB)
24/09/19 19:48:17 INFO TorrentBroadcast: Reading broadcast variable 0 took 104 ms
24/09/19 19:48:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 29.9 KiB, free 434.4 MiB)
24/09/19 19:48:18 INFO CodeGenerator: Code generated in 167.073337 ms
24/09/19 19:48:19 INFO CodeGenerator: Code generated in 28.002956 ms
24/09/19 19:48:19 INFO PythonRunner: Times: total = 585, boot = 479, init = 106, finish = 0
24/09/19 19:48:19 INFO PythonRunner: Times: total = 586, boot = 482, init = 104, finish = 0
24/09/19 19:48:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 19:48:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 19:48:19 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:48:19 INFO Worker: Asked to kill executor app-20240919194753-0003/0
24/09/19 19:48:19 INFO ExecutorRunner: Runner thread for executor app-20240919194753-0003/0 interrupted
24/09/19 19:48:19 INFO ExecutorRunner: Killing process!
24/09/19 19:48:19 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:48:19 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:48:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-ffb7c675-f1fd-427c-a1e4-e00fea3d5fba/spark-1a2e9e79-5e44-4cfe-8e56-82fc8db48959
24/09/19 19:48:19 INFO MemoryStore: MemoryStore cleared
24/09/19 19:48:19 INFO BlockManager: BlockManager stopped
24/09/19 19:48:19 INFO Worker: Executor app-20240919194753-0003/0 finished with state KILLED exitStatus 143
24/09/19 19:48:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:48:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919194753-0003, execId=0)
24/09/19 19:48:19 INFO ExternalShuffleBlockResolver: Application app-20240919194753-0003 removed, cleanupLocalDirs = true
24/09/19 19:48:19 INFO Worker: Cleaning up local directories for application app-20240919194753-0003
24/09/19 19:50:10 INFO Worker: Asked to launch executor app-20240919195010-0004/0 for Postgres to Postgres
24/09/19 19:50:10 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:50:10 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:50:10 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:10 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:50:10 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40551" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40551" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919195010-0004" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:50:11 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 560@81fa745d0ef3
24/09/19 19:50:11 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:50:11 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:50:11 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:50:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:50:11 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:50:11 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:50:11 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:11 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:50:12 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40551 after 45 ms (0 ms spent in bootstraps)
24/09/19 19:50:12 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:50:12 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:50:12 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:12 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:50:12 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40551 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:12 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/blockmgr-5bfce345-a91d-4ae5-95c6-27c73cd61d41
24/09/19 19:50:12 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:50:12 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40551
24/09/19 19:50:12 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:50:12 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:12 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:50:12 INFO ResourceUtils: ==============================================================
24/09/19 19:50:12 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:50:12 INFO ResourceUtils: ==============================================================
24/09/19 19:50:12 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:50:12 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:50:12 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:50:12 INFO Executor: Java version 17.0.12
24/09/19 19:50:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33575.
24/09/19 19:50:12 INFO NettyBlockTransferService: Server created on 172.22.0.4:33575
24/09/19 19:50:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:50:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 33575, None)
24/09/19 19:50:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 33575, None)
24/09/19 19:50:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 33575, None)
24/09/19 19:50:12 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:50:12 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1635823e for default.
24/09/19 19:50:12 INFO Executor: Fetching spark://dc42800f0e25:40551/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775409520
24/09/19 19:50:12 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40551 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:12 INFO Utils: Fetching spark://dc42800f0e25:40551/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/fetchFileTemp15827535637286071335.tmp
24/09/19 19:50:12 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/-9315388131726775409520_cache to /opt/bitnami/spark/work/app-20240919195010-0004/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:50:12 INFO Executor: Fetching spark://dc42800f0e25:40551/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775409520
24/09/19 19:50:12 INFO Utils: Fetching spark://dc42800f0e25:40551/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/fetchFileTemp14100056630880461407.tmp
24/09/19 19:50:12 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/-3167962691726775409520_cache to /opt/bitnami/spark/work/app-20240919195010-0004/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:50:12 INFO Executor: Fetching spark://dc42800f0e25:40551/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775409520
24/09/19 19:50:12 INFO Utils: Fetching spark://dc42800f0e25:40551/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/fetchFileTemp880275220237691131.tmp
24/09/19 19:50:12 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/19765721726775409520_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195010-0004/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:50:12 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195010-0004/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:50:12 INFO Executor: Fetching spark://dc42800f0e25:40551/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775409520
24/09/19 19:50:12 INFO Utils: Fetching spark://dc42800f0e25:40551/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/fetchFileTemp1146725518065204347.tmp
24/09/19 19:50:12 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932/3858586041726775409520_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195010-0004/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:50:12 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195010-0004/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:50:14 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:50:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:50:14 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:50:14 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:35551 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 434.4 MiB)
24/09/19 19:50:15 INFO TorrentBroadcast: Reading broadcast variable 0 took 85 ms
24/09/19 19:50:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 22.1 KiB, free 434.4 MiB)
24/09/19 19:50:17 INFO CodeGenerator: Code generated in 145.232646 ms
24/09/19 19:50:17 INFO CodeGenerator: Code generated in 30.669488 ms
24/09/19 19:50:18 INFO JDBCRDD: closed connection
24/09/19 19:50:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 19:50:18 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:50:18 INFO Worker: Asked to kill executor app-20240919195010-0004/0
24/09/19 19:50:18 INFO ExecutorRunner: Runner thread for executor app-20240919195010-0004/0 interrupted
24/09/19 19:50:18 INFO ExecutorRunner: Killing process!
24/09/19 19:50:18 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:50:18 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:50:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c5bfc068-8712-42bd-bd1b-e4ff23b35859/spark-f2158692-dc84-4598-9f4f-0f6231434932
24/09/19 19:50:18 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40551 disconnected during shutdown
24/09/19 19:50:18 INFO MemoryStore: MemoryStore cleared
24/09/19 19:50:18 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40551 disconnected during shutdown
24/09/19 19:50:18 INFO BlockManager: BlockManager stopped
24/09/19 19:50:18 INFO Worker: Executor app-20240919195010-0004/0 finished with state KILLED exitStatus 143
24/09/19 19:50:18 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:50:18 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919195010-0004, execId=0)
24/09/19 19:50:18 INFO ExternalShuffleBlockResolver: Application app-20240919195010-0004 removed, cleanupLocalDirs = true
24/09/19 19:50:18 INFO Worker: Cleaning up local directories for application app-20240919195010-0004
24/09/19 19:50:37 INFO Worker: Asked to launch executor app-20240919195037-0005/0 for GCS to Postgres
24/09/19 19:50:37 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:50:37 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:50:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:50:37 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34321" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:34321" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919195037-0005" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:50:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 671@81fa745d0ef3
24/09/19 19:50:38 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:50:38 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:50:38 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:50:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:50:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:50:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:50:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:50:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34321 after 47 ms (0 ms spent in bootstraps)
24/09/19 19:50:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:50:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:50:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:50:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:50:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:50:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34321 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:50:39 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/blockmgr-3cb48a6b-30c0-4e08-93a1-eb01b1d704a6
24/09/19 19:50:39 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:50:39 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:34321
24/09/19 19:50:39 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:50:39 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:50:39 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:50:39 INFO ResourceUtils: ==============================================================
24/09/19 19:50:39 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:50:39 INFO ResourceUtils: ==============================================================
24/09/19 19:50:39 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:50:39 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:50:39 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:50:39 INFO Executor: Java version 17.0.12
24/09/19 19:50:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43583.
24/09/19 19:50:39 INFO NettyBlockTransferService: Server created on 172.22.0.4:43583
24/09/19 19:50:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:50:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 43583, None)
24/09/19 19:50:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 43583, None)
24/09/19 19:50:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 43583, None)
24/09/19 19:50:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:50:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 19:50:39 INFO Executor: Fetching spark://dc42800f0e25:34321/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775436786
24/09/19 19:50:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34321 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:40 INFO Utils: Fetching spark://dc42800f0e25:34321/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/fetchFileTemp7109979643306038751.tmp
24/09/19 19:50:40 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/-11175171371726775436786_cache to /opt/bitnami/spark/work/app-20240919195037-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:50:40 INFO Executor: Fetching spark://dc42800f0e25:34321/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775436786
24/09/19 19:50:40 INFO Utils: Fetching spark://dc42800f0e25:34321/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/fetchFileTemp762016993829183253.tmp
24/09/19 19:50:40 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/16706630711726775436786_cache to /opt/bitnami/spark/work/app-20240919195037-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:50:40 INFO Executor: Fetching spark://dc42800f0e25:34321/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775436786
24/09/19 19:50:40 INFO Utils: Fetching spark://dc42800f0e25:34321/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/fetchFileTemp15432009323264946090.tmp
24/09/19 19:50:40 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/15001675201726775436786_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195037-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:50:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195037-0005/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:50:40 INFO Executor: Fetching spark://dc42800f0e25:34321/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775436786
24/09/19 19:50:40 INFO Utils: Fetching spark://dc42800f0e25:34321/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/fetchFileTemp2563743462847087910.tmp
24/09/19 19:50:40 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e/1927059361726775436786_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195037-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:50:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195037-0005/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:50:40 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:50:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:50:40 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:50:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42459 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:50:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 434.4 MiB)
24/09/19 19:50:40 INFO TorrentBroadcast: Reading broadcast variable 0 took 90 ms
24/09/19 19:50:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 19:50:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1785 bytes result sent to driver
24/09/19 19:50:42 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:50:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:50:42 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:50:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 434.4 MiB)
24/09/19 19:50:42 INFO TorrentBroadcast: Reading broadcast variable 2 took 20 ms
24/09/19 19:50:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.8 KiB, free 434.4 MiB)
24/09/19 19:50:42 INFO CodeGenerator: Code generated in 203.464725 ms
24/09/19 19:50:43 INFO CodeGenerator: Code generated in 18.620038 ms
24/09/19 19:50:43 INFO FileScanRDD: Reading File path: file:///opt/data/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:50:43 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:50:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.3 MiB)
24/09/19 19:50:43 INFO TorrentBroadcast: Reading broadcast variable 1 took 14 ms
24/09/19 19:50:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 373.4 KiB, free 434.0 MiB)
24/09/19 19:50:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1843 bytes result sent to driver
24/09/19 19:50:44 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:50:44 INFO Worker: Asked to kill executor app-20240919195037-0005/0
24/09/19 19:50:44 INFO ExecutorRunner: Runner thread for executor app-20240919195037-0005/0 interrupted
24/09/19 19:50:44 INFO ExecutorRunner: Killing process!
24/09/19 19:50:44 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:50:44 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:50:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a5562979-c3a4-4b16-8fd0-6f9ec91b5171/spark-d18cf9ca-599b-434a-b03f-08f764c8af2e
24/09/19 19:50:44 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34321 disconnected during shutdown
24/09/19 19:50:44 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34321 disconnected during shutdown
24/09/19 19:50:44 INFO MemoryStore: MemoryStore cleared
24/09/19 19:50:44 INFO BlockManager: BlockManager stopped
24/09/19 19:50:44 INFO Worker: Executor app-20240919195037-0005/0 finished with state KILLED exitStatus 143
24/09/19 19:50:44 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:50:44 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919195037-0005, execId=0)
24/09/19 19:50:44 INFO ExternalShuffleBlockResolver: Application app-20240919195037-0005 removed, cleanupLocalDirs = true
24/09/19 19:50:44 INFO Worker: Cleaning up local directories for application app-20240919195037-0005
24/09/19 19:51:31 INFO Worker: Asked to launch executor app-20240919195131-0006/0 for GCS to Postgres
24/09/19 19:51:31 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 19:51:31 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 19:51:31 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:51:31 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:51:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 19:51:31 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40079" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40079" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919195131-0006" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 19:51:33 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 777@81fa745d0ef3
24/09/19 19:51:33 INFO SignalUtils: Registering signal handler for TERM
24/09/19 19:51:33 INFO SignalUtils: Registering signal handler for HUP
24/09/19 19:51:33 INFO SignalUtils: Registering signal handler for INT
24/09/19 19:51:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 19:51:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:51:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:51:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:51:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:51:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:51:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40079 after 46 ms (0 ms spent in bootstraps)
24/09/19 19:51:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 19:51:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 19:51:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 19:51:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 19:51:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 19:51:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40079 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:51:34 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/blockmgr-51ea85a9-6ddc-4c1d-bd6e-6dc05c764f8c
24/09/19 19:51:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 19:51:34 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40079
24/09/19 19:51:34 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 19:51:34 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 10 ms (0 ms spent in bootstraps)
24/09/19 19:51:34 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 19:51:34 INFO ResourceUtils: ==============================================================
24/09/19 19:51:34 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 19:51:34 INFO ResourceUtils: ==============================================================
24/09/19 19:51:34 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 19:51:34 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 19:51:34 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 19:51:34 INFO Executor: Java version 17.0.12
24/09/19 19:51:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34675.
24/09/19 19:51:34 INFO NettyBlockTransferService: Server created on 172.22.0.4:34675
24/09/19 19:51:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 19:51:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34675, None)
24/09/19 19:51:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34675, None)
24/09/19 19:51:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34675, None)
24/09/19 19:51:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 19:51:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 19:51:34 INFO Executor: Fetching spark://dc42800f0e25:40079/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775491116
24/09/19 19:51:34 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40079 after 2 ms (0 ms spent in bootstraps)
24/09/19 19:51:34 INFO Utils: Fetching spark://dc42800f0e25:40079/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/fetchFileTemp9177742881798952093.tmp
24/09/19 19:51:34 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/-3743082041726775491116_cache to /opt/bitnami/spark/work/app-20240919195131-0006/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:51:34 INFO Executor: Fetching spark://dc42800f0e25:40079/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775491116
24/09/19 19:51:34 INFO Utils: Fetching spark://dc42800f0e25:40079/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/fetchFileTemp14359778900037342886.tmp
24/09/19 19:51:34 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/21201233321726775491116_cache to /opt/bitnami/spark/work/app-20240919195131-0006/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:51:34 INFO Executor: Fetching spark://dc42800f0e25:40079/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726775491116
24/09/19 19:51:34 INFO Utils: Fetching spark://dc42800f0e25:40079/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/fetchFileTemp6641706213082924440.tmp
24/09/19 19:51:34 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/11770359791726775491116_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195131-0006/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 19:51:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195131-0006/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 19:51:34 INFO Executor: Fetching spark://dc42800f0e25:40079/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726775491116
24/09/19 19:51:34 INFO Utils: Fetching spark://dc42800f0e25:40079/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/fetchFileTemp4040108508009744684.tmp
24/09/19 19:51:34 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37/-13853519731726775491116_cache has been previously copied to /opt/bitnami/spark/work/app-20240919195131-0006/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 19:51:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919195131-0006/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 19:51:34 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 19:51:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 19:51:34 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:51:34 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36377 after 1 ms (0 ms spent in bootstraps)
24/09/19 19:51:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 434.4 MiB)
24/09/19 19:51:34 INFO TorrentBroadcast: Reading broadcast variable 0 took 99 ms
24/09/19 19:51:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.4 KiB, free 434.3 MiB)
24/09/19 19:51:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1785 bytes result sent to driver
24/09/19 19:51:36 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 19:51:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 19:51:36 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:51:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 434.4 MiB)
24/09/19 19:51:36 INFO TorrentBroadcast: Reading broadcast variable 2 took 17 ms
24/09/19 19:51:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.8 KiB, free 434.4 MiB)
24/09/19 19:51:37 INFO CodeGenerator: Code generated in 205.329161 ms
24/09/19 19:51:37 INFO CodeGenerator: Code generated in 19.809678 ms
24/09/19 19:51:37 INFO FileScanRDD: Reading File path: file:///opt/data/categoria.parquet, range: 0-839, partition values: [empty row]
24/09/19 19:51:37 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 19:51:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.3 MiB)
24/09/19 19:51:38 INFO TorrentBroadcast: Reading broadcast variable 1 took 12 ms
24/09/19 19:51:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 373.4 KiB, free 434.0 MiB)
24/09/19 19:51:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1843 bytes result sent to driver
24/09/19 19:51:38 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 19:51:38 INFO Worker: Asked to kill executor app-20240919195131-0006/0
24/09/19 19:51:38 INFO ExecutorRunner: Runner thread for executor app-20240919195131-0006/0 interrupted
24/09/19 19:51:38 INFO ExecutorRunner: Killing process!
24/09/19 19:51:38 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 19:51:38 INFO ShutdownHookManager: Shutdown hook called
24/09/19 19:51:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c97fc16d-4300-45b0-b41b-34dc4651be5a/spark-3bac8203-0081-477e-992d-d77d0b5a7c37
24/09/19 19:51:38 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40079 disconnected during shutdown
24/09/19 19:51:38 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40079 disconnected during shutdown
24/09/19 19:51:38 INFO MemoryStore: MemoryStore cleared
24/09/19 19:51:38 INFO BlockManager: BlockManager stopped
24/09/19 19:51:38 INFO Worker: Executor app-20240919195131-0006/0 finished with state KILLED exitStatus 143
24/09/19 19:51:38 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 19:51:38 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919195131-0006, execId=0)
24/09/19 19:51:38 INFO Worker: Cleaning up local directories for application app-20240919195131-0006
24/09/19 19:51:38 INFO ExternalShuffleBlockResolver: Application app-20240919195131-0006 removed, cleanupLocalDirs = true
24/09/19 20:03:13 INFO ExternalShuffleBlockResolver: Application app-20240919200311-0007 removed, cleanupLocalDirs = true
24/09/19 20:03:13 INFO ExternalShuffleBlockResolver: Application app-20240919200311-0008 removed, cleanupLocalDirs = true
24/09/19 20:03:22 INFO ExternalShuffleBlockResolver: Application app-20240919200320-0009 removed, cleanupLocalDirs = true
24/09/19 20:06:39 INFO ExternalShuffleBlockResolver: Application app-20240919200356-0010 removed, cleanupLocalDirs = true
24/09/19 20:07:38 INFO Worker: Asked to launch executor app-20240919200738-0011/0 for PostgresToGoldSchema
24/09/19 20:07:38 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:07:38 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:07:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:07:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:07:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:07:38 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41653" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:41653" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919200738-0011" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:07:40 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 891@81fa745d0ef3
24/09/19 20:07:40 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:07:40 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:07:40 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:07:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:07:40 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:07:40 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:07:40 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:07:40 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:07:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:07:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41653 after 60 ms (0 ms spent in bootstraps)
24/09/19 20:07:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:07:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:07:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:07:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:07:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:07:41 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41653 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:07:41 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/blockmgr-cdaf5105-0bd9-4e57-9278-5d431cc62d47
24/09/19 20:07:41 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:07:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:41653
24/09/19 20:07:41 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:07:41 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:07:41 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:07:41 INFO ResourceUtils: ==============================================================
24/09/19 20:07:41 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:07:41 INFO ResourceUtils: ==============================================================
24/09/19 20:07:41 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:07:41 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:07:41 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:07:41 INFO Executor: Java version 17.0.12
24/09/19 20:07:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46457.
24/09/19 20:07:41 INFO NettyBlockTransferService: Server created on 172.22.0.4:46457
24/09/19 20:07:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:07:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 46457, None)
24/09/19 20:07:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 46457, None)
24/09/19 20:07:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 46457, None)
24/09/19 20:07:41 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:07:41 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@42f90c0d for default.
24/09/19 20:07:41 INFO Executor: Fetching spark://dc42800f0e25:41653/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776457858
24/09/19 20:07:41 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41653 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:07:41 INFO Utils: Fetching spark://dc42800f0e25:41653/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/fetchFileTemp5291748253044171080.tmp
24/09/19 20:07:41 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/-7777567471726776457858_cache to /opt/bitnami/spark/work/app-20240919200738-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:07:41 INFO Executor: Fetching spark://dc42800f0e25:41653/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776457858
24/09/19 20:07:41 INFO Utils: Fetching spark://dc42800f0e25:41653/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/fetchFileTemp14667445689008282163.tmp
24/09/19 20:07:41 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/-1526814351726776457858_cache to /opt/bitnami/spark/work/app-20240919200738-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:07:41 INFO Executor: Fetching spark://dc42800f0e25:41653/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776457858
24/09/19 20:07:41 INFO Utils: Fetching spark://dc42800f0e25:41653/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/fetchFileTemp11956380073636025346.tmp
24/09/19 20:07:41 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/-12598191101726776457858_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200738-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:07:41 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200738-0011/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:07:41 INFO Executor: Fetching spark://dc42800f0e25:41653/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776457858
24/09/19 20:07:41 INFO Utils: Fetching spark://dc42800f0e25:41653/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/fetchFileTemp12451784130058459376.tmp
24/09/19 20:07:42 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006/-12515849501726776457858_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200738-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:07:42 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200738-0011/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:07:42 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:07:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:07:42 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:07:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46339 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:07:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 20:07:42 INFO TorrentBroadcast: Reading broadcast variable 0 took 89 ms
24/09/19 20:07:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 27.8 KiB, free 434.4 MiB)
24/09/19 20:07:43 INFO CodeGenerator: Code generated in 173.148885 ms
24/09/19 20:07:44 INFO CodeGenerator: Code generated in 37.759586 ms
24/09/19 20:07:44 INFO JDBCRDD: closed connection
24/09/19 20:07:44 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gold.dim_categoria ("id","nome_categoria") VALUES (1,'Babywear') was aborted: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:169)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:862)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:901)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1644)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:753)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:904)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:903)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.postgresql.util.PSQLException: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:859)
	... 19 more
24/09/19 20:07:44 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:07:44 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
24/09/19 20:07:44 INFO JDBCRDD: closed connection
24/09/19 20:07:44 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gold.dim_categoria ("id","nome_categoria") VALUES (1,'Babywear') was aborted: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:169)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:862)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:901)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1644)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:753)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:904)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:903)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.postgresql.util.PSQLException: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:859)
	... 19 more
24/09/19 20:07:44 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:07:44 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
24/09/19 20:07:44 INFO JDBCRDD: closed connection
24/09/19 20:07:44 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gold.dim_categoria ("id","nome_categoria") VALUES (1,'Babywear') was aborted: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:169)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:862)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:901)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1644)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:753)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:904)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:903)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.postgresql.util.PSQLException: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:859)
	... 19 more
24/09/19 20:07:44 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:07:44 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
24/09/19 20:07:44 INFO JDBCRDD: closed connection
24/09/19 20:07:44 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gold.dim_categoria ("id","nome_categoria") VALUES (1,'Babywear') was aborted: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:169)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:862)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:901)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1644)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:753)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:904)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:903)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.postgresql.util.PSQLException: ERROR: relation "gold.dim_categoria" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:859)
	... 19 more
24/09/19 20:07:45 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:07:45 INFO Worker: Asked to kill executor app-20240919200738-0011/0
24/09/19 20:07:45 INFO ExecutorRunner: Runner thread for executor app-20240919200738-0011/0 interrupted
24/09/19 20:07:45 INFO ExecutorRunner: Killing process!
24/09/19 20:07:45 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:07:45 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:07:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-fe5976cc-7e8f-4a0b-8dad-21f0b8d53cf8/spark-bed0197a-d442-4670-8159-c03fae2a3006
24/09/19 20:07:45 INFO MemoryStore: MemoryStore cleared
24/09/19 20:07:45 INFO BlockManager: BlockManager stopped
24/09/19 20:07:45 INFO Worker: Executor app-20240919200738-0011/0 finished with state KILLED exitStatus 143
24/09/19 20:07:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:07:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919200738-0011, execId=0)
24/09/19 20:07:45 INFO Worker: Cleaning up local directories for application app-20240919200738-0011
24/09/19 20:07:45 INFO ExternalShuffleBlockResolver: Application app-20240919200738-0011 removed, cleanupLocalDirs = true
24/09/19 20:08:36 INFO Worker: Asked to launch executor app-20240919200836-0012/0 for PostgresToGoldSchema
24/09/19 20:08:36 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:08:36 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:08:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:08:36 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42605" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:42605" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919200836-0012" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:08:37 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 990@81fa745d0ef3
24/09/19 20:08:37 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:08:37 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:08:37 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:08:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:08:38 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:08:38 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:08:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:08:38 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42605 after 46 ms (0 ms spent in bootstraps)
24/09/19 20:08:38 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:08:38 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:08:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:08:38 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42605 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:08:38 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/blockmgr-6681cabe-51c5-4fb1-aa15-3ec97c6f5e40
24/09/19 20:08:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:08:38 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:42605
24/09/19 20:08:38 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:08:38 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:08:38 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:08:38 INFO ResourceUtils: ==============================================================
24/09/19 20:08:38 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:08:38 INFO ResourceUtils: ==============================================================
24/09/19 20:08:38 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:08:38 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:08:38 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:08:38 INFO Executor: Java version 17.0.12
24/09/19 20:08:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44627.
24/09/19 20:08:38 INFO NettyBlockTransferService: Server created on 172.22.0.4:44627
24/09/19 20:08:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:08:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44627, None)
24/09/19 20:08:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44627, None)
24/09/19 20:08:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44627, None)
24/09/19 20:08:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:08:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c02f038 for default.
24/09/19 20:08:39 INFO Executor: Fetching spark://dc42800f0e25:42605/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776515575
24/09/19 20:08:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42605 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:08:39 INFO Utils: Fetching spark://dc42800f0e25:42605/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/fetchFileTemp2171607831367592156.tmp
24/09/19 20:08:39 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/-15878874931726776515575_cache to /opt/bitnami/spark/work/app-20240919200836-0012/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:08:39 INFO Executor: Fetching spark://dc42800f0e25:42605/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776515575
24/09/19 20:08:39 INFO Utils: Fetching spark://dc42800f0e25:42605/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/fetchFileTemp7688258333461289806.tmp
24/09/19 20:08:39 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/-12941408211726776515575_cache to /opt/bitnami/spark/work/app-20240919200836-0012/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:08:39 INFO Executor: Fetching spark://dc42800f0e25:42605/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776515575
24/09/19 20:08:39 INFO Utils: Fetching spark://dc42800f0e25:42605/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/fetchFileTemp11292470501694933120.tmp
24/09/19 20:08:39 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/-14244996921726776515575_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200836-0012/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:08:39 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200836-0012/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:08:39 INFO Executor: Fetching spark://dc42800f0e25:42605/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776515575
24/09/19 20:08:39 INFO Utils: Fetching spark://dc42800f0e25:42605/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/fetchFileTemp7936385550659122820.tmp
24/09/19 20:08:39 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea/-7342168921726776515575_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200836-0012/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:08:39 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200836-0012/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:08:39 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:08:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:08:39 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:08:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:32799 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:08:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 434.4 MiB)
24/09/19 20:08:40 INFO TorrentBroadcast: Reading broadcast variable 0 took 103 ms
24/09/19 20:08:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 27.8 KiB, free 434.4 MiB)
24/09/19 20:08:40 INFO CodeGenerator: Code generated in 159.584794 ms
24/09/19 20:08:41 INFO CodeGenerator: Code generated in 23.398682 ms
24/09/19 20:08:41 INFO JDBCRDD: closed connection
24/09/19 20:08:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 20:08:41 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:08:41 INFO Worker: Asked to kill executor app-20240919200836-0012/0
24/09/19 20:08:41 INFO ExecutorRunner: Runner thread for executor app-20240919200836-0012/0 interrupted
24/09/19 20:08:41 INFO ExecutorRunner: Killing process!
24/09/19 20:08:41 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:08:41 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:08:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-a95227a4-7f4e-40f1-9f05-d34081899169/spark-179bd630-3303-445a-bfe0-79c7e05404ea
24/09/19 20:08:41 INFO MemoryStore: MemoryStore cleared
24/09/19 20:08:41 INFO BlockManager: BlockManager stopped
24/09/19 20:08:41 INFO Worker: Executor app-20240919200836-0012/0 finished with state KILLED exitStatus 143
24/09/19 20:08:41 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:08:41 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919200836-0012, execId=0)
24/09/19 20:08:41 INFO ExternalShuffleBlockResolver: Application app-20240919200836-0012 removed, cleanupLocalDirs = true
24/09/19 20:08:41 INFO Worker: Cleaning up local directories for application app-20240919200836-0012
24/09/19 20:08:46 INFO Worker: Asked to launch executor app-20240919200846-0013/0 for PostgresToGoldSchema
24/09/19 20:08:46 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:08:46 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:08:46 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:46 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:08:46 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45939" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:45939" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919200846-0013" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:08:48 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1086@81fa745d0ef3
24/09/19 20:08:48 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:08:48 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:08:48 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:08:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:08:48 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:08:48 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:08:48 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:48 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:08:48 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45939 after 46 ms (0 ms spent in bootstraps)
24/09/19 20:08:48 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:08:48 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:08:48 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:08:48 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:08:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:08:49 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45939 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:08:49 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/blockmgr-ebdce4e4-ae4b-4257-9d8d-47be7eff7902
24/09/19 20:08:49 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:08:49 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:45939
24/09/19 20:08:49 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:08:49 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:08:49 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:08:49 INFO ResourceUtils: ==============================================================
24/09/19 20:08:49 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:08:49 INFO ResourceUtils: ==============================================================
24/09/19 20:08:49 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:08:49 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:08:49 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:08:49 INFO Executor: Java version 17.0.12
24/09/19 20:08:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43251.
24/09/19 20:08:49 INFO NettyBlockTransferService: Server created on 172.22.0.4:43251
24/09/19 20:08:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:08:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 43251, None)
24/09/19 20:08:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 43251, None)
24/09/19 20:08:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 43251, None)
24/09/19 20:08:49 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:08:49 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:08:49 INFO Executor: Fetching spark://dc42800f0e25:45939/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776526131
24/09/19 20:08:49 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45939 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:08:49 INFO Utils: Fetching spark://dc42800f0e25:45939/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/fetchFileTemp7776180963089422103.tmp
24/09/19 20:08:49 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/10835601721726776526131_cache to /opt/bitnami/spark/work/app-20240919200846-0013/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:08:49 INFO Executor: Fetching spark://dc42800f0e25:45939/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776526131
24/09/19 20:08:49 INFO Utils: Fetching spark://dc42800f0e25:45939/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/fetchFileTemp5048025198244239832.tmp
24/09/19 20:08:49 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/11756374361726776526131_cache to /opt/bitnami/spark/work/app-20240919200846-0013/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:08:49 INFO Executor: Fetching spark://dc42800f0e25:45939/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776526131
24/09/19 20:08:49 INFO Utils: Fetching spark://dc42800f0e25:45939/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/fetchFileTemp13710606030317212000.tmp
24/09/19 20:08:49 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/3272142591726776526131_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200846-0013/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:08:49 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200846-0013/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:08:49 INFO Executor: Fetching spark://dc42800f0e25:45939/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776526131
24/09/19 20:08:49 INFO Utils: Fetching spark://dc42800f0e25:45939/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/fetchFileTemp17792098484360014602.tmp
24/09/19 20:08:49 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393/-17658955171726776526131_cache has been previously copied to /opt/bitnami/spark/work/app-20240919200846-0013/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:08:49 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919200846-0013/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:08:50 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:08:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:08:50 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:08:50 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39613 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:08:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.4 MiB)
24/09/19 20:08:50 INFO TorrentBroadcast: Reading broadcast variable 0 took 111 ms
24/09/19 20:08:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 27.8 KiB, free 434.4 MiB)
24/09/19 20:08:51 INFO CodeGenerator: Code generated in 160.789345 ms
24/09/19 20:08:52 INFO CodeGenerator: Code generated in 23.527474 ms
24/09/19 20:08:52 INFO JDBCRDD: closed connection
24/09/19 20:08:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 20:08:52 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:08:52 INFO Worker: Asked to kill executor app-20240919200846-0013/0
24/09/19 20:08:52 INFO ExecutorRunner: Runner thread for executor app-20240919200846-0013/0 interrupted
24/09/19 20:08:52 INFO ExecutorRunner: Killing process!
24/09/19 20:08:52 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:08:52 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:08:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-b76148ac-d4ea-4b61-871c-58612367ca2d/spark-f1ea2664-cf55-44d1-b2cf-5a5fe21cc393
24/09/19 20:08:52 INFO MemoryStore: MemoryStore cleared
24/09/19 20:08:52 INFO BlockManager: BlockManager stopped
24/09/19 20:08:52 INFO Worker: Executor app-20240919200846-0013/0 finished with state KILLED exitStatus 143
24/09/19 20:08:52 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:08:52 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919200846-0013, execId=0)
24/09/19 20:08:52 INFO ExternalShuffleBlockResolver: Application app-20240919200846-0013 removed, cleanupLocalDirs = true
24/09/19 20:08:52 INFO Worker: Cleaning up local directories for application app-20240919200846-0013
24/09/19 20:15:37 INFO Worker: Asked to launch executor app-20240919201537-0014/0 for DimensaoTempo
24/09/19 20:15:37 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:15:37 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:15:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:15:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:15:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:15:37 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46391" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:46391" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919201537-0014" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:15:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1181@81fa745d0ef3
24/09/19 20:15:38 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:15:38 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:15:38 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:15:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:15:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:15:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:15:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:15:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:15:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:15:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46391 after 51 ms (0 ms spent in bootstraps)
24/09/19 20:15:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:15:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:15:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:15:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:15:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:15:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46391 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:15:39 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/blockmgr-f65225cc-fd49-4855-b9ed-210cfdc67c94
24/09/19 20:15:39 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:15:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:46391
24/09/19 20:15:40 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:15:40 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:15:40 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:15:40 INFO ResourceUtils: ==============================================================
24/09/19 20:15:40 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:15:40 INFO ResourceUtils: ==============================================================
24/09/19 20:15:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:15:40 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:15:40 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:15:40 INFO Executor: Java version 17.0.12
24/09/19 20:15:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34883.
24/09/19 20:15:40 INFO NettyBlockTransferService: Server created on 172.22.0.4:34883
24/09/19 20:15:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:15:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34883, None)
24/09/19 20:15:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34883, None)
24/09/19 20:15:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34883, None)
24/09/19 20:15:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:15:40 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@300f28ca for default.
24/09/19 20:15:40 INFO Executor: Fetching spark://dc42800f0e25:46391/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776936548
24/09/19 20:15:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46391 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:15:40 INFO Utils: Fetching spark://dc42800f0e25:46391/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/fetchFileTemp5475655920002574451.tmp
24/09/19 20:15:40 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/11203890631726776936548_cache to /opt/bitnami/spark/work/app-20240919201537-0014/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:15:40 INFO Executor: Fetching spark://dc42800f0e25:46391/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776936548
24/09/19 20:15:40 INFO Utils: Fetching spark://dc42800f0e25:46391/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/fetchFileTemp15337536509636933925.tmp
24/09/19 20:15:40 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/343302951726776936548_cache to /opt/bitnami/spark/work/app-20240919201537-0014/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:15:40 INFO Executor: Fetching spark://dc42800f0e25:46391/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726776936548
24/09/19 20:15:40 INFO Utils: Fetching spark://dc42800f0e25:46391/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/fetchFileTemp873268842302659789.tmp
24/09/19 20:15:40 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/4170156721726776936548_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201537-0014/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:15:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201537-0014/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:15:40 INFO Executor: Fetching spark://dc42800f0e25:46391/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726776936548
24/09/19 20:15:40 INFO Utils: Fetching spark://dc42800f0e25:46391/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/fetchFileTemp15426393140999760401.tmp
24/09/19 20:15:40 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7/-11985886001726776936548_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201537-0014/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:15:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201537-0014/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:15:41 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:15:41 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:15:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:15:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:15:42 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:15:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:33871 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:15:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 434.4 MiB)
24/09/19 20:15:42 INFO TorrentBroadcast: Reading broadcast variable 0 took 96 ms
24/09/19 20:15:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 42.7 KiB, free 434.3 MiB)
24/09/19 20:15:43 INFO CodeGenerator: Code generated in 196.815691 ms
24/09/19 20:15:44 INFO CodeGenerator: Code generated in 35.091652 ms
24/09/19 20:15:45 INFO PythonRunner: Times: total = 678, boot = 544, init = 133, finish = 1
24/09/19 20:15:45 INFO PythonRunner: Times: total = 693, boot = 548, init = 144, finish = 1
24/09/19 20:15:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 20:15:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 20:15:45 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:15:45 INFO Worker: Asked to kill executor app-20240919201537-0014/0
24/09/19 20:15:45 INFO ExecutorRunner: Runner thread for executor app-20240919201537-0014/0 interrupted
24/09/19 20:15:45 INFO ExecutorRunner: Killing process!
24/09/19 20:15:45 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:15:45 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:15:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-c95def0c-7be8-42f2-b422-6253936e3fb6/spark-3e6691bf-a7bf-4656-867c-be11dbfce4f7
24/09/19 20:15:45 INFO MemoryStore: MemoryStore cleared
24/09/19 20:15:45 INFO BlockManager: BlockManager stopped
24/09/19 20:15:45 INFO Worker: Executor app-20240919201537-0014/0 finished with state KILLED exitStatus 143
24/09/19 20:15:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:15:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919201537-0014, execId=0)
24/09/19 20:15:45 INFO ExternalShuffleBlockResolver: Application app-20240919201537-0014 removed, cleanupLocalDirs = true
24/09/19 20:15:45 INFO Worker: Cleaning up local directories for application app-20240919201537-0014
24/09/19 20:17:41 INFO Worker: Asked to launch executor app-20240919201741-0015/0 for DimensaoTempoComIDPortugues
24/09/19 20:17:41 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:17:41 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:17:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:17:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:17:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:17:41 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40343" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40343" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919201741-0015" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:17:42 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1301@81fa745d0ef3
24/09/19 20:17:42 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:17:42 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:17:42 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:17:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:17:43 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:17:43 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:17:43 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:17:43 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:17:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:17:43 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40343 after 64 ms (0 ms spent in bootstraps)
24/09/19 20:17:44 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:17:44 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:17:44 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:17:44 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:17:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:17:44 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40343 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:17:44 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/blockmgr-e5e8aac4-b5b2-4dd1-93f5-fce6f6315cd9
24/09/19 20:17:44 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:17:44 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40343
24/09/19 20:17:44 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:17:44 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:17:44 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:17:44 INFO ResourceUtils: ==============================================================
24/09/19 20:17:44 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:17:44 INFO ResourceUtils: ==============================================================
24/09/19 20:17:44 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:17:44 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:17:44 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:17:44 INFO Executor: Java version 17.0.12
24/09/19 20:17:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33449.
24/09/19 20:17:44 INFO NettyBlockTransferService: Server created on 172.22.0.4:33449
24/09/19 20:17:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:17:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 33449, None)
24/09/19 20:17:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 33449, None)
24/09/19 20:17:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 33449, None)
24/09/19 20:17:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:17:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7aeea835 for default.
24/09/19 20:17:44 INFO Executor: Fetching spark://dc42800f0e25:40343/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777060430
24/09/19 20:17:44 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40343 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:17:44 INFO Utils: Fetching spark://dc42800f0e25:40343/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/fetchFileTemp1436787914336193910.tmp
24/09/19 20:17:44 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/1217716841726777060430_cache to /opt/bitnami/spark/work/app-20240919201741-0015/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:17:44 INFO Executor: Fetching spark://dc42800f0e25:40343/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777060430
24/09/19 20:17:44 INFO Utils: Fetching spark://dc42800f0e25:40343/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/fetchFileTemp6585877868026698433.tmp
24/09/19 20:17:44 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/21131257481726777060430_cache to /opt/bitnami/spark/work/app-20240919201741-0015/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:17:44 INFO Executor: Fetching spark://dc42800f0e25:40343/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777060430
24/09/19 20:17:44 INFO Utils: Fetching spark://dc42800f0e25:40343/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/fetchFileTemp7358116392081932469.tmp
24/09/19 20:17:44 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/20200238031726777060430_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201741-0015/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:17:44 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201741-0015/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:17:44 INFO Executor: Fetching spark://dc42800f0e25:40343/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777060430
24/09/19 20:17:44 INFO Utils: Fetching spark://dc42800f0e25:40343/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/fetchFileTemp6471243318906085114.tmp
24/09/19 20:17:44 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc/15282150191726777060430_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201741-0015/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:17:44 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201741-0015/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:17:46 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:17:46 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:17:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:17:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:17:46 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:17:46 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42317 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:17:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.4 MiB)
24/09/19 20:17:46 INFO TorrentBroadcast: Reading broadcast variable 0 took 130 ms
24/09/19 20:17:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 42.7 KiB, free 434.3 MiB)
24/09/19 20:17:47 INFO CodeGenerator: Code generated in 196.556993 ms
24/09/19 20:17:48 INFO CodeGenerator: Code generated in 51.648376 ms
24/09/19 20:17:49 INFO PythonRunner: Times: total = 613, boot = 485, init = 126, finish = 2
24/09/19 20:17:49 INFO PythonRunner: Times: total = 594, boot = 482, init = 112, finish = 0
24/09/19 20:17:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 20:17:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 20:17:49 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:17:49 INFO Worker: Asked to kill executor app-20240919201741-0015/0
24/09/19 20:17:49 INFO ExecutorRunner: Runner thread for executor app-20240919201741-0015/0 interrupted
24/09/19 20:17:49 INFO ExecutorRunner: Killing process!
24/09/19 20:17:49 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:17:49 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:17:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8eba516c-2f15-47fb-a99f-afa577a518d5/spark-3eb7334b-fde0-464e-ad26-d852218330fc
24/09/19 20:17:49 INFO MemoryStore: MemoryStore cleared
24/09/19 20:17:49 INFO BlockManager: BlockManager stopped
24/09/19 20:17:49 INFO Worker: Executor app-20240919201741-0015/0 finished with state KILLED exitStatus 143
24/09/19 20:17:49 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:17:49 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919201741-0015, execId=0)
24/09/19 20:17:49 INFO ExternalShuffleBlockResolver: Application app-20240919201741-0015 removed, cleanupLocalDirs = true
24/09/19 20:17:49 INFO Worker: Cleaning up local directories for application app-20240919201741-0015
24/09/19 20:18:23 INFO Worker: Asked to launch executor app-20240919201823-0016/0 for DimensaoTempoComIDPortugues
24/09/19 20:18:23 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:18:23 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:18:23 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:18:23 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:18:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:18:23 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46701" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:46701" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919201823-0016" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:18:24 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1416@81fa745d0ef3
24/09/19 20:18:24 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:18:24 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:18:24 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:18:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:18:25 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:18:25 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:18:25 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:18:25 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:18:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:18:25 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46701 after 54 ms (0 ms spent in bootstraps)
24/09/19 20:18:25 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:18:25 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:18:25 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:18:25 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:18:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:18:25 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46701 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:18:25 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/blockmgr-57fd6ebb-a08c-4af1-af7d-f17e86fcf281
24/09/19 20:18:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:18:25 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:46701
24/09/19 20:18:25 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:18:25 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:18:25 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:18:25 INFO ResourceUtils: ==============================================================
24/09/19 20:18:25 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:18:25 INFO ResourceUtils: ==============================================================
24/09/19 20:18:25 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:18:25 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:18:25 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:18:25 INFO Executor: Java version 17.0.12
24/09/19 20:18:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44271.
24/09/19 20:18:25 INFO NettyBlockTransferService: Server created on 172.22.0.4:44271
24/09/19 20:18:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:18:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44271, None)
24/09/19 20:18:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44271, None)
24/09/19 20:18:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44271, None)
24/09/19 20:18:25 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:18:25 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:18:25 INFO Executor: Fetching spark://dc42800f0e25:46701/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777102703
24/09/19 20:18:26 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46701 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:18:26 INFO Utils: Fetching spark://dc42800f0e25:46701/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/fetchFileTemp14908563428675999967.tmp
24/09/19 20:18:26 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/-18205639161726777102703_cache to /opt/bitnami/spark/work/app-20240919201823-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:18:26 INFO Executor: Fetching spark://dc42800f0e25:46701/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777102703
24/09/19 20:18:26 INFO Utils: Fetching spark://dc42800f0e25:46701/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/fetchFileTemp7995366673929105358.tmp
24/09/19 20:18:26 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/-17054311961726777102703_cache to /opt/bitnami/spark/work/app-20240919201823-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:18:26 INFO Executor: Fetching spark://dc42800f0e25:46701/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777102703
24/09/19 20:18:26 INFO Utils: Fetching spark://dc42800f0e25:46701/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/fetchFileTemp11099619579430822318.tmp
24/09/19 20:18:26 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/18849149871726777102703_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201823-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:18:26 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201823-0016/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:18:26 INFO Executor: Fetching spark://dc42800f0e25:46701/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777102703
24/09/19 20:18:26 INFO Utils: Fetching spark://dc42800f0e25:46701/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/fetchFileTemp8778515232414343934.tmp
24/09/19 20:18:26 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839/7847519311726777102703_cache has been previously copied to /opt/bitnami/spark/work/app-20240919201823-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:18:26 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919201823-0016/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:18:27 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:18:27 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:18:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:18:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:18:27 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:18:27 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41885 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:18:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 434.4 MiB)
24/09/19 20:18:27 INFO TorrentBroadcast: Reading broadcast variable 0 took 87 ms
24/09/19 20:18:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 40.5 KiB, free 434.3 MiB)
24/09/19 20:18:28 INFO CodeGenerator: Code generated in 172.267203 ms
24/09/19 20:18:28 INFO CodeGenerator: Code generated in 28.097647 ms
24/09/19 20:18:29 INFO PythonRunner: Times: total = 632, boot = 530, init = 101, finish = 1
24/09/19 20:18:29 INFO PythonRunner: Times: total = 636, boot = 527, init = 108, finish = 1
24/09/19 20:18:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1750 bytes result sent to driver
24/09/19 20:18:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1750 bytes result sent to driver
24/09/19 20:18:29 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:18:29 INFO Worker: Asked to kill executor app-20240919201823-0016/0
24/09/19 20:18:29 INFO ExecutorRunner: Runner thread for executor app-20240919201823-0016/0 interrupted
24/09/19 20:18:29 INFO ExecutorRunner: Killing process!
24/09/19 20:18:29 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:18:29 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:18:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-d9d78dfd-2d3f-4099-8ffa-d839fdfe5d19/spark-9ba15527-804d-486b-999f-957dd2f5d839
24/09/19 20:18:29 INFO MemoryStore: MemoryStore cleared
24/09/19 20:18:29 INFO BlockManager: BlockManager stopped
24/09/19 20:18:29 INFO Worker: Executor app-20240919201823-0016/0 finished with state KILLED exitStatus 143
24/09/19 20:18:29 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:18:29 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919201823-0016, execId=0)
24/09/19 20:18:29 INFO ExternalShuffleBlockResolver: Application app-20240919201823-0016 removed, cleanupLocalDirs = true
24/09/19 20:18:29 INFO Worker: Cleaning up local directories for application app-20240919201823-0016
24/09/19 20:20:34 INFO Worker: Asked to launch executor app-20240919202034-0017/0 for DimensaoTempoComIDPortugues
24/09/19 20:20:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:20:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:20:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:20:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:20:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:20:34 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46759" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:46759" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919202034-0017" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:20:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1523@81fa745d0ef3
24/09/19 20:20:35 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:20:35 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:20:35 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:20:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:20:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:20:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:20:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:20:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:20:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:20:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46759 after 58 ms (0 ms spent in bootstraps)
24/09/19 20:20:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:20:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:20:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:20:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:20:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:20:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46759 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:20:36 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/blockmgr-5964d51d-bb8c-4230-975a-28e754e7fc1e
24/09/19 20:20:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:20:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:46759
24/09/19 20:20:36 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:20:36 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:20:36 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:20:36 INFO ResourceUtils: ==============================================================
24/09/19 20:20:36 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:20:36 INFO ResourceUtils: ==============================================================
24/09/19 20:20:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:20:36 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:20:36 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:20:36 INFO Executor: Java version 17.0.12
24/09/19 20:20:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44031.
24/09/19 20:20:37 INFO NettyBlockTransferService: Server created on 172.22.0.4:44031
24/09/19 20:20:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:20:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44031, None)
24/09/19 20:20:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44031, None)
24/09/19 20:20:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44031, None)
24/09/19 20:20:37 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:20:37 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:20:37 INFO Executor: Fetching spark://dc42800f0e25:46759/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777233586
24/09/19 20:20:37 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46759 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:20:37 INFO Utils: Fetching spark://dc42800f0e25:46759/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/fetchFileTemp12390527183193167130.tmp
24/09/19 20:20:37 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/-16789582651726777233586_cache to /opt/bitnami/spark/work/app-20240919202034-0017/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:20:37 INFO Executor: Fetching spark://dc42800f0e25:46759/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777233586
24/09/19 20:20:37 INFO Utils: Fetching spark://dc42800f0e25:46759/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/fetchFileTemp12011476900496211795.tmp
24/09/19 20:20:37 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/1316122471726777233586_cache to /opt/bitnami/spark/work/app-20240919202034-0017/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:20:37 INFO Executor: Fetching spark://dc42800f0e25:46759/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777233586
24/09/19 20:20:37 INFO Utils: Fetching spark://dc42800f0e25:46759/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/fetchFileTemp12043723352269131934.tmp
24/09/19 20:20:37 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/12633673521726777233586_cache has been previously copied to /opt/bitnami/spark/work/app-20240919202034-0017/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:20:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919202034-0017/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:20:37 INFO Executor: Fetching spark://dc42800f0e25:46759/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777233586
24/09/19 20:20:37 INFO Utils: Fetching spark://dc42800f0e25:46759/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/fetchFileTemp8279022592900510364.tmp
24/09/19 20:20:37 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155/13315796241726777233586_cache has been previously copied to /opt/bitnami/spark/work/app-20240919202034-0017/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:20:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919202034-0017/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:20:38 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:20:38 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:20:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:20:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:20:38 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:20:38 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41441 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:20:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
24/09/19 20:20:38 INFO TorrentBroadcast: Reading broadcast variable 0 took 120 ms
24/09/19 20:20:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
24/09/19 20:20:39 INFO CodeGenerator: Code generated in 158.439568 ms
24/09/19 20:20:39 INFO PythonRunner: Times: total = 570, boot = 466, init = 103, finish = 1
24/09/19 20:20:39 INFO PythonRunner: Times: total = 563, boot = 464, init = 99, finish = 0
24/09/19 20:20:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2214 bytes result sent to driver
24/09/19 20:20:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2171 bytes result sent to driver
24/09/19 20:20:40 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:20:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 20:20:40 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:20:40 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:20:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 434.4 MiB)
24/09/19 20:20:40 INFO TorrentBroadcast: Reading broadcast variable 1 took 14 ms
24/09/19 20:20:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.1 KiB, free 434.3 MiB)
24/09/19 20:20:40 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:20:40 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:46759)
24/09/19 20:20:40 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:20:40 INFO ShuffleBlockFetcherIterator: Getting 2 (10.4 KiB) non-empty blocks including 2 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 20.753699 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 13.64051 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 12.054402 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 9.917151 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 6.934897 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 7.8186 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 7.774569 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 5.658295 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 20.296926 ms
24/09/19 20:20:40 INFO CodeGenerator: Code generated in 23.99833 ms
24/09/19 20:20:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4613 bytes result sent to driver
24/09/19 20:20:41 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:20:41 INFO Worker: Asked to kill executor app-20240919202034-0017/0
24/09/19 20:20:41 INFO ExecutorRunner: Runner thread for executor app-20240919202034-0017/0 interrupted
24/09/19 20:20:41 INFO ExecutorRunner: Killing process!
24/09/19 20:20:41 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:20:41 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:20:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-2e808bc7-26ec-45e2-90cb-82e1859e7def/spark-235aca57-5145-4c25-9bb0-d13567760155
24/09/19 20:20:41 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:46759 disconnected during shutdown
24/09/19 20:20:41 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:46759 disconnected during shutdown
24/09/19 20:20:42 INFO Worker: Executor app-20240919202034-0017/0 finished with state KILLED exitStatus 143
24/09/19 20:20:42 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:20:42 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919202034-0017, execId=0)
24/09/19 20:20:42 INFO ExternalShuffleBlockResolver: Application app-20240919202034-0017 removed, cleanupLocalDirs = true
24/09/19 20:20:42 INFO Worker: Cleaning up local directories for application app-20240919202034-0017
24/09/19 20:25:48 INFO Worker: Asked to launch executor app-20240919202548-0018/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:25:48 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:25:48 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:25:48 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:25:48 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:25:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:25:48 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38947" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:38947" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919202548-0018" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:25:49 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1631@81fa745d0ef3
24/09/19 20:25:49 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:25:49 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:25:49 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:25:49 INFO Worker: Asked to kill executor app-20240919202548-0018/0
24/09/19 20:25:49 INFO ExecutorRunner: Runner thread for executor app-20240919202548-0018/0 interrupted
24/09/19 20:25:49 INFO ExecutorRunner: Killing process!
24/09/19 20:25:49 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:25:49 INFO Worker: Executor app-20240919202548-0018/0 finished with state KILLED exitStatus 143
24/09/19 20:25:49 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:25:49 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919202548-0018, execId=0)
24/09/19 20:25:49 INFO ExternalShuffleBlockResolver: Application app-20240919202548-0018 removed, cleanupLocalDirs = true
24/09/19 20:25:49 INFO Worker: Cleaning up local directories for application app-20240919202548-0018
24/09/19 20:26:13 INFO Worker: Asked to launch executor app-20240919202613-0019/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:26:13 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:26:13 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:26:13 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:26:13 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:26:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:26:13 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41159" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:41159" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919202613-0019" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:26:14 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1668@81fa745d0ef3
24/09/19 20:26:14 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:26:14 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:26:14 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:26:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:26:15 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:26:15 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:26:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:26:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:26:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:26:15 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41159 after 52 ms (0 ms spent in bootstraps)
24/09/19 20:26:15 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:26:15 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:26:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:26:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:26:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:26:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41159 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:26:16 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/blockmgr-8c05ab45-e160-488f-bb03-352e1c687171
24/09/19 20:26:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:26:16 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:41159
24/09/19 20:26:16 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:26:16 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 14 ms (0 ms spent in bootstraps)
24/09/19 20:26:16 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:26:16 INFO ResourceUtils: ==============================================================
24/09/19 20:26:16 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:26:16 INFO ResourceUtils: ==============================================================
24/09/19 20:26:16 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:26:16 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:26:16 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:26:16 INFO Executor: Java version 17.0.12
24/09/19 20:26:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44741.
24/09/19 20:26:16 INFO NettyBlockTransferService: Server created on 172.22.0.4:44741
24/09/19 20:26:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:26:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44741, None)
24/09/19 20:26:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44741, None)
24/09/19 20:26:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44741, None)
24/09/19 20:26:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:26:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:26:16 INFO Executor: Fetching spark://dc42800f0e25:41159/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777572660
24/09/19 20:26:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41159 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:26:16 INFO Utils: Fetching spark://dc42800f0e25:41159/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/fetchFileTemp6906161010141375244.tmp
24/09/19 20:26:16 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/6379395741726777572660_cache to /opt/bitnami/spark/work/app-20240919202613-0019/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:26:16 INFO Executor: Fetching spark://dc42800f0e25:41159/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777572660
24/09/19 20:26:16 INFO Utils: Fetching spark://dc42800f0e25:41159/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/fetchFileTemp10325001347277937323.tmp
24/09/19 20:26:16 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/-9057405061726777572660_cache to /opt/bitnami/spark/work/app-20240919202613-0019/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:26:16 INFO Executor: Fetching spark://dc42800f0e25:41159/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777572660
24/09/19 20:26:16 INFO Utils: Fetching spark://dc42800f0e25:41159/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/fetchFileTemp6210200274122499269.tmp
24/09/19 20:26:16 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/-14912461511726777572660_cache has been previously copied to /opt/bitnami/spark/work/app-20240919202613-0019/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:26:16 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919202613-0019/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:26:16 INFO Executor: Fetching spark://dc42800f0e25:41159/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777572660
24/09/19 20:26:16 INFO Utils: Fetching spark://dc42800f0e25:41159/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/fetchFileTemp17157426478613177360.tmp
24/09/19 20:26:16 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8/20492587931726777572660_cache has been previously copied to /opt/bitnami/spark/work/app-20240919202613-0019/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:26:16 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919202613-0019/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:26:17 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:26:17 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:26:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:26:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:26:17 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:26:17 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:26:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:33731 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:26:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 434.4 MiB)
24/09/19 20:26:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
24/09/19 20:26:18 INFO TorrentBroadcast: Reading broadcast variable 1 took 97 ms
24/09/19 20:26:18 INFO TorrentBroadcast: Reading broadcast variable 0 took 97 ms
24/09/19 20:26:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.2 KiB, free 434.3 MiB)
24/09/19 20:26:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 23.9 KiB, free 434.3 MiB)
24/09/19 20:26:18 INFO JDBCRDD: closed connection
24/09/19 20:26:18 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)
org.postgresql.util.PSQLException: ERROR: column "data" does not exist
  Hint: Perhaps you meant to reference the column "dim_tempo.dia".
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:26:18 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:26:18 INFO Executor: Running task 0.1 in stage 1.0 (TID 2)
24/09/19 20:26:18 INFO JDBCRDD: closed connection
24/09/19 20:26:18 ERROR Executor: Exception in task 0.1 in stage 1.0 (TID 2)
org.postgresql.util.PSQLException: ERROR: column "data" does not exist
  Hint: Perhaps you meant to reference the column "dim_tempo.dia".
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:26:18 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:26:18 INFO Executor: Running task 0.2 in stage 1.0 (TID 3)
24/09/19 20:26:18 INFO JDBCRDD: closed connection
24/09/19 20:26:18 ERROR Executor: Exception in task 0.2 in stage 1.0 (TID 3)
org.postgresql.util.PSQLException: ERROR: column "data" does not exist
  Hint: Perhaps you meant to reference the column "dim_tempo.dia".
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:26:18 INFO CoarseGrainedExecutorBackend: Got assigned task 4
24/09/19 20:26:18 INFO Executor: Running task 0.3 in stage 1.0 (TID 4)
24/09/19 20:26:18 INFO JDBCRDD: closed connection
24/09/19 20:26:18 ERROR Executor: Exception in task 0.3 in stage 1.0 (TID 4)
org.postgresql.util.PSQLException: ERROR: column "data" does not exist
  Hint: Perhaps you meant to reference the column "dim_tempo.dia".
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:26:18 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled: Job 0 cancelled 
24/09/19 20:26:18 INFO CodeGenerator: Code generated in 201.314245 ms
24/09/19 20:26:18 INFO CodeGenerator: Code generated in 27.00179 ms
24/09/19 20:26:18 INFO JDBCRDD: closed connection
24/09/19 20:26:18 INFO Executor: Executor killed task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled: Job 0 cancelled 
24/09/19 20:26:18 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:26:18 INFO Worker: Asked to kill executor app-20240919202613-0019/0
24/09/19 20:26:18 INFO ExecutorRunner: Runner thread for executor app-20240919202613-0019/0 interrupted
24/09/19 20:26:18 INFO ExecutorRunner: Killing process!
24/09/19 20:26:18 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:26:18 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:26:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8790eb04-69e9-4140-a428-0a094b567e4a/spark-34979037-fc7f-49bb-bbb5-16849211b3f8
24/09/19 20:26:18 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:41159 disconnected during shutdown
24/09/19 20:26:19 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:41159 disconnected during shutdown
24/09/19 20:26:19 INFO MemoryStore: MemoryStore cleared
24/09/19 20:26:19 INFO BlockManager: BlockManager stopped
24/09/19 20:26:19 INFO Worker: Executor app-20240919202613-0019/0 finished with state KILLED exitStatus 143
24/09/19 20:26:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:26:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919202613-0019, execId=0)
24/09/19 20:26:19 INFO ExternalShuffleBlockResolver: Application app-20240919202613-0019 removed, cleanupLocalDirs = true
24/09/19 20:26:19 INFO Worker: Cleaning up local directories for application app-20240919202613-0019
24/09/19 20:28:34 INFO Worker: Asked to launch executor app-20240919202834-0020/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:28:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:28:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:28:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:28:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:28:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:28:34 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38601" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:38601" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919202834-0020" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:28:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1762@81fa745d0ef3
24/09/19 20:28:35 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:28:35 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:28:35 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:28:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:28:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:28:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:28:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:28:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:28:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:28:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38601 after 54 ms (0 ms spent in bootstraps)
24/09/19 20:28:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:28:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:28:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:28:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:28:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:28:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38601 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:28:36 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8430866e-da7f-4bbd-bf58-99ddfef077ab/blockmgr-b943f071-7cfc-4228-b8cb-8f2cc3644b0d
24/09/19 20:28:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:28:37 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:38601
24/09/19 20:28:37 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:28:37 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:28:37 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:28:37 INFO ResourceUtils: ==============================================================
24/09/19 20:28:37 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:28:37 INFO ResourceUtils: ==============================================================
24/09/19 20:28:37 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:28:37 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:28:37 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:28:37 INFO Executor: Java version 17.0.12
24/09/19 20:28:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39425.
24/09/19 20:28:37 INFO NettyBlockTransferService: Server created on 172.22.0.4:39425
24/09/19 20:28:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:28:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 39425, None)
24/09/19 20:28:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 39425, None)
24/09/19 20:28:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 39425, None)
24/09/19 20:28:37 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:28:37 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:28:37 INFO Executor: Fetching spark://dc42800f0e25:38601/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777713886
24/09/19 20:28:37 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38601 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:28:37 INFO Worker: Asked to kill executor app-20240919202834-0020/0
24/09/19 20:28:37 INFO ExecutorRunner: Runner thread for executor app-20240919202834-0020/0 interrupted
24/09/19 20:28:37 INFO ExecutorRunner: Killing process!
24/09/19 20:28:37 INFO Utils: Fetching spark://dc42800f0e25:38601/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8430866e-da7f-4bbd-bf58-99ddfef077ab/spark-461cbba2-4ca9-465b-9f7a-87fef6f044b3/fetchFileTemp8716067349606345843.tmp
24/09/19 20:28:37 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:28:37 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8430866e-da7f-4bbd-bf58-99ddfef077ab/spark-461cbba2-4ca9-465b-9f7a-87fef6f044b3/4027284161726777713886_cache to /opt/bitnami/spark/work/app-20240919202834-0020/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:28:37 INFO MemoryStore: MemoryStore cleared
24/09/19 20:28:37 INFO BlockManager: BlockManager stopped
24/09/19 20:28:37 INFO Executor: Fetching spark://dc42800f0e25:38601/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777713886
24/09/19 20:28:37 INFO TransportClientFactory: Found inactive connection to dc42800f0e25/172.22.0.5:38601, creating a new one.
24/09/19 20:28:37 ERROR Utils: Aborting task
java.io.IOException: Failed to connect to dc42800f0e25/172.22.0.5:38601
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)
	at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:709)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:454)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5(Executor.scala:1136)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5$adapted(Executor.scala:1133)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:273)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at org.apache.spark.executor.Executor.updateDependencies(Executor.scala:1133)
	at org.apache.spark.executor.Executor.<init>(Executor.scala:330)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:181)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dc42800f0e25/172.22.0.5:38601
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:28:37 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Failed to connect to dc42800f0e25/172.22.0.5:38601
java.io.IOException: Failed to connect to dc42800f0e25/172.22.0.5:38601
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)
	at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:709)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:454)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5(Executor.scala:1136)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5$adapted(Executor.scala:1133)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:273)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at org.apache.spark.executor.Executor.updateDependencies(Executor.scala:1133)
	at org.apache.spark.executor.Executor.<init>(Executor.scala:330)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:181)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dc42800f0e25/172.22.0.5:38601
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:28:37 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:28:37 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:38601 disconnected during shutdown
24/09/19 20:28:37 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:38601 disconnected during shutdown
24/09/19 20:28:37 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:28:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-8430866e-da7f-4bbd-bf58-99ddfef077ab/spark-461cbba2-4ca9-465b-9f7a-87fef6f044b3
24/09/19 20:28:37 INFO Worker: Executor app-20240919202834-0020/0 finished with state KILLED exitStatus 143
24/09/19 20:28:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:28:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919202834-0020, execId=0)
24/09/19 20:28:37 INFO ExternalShuffleBlockResolver: Application app-20240919202834-0020 removed, cleanupLocalDirs = true
24/09/19 20:28:37 INFO Worker: Cleaning up local directories for application app-20240919202834-0020
24/09/19 20:29:40 INFO Worker: Asked to launch executor app-20240919202940-0021/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:29:40 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:29:40 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:29:40 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:29:40 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:29:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:29:40 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42673" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:42673" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919202940-0021" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:29:41 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1844@81fa745d0ef3
24/09/19 20:29:41 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:29:41 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:29:41 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:29:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:29:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:29:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:29:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:29:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:29:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:29:41 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42673 after 49 ms (0 ms spent in bootstraps)
24/09/19 20:29:42 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:29:42 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:29:42 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:29:42 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:29:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:29:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42673 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:29:42 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-359af0a4-eeb9-4bea-8aa9-1ca49938e298/blockmgr-532e22dc-c797-4f2c-82a3-bd095306c0fd
24/09/19 20:29:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:29:42 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:42673
24/09/19 20:29:42 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:29:42 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:29:42 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:29:42 INFO ResourceUtils: ==============================================================
24/09/19 20:29:42 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:29:42 INFO ResourceUtils: ==============================================================
24/09/19 20:29:42 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:29:42 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:29:42 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:29:42 INFO Executor: Java version 17.0.12
24/09/19 20:29:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42463.
24/09/19 20:29:42 INFO NettyBlockTransferService: Server created on 172.22.0.4:42463
24/09/19 20:29:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:29:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 42463, None)
24/09/19 20:29:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 42463, None)
24/09/19 20:29:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 42463, None)
24/09/19 20:29:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:29:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5e4e04a3 for default.
24/09/19 20:29:42 INFO Executor: Fetching spark://dc42800f0e25:42673/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777779253
24/09/19 20:29:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42673 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:29:42 INFO Utils: Fetching spark://dc42800f0e25:42673/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-359af0a4-eeb9-4bea-8aa9-1ca49938e298/spark-6ae4671a-cd92-4a78-8f93-33b27054a295/fetchFileTemp6184801065482836271.tmp
24/09/19 20:29:42 INFO Worker: Asked to kill executor app-20240919202940-0021/0
24/09/19 20:29:42 INFO ExecutorRunner: Runner thread for executor app-20240919202940-0021/0 interrupted
24/09/19 20:29:42 INFO ExecutorRunner: Killing process!
24/09/19 20:29:42 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:29:42 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-359af0a4-eeb9-4bea-8aa9-1ca49938e298/spark-6ae4671a-cd92-4a78-8f93-33b27054a295/18236680981726777779253_cache to /opt/bitnami/spark/work/app-20240919202940-0021/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:29:42 INFO MemoryStore: MemoryStore cleared
24/09/19 20:29:42 INFO Executor: Fetching spark://dc42800f0e25:42673/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777779253
24/09/19 20:29:42 INFO BlockManager: BlockManager stopped
24/09/19 20:29:42 ERROR TransportClient: Failed to send RPC /files/org.postgresql_postgresql-42.2.20.jar to dc42800f0e25/172.22.0.5:42673: io.netty.channel.StacklessClosedChannelException
io.netty.channel.StacklessClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/09/19 20:29:42 INFO Utils: Fetching spark://dc42800f0e25:42673/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-359af0a4-eeb9-4bea-8aa9-1ca49938e298/spark-6ae4671a-cd92-4a78-8f93-33b27054a295/fetchFileTemp10905538453273447203.tmp
24/09/19 20:29:42 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from dc42800f0e25/172.22.0.5:42673 is closed
24/09/19 20:29:42 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Failed to send RPC /files/org.postgresql_postgresql-42.2.20.jar to dc42800f0e25/172.22.0.5:42673: io.netty.channel.StacklessClosedChannelException
java.io.IOException: Failed to send RPC /files/org.postgresql_postgresql-42.2.20.jar to dc42800f0e25/172.22.0.5:42673: io.netty.channel.StacklessClosedChannelException
	at org.apache.spark.network.client.TransportClient$2.handleFailure(TransportClient.java:164)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:372)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:629)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:118)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:877)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:863)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:968)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:856)
	at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:113)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:881)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:863)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:968)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:856)
	at io.netty.handler.timeout.IdleStateHandler.write(IdleStateHandler.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:879)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:940)
	at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1247)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:566)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: io.netty.channel.StacklessClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/09/19 20:29:42 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:29:42 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:29:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-359af0a4-eeb9-4bea-8aa9-1ca49938e298/spark-6ae4671a-cd92-4a78-8f93-33b27054a295
24/09/19 20:29:42 INFO Worker: Executor app-20240919202940-0021/0 finished with state KILLED exitStatus 143
24/09/19 20:29:42 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:29:42 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919202940-0021, execId=0)
24/09/19 20:29:42 INFO ExternalShuffleBlockResolver: Application app-20240919202940-0021 removed, cleanupLocalDirs = true
24/09/19 20:29:42 INFO Worker: Cleaning up local directories for application app-20240919202940-0021
24/09/19 20:30:15 INFO Worker: Asked to launch executor app-20240919203015-0022/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:30:15 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:30:15 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:30:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:30:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:30:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:30:15 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32895" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:32895" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203015-0022" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:30:16 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1927@81fa745d0ef3
24/09/19 20:30:16 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:30:16 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:30:16 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:30:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:30:16 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:30:16 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:30:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:30:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:30:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:30:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:32895 after 51 ms (0 ms spent in bootstraps)
24/09/19 20:30:17 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:30:17 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:30:17 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:30:17 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:30:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:30:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:32895 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:30:17 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/blockmgr-68bab1b5-c77c-41c6-92dc-910b22fb4f65
24/09/19 20:30:17 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:30:17 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:32895
24/09/19 20:30:17 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:30:17 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:30:17 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:30:17 INFO ResourceUtils: ==============================================================
24/09/19 20:30:17 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:30:17 INFO ResourceUtils: ==============================================================
24/09/19 20:30:17 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:30:17 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:30:17 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:30:17 INFO Executor: Java version 17.0.12
24/09/19 20:30:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42101.
24/09/19 20:30:17 INFO NettyBlockTransferService: Server created on 172.22.0.4:42101
24/09/19 20:30:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:30:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 42101, None)
24/09/19 20:30:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 42101, None)
24/09/19 20:30:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 42101, None)
24/09/19 20:30:17 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:30:17 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@67c5f819 for default.
24/09/19 20:30:17 INFO Executor: Fetching spark://dc42800f0e25:32895/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777814530
24/09/19 20:30:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:32895 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:30:17 INFO Utils: Fetching spark://dc42800f0e25:32895/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/fetchFileTemp14486985497447139809.tmp
24/09/19 20:30:17 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/10839299871726777814530_cache to /opt/bitnami/spark/work/app-20240919203015-0022/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:30:17 INFO Executor: Fetching spark://dc42800f0e25:32895/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777814530
24/09/19 20:30:17 INFO Utils: Fetching spark://dc42800f0e25:32895/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/fetchFileTemp10766095061280512794.tmp
24/09/19 20:30:17 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/3015596991726777814530_cache to /opt/bitnami/spark/work/app-20240919203015-0022/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:30:18 INFO Executor: Fetching spark://dc42800f0e25:32895/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777814530
24/09/19 20:30:18 INFO Utils: Fetching spark://dc42800f0e25:32895/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/fetchFileTemp2098471595306898265.tmp
24/09/19 20:30:18 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/19748943801726777814530_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203015-0022/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:30:18 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203015-0022/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:30:18 INFO Executor: Fetching spark://dc42800f0e25:32895/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777814530
24/09/19 20:30:18 INFO Utils: Fetching spark://dc42800f0e25:32895/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/fetchFileTemp11304971053923150064.tmp
24/09/19 20:30:18 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3/14073968601726777814530_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203015-0022/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:30:18 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203015-0022/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:30:18 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:30:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:30:18 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:30:18 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38257 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:30:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 20:30:18 INFO TorrentBroadcast: Reading broadcast variable 0 took 105 ms
24/09/19 20:30:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 20:30:19 INFO CodeGenerator: Code generated in 173.919345 ms
24/09/19 20:30:19 INFO JDBCRDD: closed connection
24/09/19 20:30:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 20:30:20 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:30:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:30:20 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:30:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:30:20 INFO TorrentBroadcast: Reading broadcast variable 1 took 16 ms
24/09/19 20:30:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:30:20 INFO CodeGenerator: Code generated in 30.279664 ms
24/09/19 20:30:20 INFO JDBCRDD: closed connection
24/09/19 20:30:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1495 bytes result sent to driver
24/09/19 20:30:20 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:30:20 INFO Worker: Asked to kill executor app-20240919203015-0022/0
24/09/19 20:30:20 INFO ExecutorRunner: Runner thread for executor app-20240919203015-0022/0 interrupted
24/09/19 20:30:20 INFO ExecutorRunner: Killing process!
24/09/19 20:30:20 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:30:20 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:30:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-eed06996-e984-41ca-829e-43d5a4d685c3/spark-11cc0ce1-e12b-4190-866f-44fb63efddb3
24/09/19 20:30:20 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:32895 disconnected during shutdown
24/09/19 20:30:20 INFO MemoryStore: MemoryStore cleared
24/09/19 20:30:20 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:32895 disconnected during shutdown
24/09/19 20:30:20 INFO BlockManager: BlockManager stopped
24/09/19 20:30:20 INFO Worker: Executor app-20240919203015-0022/0 finished with state KILLED exitStatus 143
24/09/19 20:30:20 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:30:20 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203015-0022, execId=0)
24/09/19 20:30:20 INFO ExternalShuffleBlockResolver: Application app-20240919203015-0022 removed, cleanupLocalDirs = true
24/09/19 20:30:20 INFO Worker: Cleaning up local directories for application app-20240919203015-0022
24/09/19 20:31:07 INFO Worker: Asked to launch executor app-20240919203107-0023/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:31:07 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:31:07 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:31:07 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:07 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:31:07 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39659" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:39659" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203107-0023" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:31:08 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 2024@81fa745d0ef3
24/09/19 20:31:08 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:31:08 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:31:08 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:31:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:31:09 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:31:09 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:31:09 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:09 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:31:09 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39659 after 58 ms (0 ms spent in bootstraps)
24/09/19 20:31:10 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:31:10 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:31:10 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:10 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:31:10 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39659 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:31:10 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/blockmgr-1f8f857c-968f-4998-afca-897cdffc75bb
24/09/19 20:31:10 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:31:10 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:39659
24/09/19 20:31:10 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:31:10 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:31:10 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:31:10 INFO ResourceUtils: ==============================================================
24/09/19 20:31:10 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:31:10 INFO ResourceUtils: ==============================================================
24/09/19 20:31:10 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:31:10 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:31:10 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:31:10 INFO Executor: Java version 17.0.12
24/09/19 20:31:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37669.
24/09/19 20:31:10 INFO NettyBlockTransferService: Server created on 172.22.0.4:37669
24/09/19 20:31:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:31:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 37669, None)
24/09/19 20:31:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 37669, None)
24/09/19 20:31:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 37669, None)
24/09/19 20:31:10 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:31:10 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3e1f5e0c for default.
24/09/19 20:31:10 INFO Executor: Fetching spark://dc42800f0e25:39659/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777867114
24/09/19 20:31:10 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39659 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:31:10 INFO Utils: Fetching spark://dc42800f0e25:39659/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/fetchFileTemp13932875822853812446.tmp
24/09/19 20:31:10 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/8672108501726777867114_cache to /opt/bitnami/spark/work/app-20240919203107-0023/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:31:10 INFO Executor: Fetching spark://dc42800f0e25:39659/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777867114
24/09/19 20:31:10 INFO Utils: Fetching spark://dc42800f0e25:39659/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/fetchFileTemp2748134789507971825.tmp
24/09/19 20:31:10 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/10771752181726777867114_cache to /opt/bitnami/spark/work/app-20240919203107-0023/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:31:10 INFO Executor: Fetching spark://dc42800f0e25:39659/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777867114
24/09/19 20:31:10 INFO Utils: Fetching spark://dc42800f0e25:39659/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/fetchFileTemp15904026170062391763.tmp
24/09/19 20:31:10 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/-11999825951726777867114_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203107-0023/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:31:10 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203107-0023/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:31:10 INFO Executor: Fetching spark://dc42800f0e25:39659/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777867114
24/09/19 20:31:10 INFO Utils: Fetching spark://dc42800f0e25:39659/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/fetchFileTemp725391721951968681.tmp
24/09/19 20:31:10 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc/-13572325311726777867114_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203107-0023/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:31:10 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203107-0023/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:31:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:31:11 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:31:11 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45441 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:31:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:31:11 INFO TorrentBroadcast: Reading broadcast variable 0 took 100 ms
24/09/19 20:31:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:31:12 INFO CodeGenerator: Code generated in 195.536754 ms
24/09/19 20:31:12 INFO JDBCRDD: closed connection
24/09/19 20:31:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
24/09/19 20:31:12 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:31:12 INFO Worker: Asked to kill executor app-20240919203107-0023/0
24/09/19 20:31:12 INFO ExecutorRunner: Runner thread for executor app-20240919203107-0023/0 interrupted
24/09/19 20:31:12 INFO ExecutorRunner: Killing process!
24/09/19 20:31:12 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:31:12 INFO DiskBlockManager: Shutdown hook called
24/09/19 20:31:12 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:31:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-4c7a0d3b-6e2b-4619-ace5-edf23ecabeff/spark-3aa12aca-82cc-4d36-bfdb-c8d0258976cc
24/09/19 20:31:12 INFO MemoryStore: MemoryStore cleared
24/09/19 20:31:12 INFO BlockManager: BlockManager stopped
24/09/19 20:31:12 INFO Worker: Executor app-20240919203107-0023/0 finished with state KILLED exitStatus 143
24/09/19 20:31:12 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:31:12 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203107-0023, execId=0)
24/09/19 20:31:12 INFO ExternalShuffleBlockResolver: Application app-20240919203107-0023 removed, cleanupLocalDirs = true
24/09/19 20:31:12 INFO Worker: Cleaning up local directories for application app-20240919203107-0023
24/09/19 20:31:45 INFO Worker: Asked to launch executor app-20240919203145-0024/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:31:45 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:31:45 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:31:45 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:45 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:31:45 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40893" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40893" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203145-0024" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:31:46 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 2116@81fa745d0ef3
24/09/19 20:31:46 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:31:46 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:31:46 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:31:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:31:47 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:31:47 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:31:47 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:47 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:31:47 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40893 after 46 ms (0 ms spent in bootstraps)
24/09/19 20:31:47 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:31:47 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:31:47 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:31:47 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:31:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:31:47 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40893 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:31:47 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/blockmgr-b28ef5dd-f168-44f2-bccc-8ca512f90d56
24/09/19 20:31:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:31:47 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40893
24/09/19 20:31:47 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:31:47 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:31:47 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:31:47 INFO ResourceUtils: ==============================================================
24/09/19 20:31:47 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:31:47 INFO ResourceUtils: ==============================================================
24/09/19 20:31:47 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:31:47 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:31:47 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:31:47 INFO Executor: Java version 17.0.12
24/09/19 20:31:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34349.
24/09/19 20:31:47 INFO NettyBlockTransferService: Server created on 172.22.0.4:34349
24/09/19 20:31:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:31:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34349, None)
24/09/19 20:31:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34349, None)
24/09/19 20:31:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34349, None)
24/09/19 20:31:47 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:31:47 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:31:47 INFO Executor: Fetching spark://dc42800f0e25:40893/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777904603
24/09/19 20:31:47 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40893 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:31:47 INFO Utils: Fetching spark://dc42800f0e25:40893/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/fetchFileTemp12277748658955539628.tmp
24/09/19 20:31:47 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/-13650775001726777904603_cache to /opt/bitnami/spark/work/app-20240919203145-0024/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:31:47 INFO Executor: Fetching spark://dc42800f0e25:40893/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777904603
24/09/19 20:31:47 INFO Utils: Fetching spark://dc42800f0e25:40893/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/fetchFileTemp6966427654775933041.tmp
24/09/19 20:31:48 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/17561192521726777904603_cache to /opt/bitnami/spark/work/app-20240919203145-0024/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:31:48 INFO Executor: Fetching spark://dc42800f0e25:40893/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777904603
24/09/19 20:31:48 INFO Utils: Fetching spark://dc42800f0e25:40893/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/fetchFileTemp4744772998496692224.tmp
24/09/19 20:31:48 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/-18448838291726777904603_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203145-0024/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:31:48 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203145-0024/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:31:48 INFO Executor: Fetching spark://dc42800f0e25:40893/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777904603
24/09/19 20:31:48 INFO Utils: Fetching spark://dc42800f0e25:40893/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/fetchFileTemp8914425528839590226.tmp
24/09/19 20:31:48 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe/4844868111726777904603_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203145-0024/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:31:48 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203145-0024/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:31:48 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:31:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:31:48 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:31:48 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34253 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:31:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:31:48 INFO TorrentBroadcast: Reading broadcast variable 0 took 89 ms
24/09/19 20:31:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:31:49 INFO CodeGenerator: Code generated in 198.962774 ms
24/09/19 20:31:49 INFO JDBCRDD: closed connection
24/09/19 20:31:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
24/09/19 20:31:49 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:31:49 INFO Worker: Asked to kill executor app-20240919203145-0024/0
24/09/19 20:31:49 INFO ExecutorRunner: Runner thread for executor app-20240919203145-0024/0 interrupted
24/09/19 20:31:49 INFO ExecutorRunner: Killing process!
24/09/19 20:31:49 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:31:49 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:31:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0adeadb8-f3f2-4627-9074-b42b93794882/spark-69439130-d1d9-47f1-8849-dacf412f70fe
24/09/19 20:31:49 INFO MemoryStore: MemoryStore cleared
24/09/19 20:31:49 INFO BlockManager: BlockManager stopped
24/09/19 20:31:49 INFO Worker: Executor app-20240919203145-0024/0 finished with state KILLED exitStatus 143
24/09/19 20:31:49 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:31:49 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203145-0024, execId=0)
24/09/19 20:31:49 INFO Worker: Cleaning up local directories for application app-20240919203145-0024
24/09/19 20:31:49 INFO ExternalShuffleBlockResolver: Application app-20240919203145-0024 removed, cleanupLocalDirs = true
24/09/19 20:32:34 INFO Worker: Asked to launch executor app-20240919203234-0025/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:32:34 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:32:34 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:32:34 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:32:34 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:32:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:32:34 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41585" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:41585" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203234-0025" "--worker-url" "spark://Worker@172.22.0.4:36297" "--resourceProfileId" "0"
24/09/19 20:32:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 2208@81fa745d0ef3
24/09/19 20:32:35 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:32:35 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:32:35 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:32:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:32:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:32:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:32:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:32:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:32:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:32:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41585 after 79 ms (0 ms spent in bootstraps)
24/09/19 20:32:36 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:32:36 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:32:36 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:32:36 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:32:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:32:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41585 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:32:36 INFO DiskBlockManager: Created local directory at /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/blockmgr-8a3488c1-5709-438b-b14d-18a2ae00d477
24/09/19 20:32:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:32:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:41585
24/09/19 20:32:36 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:36297
24/09/19 20:32:36 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:36297 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:32:36 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:36297
24/09/19 20:32:36 INFO ResourceUtils: ==============================================================
24/09/19 20:32:36 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:32:36 INFO ResourceUtils: ==============================================================
24/09/19 20:32:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:32:36 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:32:36 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:32:36 INFO Executor: Java version 17.0.12
24/09/19 20:32:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34547.
24/09/19 20:32:36 INFO NettyBlockTransferService: Server created on 172.22.0.4:34547
24/09/19 20:32:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:32:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34547, None)
24/09/19 20:32:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34547, None)
24/09/19 20:32:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34547, None)
24/09/19 20:32:36 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:32:36 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:32:36 INFO Executor: Fetching spark://dc42800f0e25:41585/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777953757
24/09/19 20:32:36 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41585 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:32:37 INFO Utils: Fetching spark://dc42800f0e25:41585/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/fetchFileTemp11470191515081010822.tmp
24/09/19 20:32:37 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/-11102844611726777953757_cache to /opt/bitnami/spark/work/app-20240919203234-0025/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:32:37 INFO Executor: Fetching spark://dc42800f0e25:41585/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777953757
24/09/19 20:32:37 INFO Utils: Fetching spark://dc42800f0e25:41585/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/fetchFileTemp2844597212683147917.tmp
24/09/19 20:32:37 INFO Utils: Copying /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/20517758111726777953757_cache to /opt/bitnami/spark/work/app-20240919203234-0025/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:32:37 INFO Executor: Fetching spark://dc42800f0e25:41585/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777953757
24/09/19 20:32:37 INFO Utils: Fetching spark://dc42800f0e25:41585/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/fetchFileTemp14421959590746869918.tmp
24/09/19 20:32:37 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/13618535001726777953757_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203234-0025/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:32:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203234-0025/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:32:37 INFO Executor: Fetching spark://dc42800f0e25:41585/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777953757
24/09/19 20:32:37 INFO Utils: Fetching spark://dc42800f0e25:41585/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/fetchFileTemp16945203753405043027.tmp
24/09/19 20:32:37 INFO Utils: /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55/8977365561726777953757_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203234-0025/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:32:37 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203234-0025/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:32:37 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:32:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:32:37 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:32:37 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38155 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:32:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:32:38 INFO TorrentBroadcast: Reading broadcast variable 0 took 104 ms
24/09/19 20:32:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:32:38 INFO CodeGenerator: Code generated in 175.207112 ms
24/09/19 20:32:38 INFO JDBCRDD: closed connection
24/09/19 20:32:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
24/09/19 20:32:38 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:32:38 INFO Worker: Asked to kill executor app-20240919203234-0025/0
24/09/19 20:32:38 INFO ExecutorRunner: Runner thread for executor app-20240919203234-0025/0 interrupted
24/09/19 20:32:38 INFO ExecutorRunner: Killing process!
24/09/19 20:32:38 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:32:38 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:32:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47/executor-0c57c533-bc3c-4dc6-9010-884b984e252c/spark-24552d75-7a7d-49de-a36d-f5f536752c55
24/09/19 20:32:38 INFO MemoryStore: MemoryStore cleared
24/09/19 20:32:38 INFO BlockManager: BlockManager stopped
24/09/19 20:32:38 INFO Worker: Executor app-20240919203234-0025/0 finished with state KILLED exitStatus 143
24/09/19 20:32:38 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:32:38 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203234-0025, execId=0)
24/09/19 20:32:38 INFO ExternalShuffleBlockResolver: Application app-20240919203234-0025 removed, cleanupLocalDirs = true
24/09/19 20:32:38 INFO Worker: Cleaning up local directories for application app-20240919203234-0025
24/09/19 20:33:04 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 20:33:04 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:33:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b0c8a95-6e3d-41ca-84ef-d342820c0d47
24/09/19 20:33:06 INFO Worker: Started daemon with process name: 1@81fa745d0ef3
24/09/19 20:33:06 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:33:06 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:33:06 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:33:07 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:33:07 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:33:07 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:33:07 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:33:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:33:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:33:07 INFO Utils: Successfully started service 'sparkWorker' on port 38099.
24/09/19 20:33:07 INFO Worker: Worker decommissioning not enabled.
24/09/19 20:33:07 INFO Worker: Starting Spark worker 172.22.0.4:38099 with 2 cores, 1024.0 MiB RAM
24/09/19 20:33:07 INFO Worker: Running Spark version 3.5.2
24/09/19 20:33:07 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 20:33:07 INFO ResourceUtils: ==============================================================
24/09/19 20:33:07 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 20:33:07 INFO ResourceUtils: ==============================================================
24/09/19 20:33:07 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 20:33:07 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 20:33:07 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://81fa745d0ef3:8081
24/09/19 20:33:07 INFO Worker: Connecting to master spark-master:7077...
24/09/19 20:33:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.22.0.2:7077 after 22 ms (0 ms spent in bootstraps)
24/09/19 20:33:07 INFO Worker: Successfully registered with master spark://172.22.0.2:7077
24/09/19 20:33:16 INFO Worker: Asked to launch executor app-20240919203316-0026/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:33:16 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:33:16 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:33:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:33:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:33:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:33:16 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38605" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:38605" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203316-0026" "--worker-url" "spark://Worker@172.22.0.4:38099" "--resourceProfileId" "0"
24/09/19 20:33:17 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 112@81fa745d0ef3
24/09/19 20:33:17 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:33:17 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:33:17 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:33:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:33:17 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:33:17 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:33:17 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:33:17 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:33:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:33:18 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38605 after 53 ms (0 ms spent in bootstraps)
24/09/19 20:33:18 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:33:18 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:33:18 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:33:18 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:33:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:33:18 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38605 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:33:18 INFO DiskBlockManager: Created local directory at /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/blockmgr-8d39b45d-5d43-4e42-b632-3dad1734e973
24/09/19 20:33:18 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:33:18 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:38605
24/09/19 20:33:18 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:38099
24/09/19 20:33:18 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:38099 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:33:18 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:38099
24/09/19 20:33:18 INFO ResourceUtils: ==============================================================
24/09/19 20:33:18 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:33:18 INFO ResourceUtils: ==============================================================
24/09/19 20:33:18 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:33:18 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:33:18 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:33:18 INFO Executor: Java version 17.0.12
24/09/19 20:33:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41277.
24/09/19 20:33:18 INFO NettyBlockTransferService: Server created on 172.22.0.4:41277
24/09/19 20:33:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:33:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 41277, None)
24/09/19 20:33:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 41277, None)
24/09/19 20:33:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 41277, None)
24/09/19 20:33:18 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:33:18 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:33:18 INFO Executor: Fetching spark://dc42800f0e25:38605/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777995332
24/09/19 20:33:18 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38605 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:33:18 INFO Utils: Fetching spark://dc42800f0e25:38605/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/fetchFileTemp15321304622030860289.tmp
24/09/19 20:33:18 INFO Utils: Copying /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/-576092921726777995332_cache to /opt/bitnami/spark/work/app-20240919203316-0026/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:33:18 INFO Executor: Fetching spark://dc42800f0e25:38605/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777995332
24/09/19 20:33:18 INFO Utils: Fetching spark://dc42800f0e25:38605/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/fetchFileTemp11836625708629249557.tmp
24/09/19 20:33:18 INFO Utils: Copying /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/6405234921726777995332_cache to /opt/bitnami/spark/work/app-20240919203316-0026/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:33:18 INFO Executor: Fetching spark://dc42800f0e25:38605/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726777995332
24/09/19 20:33:18 INFO Utils: Fetching spark://dc42800f0e25:38605/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/fetchFileTemp18049505001003712938.tmp
24/09/19 20:33:19 INFO Utils: /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/8416214351726777995332_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203316-0026/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:33:19 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203316-0026/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:33:19 INFO Executor: Fetching spark://dc42800f0e25:38605/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726777995332
24/09/19 20:33:19 INFO Utils: Fetching spark://dc42800f0e25:38605/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/fetchFileTemp16090237467319408893.tmp
24/09/19 20:33:19 INFO Utils: /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6/1594756271726777995332_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203316-0026/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:33:19 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203316-0026/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:33:19 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:33:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:33:19 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:33:19 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:41907 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:33:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:33:19 INFO TorrentBroadcast: Reading broadcast variable 0 took 104 ms
24/09/19 20:33:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:33:20 INFO CodeGenerator: Code generated in 198.216217 ms
24/09/19 20:33:20 INFO JDBCRDD: closed connection
24/09/19 20:33:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
24/09/19 20:33:20 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:33:20 INFO Worker: Asked to kill executor app-20240919203316-0026/0
24/09/19 20:33:20 INFO ExecutorRunner: Runner thread for executor app-20240919203316-0026/0 interrupted
24/09/19 20:33:20 INFO ExecutorRunner: Killing process!
24/09/19 20:33:20 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:33:20 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:33:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d/executor-3c6a62f7-b8e1-4bd3-b217-59b5cd3a95b5/spark-077582e0-e0e0-43ff-89a3-ecfadd83b0e6
24/09/19 20:33:20 INFO MemoryStore: MemoryStore cleared
24/09/19 20:33:20 INFO BlockManager: BlockManager stopped
24/09/19 20:33:20 INFO Worker: Executor app-20240919203316-0026/0 finished with state KILLED exitStatus 143
24/09/19 20:33:20 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:33:20 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203316-0026, execId=0)
24/09/19 20:33:20 INFO ExternalShuffleBlockResolver: Application app-20240919203316-0026 removed, cleanupLocalDirs = true
24/09/19 20:33:20 INFO Worker: Cleaning up local directories for application app-20240919203316-0026
24/09/19 20:33:39 ERROR Worker: RECEIVED SIGNAL TERM
24/09/19 20:33:39 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:33:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-b199d7d1-5a17-439d-b7d7-0ed047b8bd1d
24/09/19 20:33:54 INFO Worker: Started daemon with process name: 1@81fa745d0ef3
24/09/19 20:33:54 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:33:54 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:33:54 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:33:54 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:33:54 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:33:54 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:33:54 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:33:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:33:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:33:55 INFO Utils: Successfully started service 'sparkWorker' on port 40253.
24/09/19 20:33:55 INFO Worker: Worker decommissioning not enabled.
24/09/19 20:33:55 INFO Worker: Starting Spark worker 172.22.0.4:40253 with 2 cores, 1024.0 MiB RAM
24/09/19 20:33:55 INFO Worker: Running Spark version 3.5.2
24/09/19 20:33:55 INFO Worker: Spark home: /opt/bitnami/spark
24/09/19 20:33:55 INFO ResourceUtils: ==============================================================
24/09/19 20:33:55 INFO ResourceUtils: No custom resources configured for spark.worker.
24/09/19 20:33:55 INFO ResourceUtils: ==============================================================
24/09/19 20:33:55 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/09/19 20:33:55 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/09/19 20:33:55 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://81fa745d0ef3:8081
24/09/19 20:33:55 INFO Worker: Connecting to master spark-master:7077...
24/09/19 20:33:55 INFO TransportClientFactory: Successfully created connection to spark-master/172.22.0.2:7077 after 30 ms (0 ms spent in bootstraps)
24/09/19 20:33:55 INFO Worker: Successfully registered with master spark://172.22.0.2:7077
24/09/19 20:34:04 INFO Worker: Asked to launch executor app-20240919203404-0000/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:34:04 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:34:04 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:34:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:34:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:34:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:34:04 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34671" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:34671" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203404-0000" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:34:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 110@81fa745d0ef3
24/09/19 20:34:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:34:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:34:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:34:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:34:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:34:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:34:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:34:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:34:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:34:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34671 after 48 ms (0 ms spent in bootstraps)
24/09/19 20:34:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:34:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:34:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:34:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:34:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:34:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34671 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:34:06 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/blockmgr-f39c2620-88dd-4dbb-98f3-5eb79fcf9b65
24/09/19 20:34:07 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:34:07 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:34671
24/09/19 20:34:07 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:34:07 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:34:07 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:34:07 INFO ResourceUtils: ==============================================================
24/09/19 20:34:07 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:34:07 INFO ResourceUtils: ==============================================================
24/09/19 20:34:07 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:34:07 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:34:07 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:34:07 INFO Executor: Java version 17.0.12
24/09/19 20:34:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33031.
24/09/19 20:34:07 INFO NettyBlockTransferService: Server created on 172.22.0.4:33031
24/09/19 20:34:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:34:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 33031, None)
24/09/19 20:34:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 33031, None)
24/09/19 20:34:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 33031, None)
24/09/19 20:34:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:34:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@132444cc for default.
24/09/19 20:34:07 INFO Executor: Fetching spark://dc42800f0e25:34671/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778043598
24/09/19 20:34:07 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34671 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:34:07 INFO Utils: Fetching spark://dc42800f0e25:34671/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/fetchFileTemp8421903795946176878.tmp
24/09/19 20:34:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/-2600867871726778043598_cache to /opt/bitnami/spark/work/app-20240919203404-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:34:07 INFO Executor: Fetching spark://dc42800f0e25:34671/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778043598
24/09/19 20:34:07 INFO Utils: Fetching spark://dc42800f0e25:34671/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/fetchFileTemp532529531635002890.tmp
24/09/19 20:34:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/-11214352511726778043598_cache to /opt/bitnami/spark/work/app-20240919203404-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:34:07 INFO Executor: Fetching spark://dc42800f0e25:34671/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778043598
24/09/19 20:34:07 INFO Utils: Fetching spark://dc42800f0e25:34671/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/fetchFileTemp17003038247231440291.tmp
24/09/19 20:34:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/-19636421741726778043598_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203404-0000/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:34:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203404-0000/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:34:07 INFO Executor: Fetching spark://dc42800f0e25:34671/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778043598
24/09/19 20:34:07 INFO Utils: Fetching spark://dc42800f0e25:34671/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/fetchFileTemp4025097484140646933.tmp
24/09/19 20:34:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec/-4237656461726778043598_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203404-0000/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:34:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203404-0000/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:34:08 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:34:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:34:08 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:34:08 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:35087 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:34:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.4 MiB)
24/09/19 20:34:08 INFO TorrentBroadcast: Reading broadcast variable 0 took 100 ms
24/09/19 20:34:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
24/09/19 20:34:08 INFO CodeGenerator: Code generated in 174.49292 ms
24/09/19 20:34:08 INFO JDBCRDD: closed connection
24/09/19 20:34:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
24/09/19 20:34:09 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:34:09 INFO Worker: Asked to kill executor app-20240919203404-0000/0
24/09/19 20:34:09 INFO ExecutorRunner: Runner thread for executor app-20240919203404-0000/0 interrupted
24/09/19 20:34:09 INFO ExecutorRunner: Killing process!
24/09/19 20:34:09 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:34:09 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:34:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-49e97b47-5409-4bc7-917a-b8d46369856c/spark-e311aa38-d6e5-4c1e-8447-8b3f4ef9c3ec
24/09/19 20:34:09 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34671 disconnected during shutdown
24/09/19 20:34:09 INFO MemoryStore: MemoryStore cleared
24/09/19 20:34:09 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34671 disconnected during shutdown
24/09/19 20:34:09 INFO BlockManager: BlockManager stopped
24/09/19 20:34:09 INFO Worker: Executor app-20240919203404-0000/0 finished with state KILLED exitStatus 143
24/09/19 20:34:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:34:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203404-0000, execId=0)
24/09/19 20:34:09 INFO ExternalShuffleBlockResolver: Application app-20240919203404-0000 removed, cleanupLocalDirs = true
24/09/19 20:34:09 INFO Worker: Cleaning up local directories for application app-20240919203404-0000
24/09/19 20:35:12 INFO Worker: Asked to launch executor app-20240919203512-0001/0 for DimensaoTempoComIDPortugues
24/09/19 20:35:12 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:35:12 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:35:12 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:12 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:35:12 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43371" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:43371" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203512-0001" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:35:13 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 206@81fa745d0ef3
24/09/19 20:35:13 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:35:13 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:35:13 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:35:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:35:13 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:35:13 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:35:13 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:13 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:35:13 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43371 after 52 ms (0 ms spent in bootstraps)
24/09/19 20:35:14 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:35:14 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:35:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:35:14 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43371 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:35:14 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/blockmgr-4b9001f7-0226-4428-9a8d-62842a3afa4c
24/09/19 20:35:14 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:35:14 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:43371
24/09/19 20:35:14 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:35:14 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 4 ms (0 ms spent in bootstraps)
24/09/19 20:35:14 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:35:14 INFO ResourceUtils: ==============================================================
24/09/19 20:35:14 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:35:14 INFO ResourceUtils: ==============================================================
24/09/19 20:35:14 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:35:14 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:35:14 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:35:14 INFO Executor: Java version 17.0.12
24/09/19 20:35:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43965.
24/09/19 20:35:14 INFO NettyBlockTransferService: Server created on 172.22.0.4:43965
24/09/19 20:35:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:35:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 43965, None)
24/09/19 20:35:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 43965, None)
24/09/19 20:35:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 43965, None)
24/09/19 20:35:14 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:35:14 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:35:14 INFO Executor: Fetching spark://dc42800f0e25:43371/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778111286
24/09/19 20:35:14 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43371 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:35:14 INFO Utils: Fetching spark://dc42800f0e25:43371/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/fetchFileTemp15402793416922680404.tmp
24/09/19 20:35:14 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/5783405881726778111286_cache to /opt/bitnami/spark/work/app-20240919203512-0001/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:35:14 INFO Executor: Fetching spark://dc42800f0e25:43371/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778111286
24/09/19 20:35:14 INFO Utils: Fetching spark://dc42800f0e25:43371/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/fetchFileTemp18153651481358237131.tmp
24/09/19 20:35:14 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/14769290521726778111286_cache to /opt/bitnami/spark/work/app-20240919203512-0001/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:35:14 INFO Executor: Fetching spark://dc42800f0e25:43371/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778111286
24/09/19 20:35:14 INFO Utils: Fetching spark://dc42800f0e25:43371/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/fetchFileTemp12757879729938563775.tmp
24/09/19 20:35:14 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/-3677328771726778111286_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203512-0001/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:35:14 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203512-0001/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:35:14 INFO Executor: Fetching spark://dc42800f0e25:43371/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778111286
24/09/19 20:35:14 INFO Utils: Fetching spark://dc42800f0e25:43371/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/fetchFileTemp2415052376489550050.tmp
24/09/19 20:35:14 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4/5850412831726778111286_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203512-0001/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:35:14 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203512-0001/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:35:16 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:35:16 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:35:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:35:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:35:16 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:35:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36825 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:35:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
24/09/19 20:35:16 INFO TorrentBroadcast: Reading broadcast variable 0 took 135 ms
24/09/19 20:35:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
24/09/19 20:35:17 INFO CodeGenerator: Code generated in 178.540245 ms
24/09/19 20:35:17 INFO PythonRunner: Times: total = 602, boot = 493, init = 107, finish = 2
24/09/19 20:35:17 INFO PythonRunner: Times: total = 602, boot = 491, init = 109, finish = 2
24/09/19 20:35:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2214 bytes result sent to driver
24/09/19 20:35:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2214 bytes result sent to driver
24/09/19 20:35:17 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:35:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 20:35:17 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:35:17 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:35:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 434.4 MiB)
24/09/19 20:35:17 INFO TorrentBroadcast: Reading broadcast variable 1 took 15 ms
24/09/19 20:35:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.1 KiB, free 434.3 MiB)
24/09/19 20:35:18 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:35:18 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:43371)
24/09/19 20:35:18 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:35:18 INFO ShuffleBlockFetcherIterator: Getting 2 (10.4 KiB) non-empty blocks including 2 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:35:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 21.115929 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 13.754453 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 10.851332 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 11.025224 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 10.716986 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 7.124792 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 7.739609 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 7.175122 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 17.005653 ms
24/09/19 20:35:18 INFO CodeGenerator: Code generated in 20.117193 ms
24/09/19 20:35:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4613 bytes result sent to driver
24/09/19 20:35:19 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:35:19 INFO Worker: Asked to kill executor app-20240919203512-0001/0
24/09/19 20:35:19 INFO ExecutorRunner: Runner thread for executor app-20240919203512-0001/0 interrupted
24/09/19 20:35:19 INFO ExecutorRunner: Killing process!
24/09/19 20:35:19 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:35:19 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:35:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d228b136-9347-49c6-ac46-31588a80ec97/spark-e4ce5d44-280b-4e3f-916f-afb8994ef9a4
24/09/19 20:35:19 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:43371 disconnected during shutdown
24/09/19 20:35:19 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:43371 disconnected during shutdown
24/09/19 20:35:19 INFO Worker: Executor app-20240919203512-0001/0 finished with state KILLED exitStatus 143
24/09/19 20:35:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:35:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203512-0001, execId=0)
24/09/19 20:35:19 INFO ExternalShuffleBlockResolver: Application app-20240919203512-0001 removed, cleanupLocalDirs = true
24/09/19 20:35:19 INFO Worker: Cleaning up local directories for application app-20240919203512-0001
24/09/19 20:35:37 INFO Worker: Asked to launch executor app-20240919203537-0002/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:35:37 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:35:37 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:35:37 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:37 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:35:37 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39709" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:39709" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203537-0002" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:35:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 314@81fa745d0ef3
24/09/19 20:35:38 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:35:38 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:35:38 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:35:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:35:38 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:35:38 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:35:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:35:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39709 after 50 ms (0 ms spent in bootstraps)
24/09/19 20:35:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:35:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:35:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:35:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:35:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:35:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39709 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:35:39 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/blockmgr-98bafea4-bf3a-4281-ab49-4d48dcaa9127
24/09/19 20:35:39 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:35:39 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:39709
24/09/19 20:35:39 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:35:39 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:35:39 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:35:39 INFO ResourceUtils: ==============================================================
24/09/19 20:35:39 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:35:39 INFO ResourceUtils: ==============================================================
24/09/19 20:35:39 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:35:39 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:35:39 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:35:39 INFO Executor: Java version 17.0.12
24/09/19 20:35:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38637.
24/09/19 20:35:39 INFO NettyBlockTransferService: Server created on 172.22.0.4:38637
24/09/19 20:35:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:35:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 38637, None)
24/09/19 20:35:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 38637, None)
24/09/19 20:35:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 38637, None)
24/09/19 20:35:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:35:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:35:39 INFO Executor: Fetching spark://dc42800f0e25:39709/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778136365
24/09/19 20:35:39 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39709 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:35:39 INFO Utils: Fetching spark://dc42800f0e25:39709/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/fetchFileTemp2593479150654858578.tmp
24/09/19 20:35:39 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/3749165681726778136365_cache to /opt/bitnami/spark/work/app-20240919203537-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:35:39 INFO Executor: Fetching spark://dc42800f0e25:39709/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778136365
24/09/19 20:35:39 INFO Utils: Fetching spark://dc42800f0e25:39709/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/fetchFileTemp17338397333206047728.tmp
24/09/19 20:35:39 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/-6092052401726778136365_cache to /opt/bitnami/spark/work/app-20240919203537-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:35:39 INFO Executor: Fetching spark://dc42800f0e25:39709/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778136365
24/09/19 20:35:39 INFO Utils: Fetching spark://dc42800f0e25:39709/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/fetchFileTemp4951501131226159717.tmp
24/09/19 20:35:40 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/18254052071726778136365_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203537-0002/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:35:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203537-0002/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:35:40 INFO Executor: Fetching spark://dc42800f0e25:39709/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778136365
24/09/19 20:35:40 INFO Utils: Fetching spark://dc42800f0e25:39709/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/fetchFileTemp4355852296053614722.tmp
24/09/19 20:35:40 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9/-19590481851726778136365_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203537-0002/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:35:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203537-0002/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:35:40 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:35:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:35:40 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:35:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:44117 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:35:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 434.4 MiB)
24/09/19 20:35:40 INFO TorrentBroadcast: Reading broadcast variable 0 took 87 ms
24/09/19 20:35:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.1 KiB, free 434.4 MiB)
24/09/19 20:35:41 INFO CodeGenerator: Code generated in 201.705941 ms
24/09/19 20:35:41 INFO JDBCRDD: closed connection
24/09/19 20:35:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2235 bytes result sent to driver
24/09/19 20:35:42 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:35:42 INFO Worker: Asked to kill executor app-20240919203537-0002/0
24/09/19 20:35:42 INFO ExecutorRunner: Runner thread for executor app-20240919203537-0002/0 interrupted
24/09/19 20:35:42 INFO ExecutorRunner: Killing process!
24/09/19 20:35:42 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:35:42 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:35:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-1d5b711e-9278-4f41-b08a-01c5e2687bed/spark-815cd3d6-f71d-4bab-a259-d5ffa4e684a9
24/09/19 20:35:42 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:39709 disconnected during shutdown
24/09/19 20:35:42 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:39709 disconnected during shutdown
24/09/19 20:35:42 INFO MemoryStore: MemoryStore cleared
24/09/19 20:35:42 INFO BlockManager: BlockManager stopped
24/09/19 20:35:42 INFO Worker: Executor app-20240919203537-0002/0 finished with state KILLED exitStatus 143
24/09/19 20:35:42 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:35:42 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203537-0002, execId=0)
24/09/19 20:35:42 INFO ExternalShuffleBlockResolver: Application app-20240919203537-0002 removed, cleanupLocalDirs = true
24/09/19 20:35:42 INFO Worker: Cleaning up local directories for application app-20240919203537-0002
24/09/19 20:36:25 INFO Worker: Asked to launch executor app-20240919203625-0003/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:36:25 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:36:25 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:36:25 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:36:25 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:36:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:36:25 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40197" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40197" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203625-0003" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:36:26 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 410@81fa745d0ef3
24/09/19 20:36:26 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:36:26 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:36:26 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:36:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:36:27 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:36:27 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:36:27 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:36:27 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:36:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:36:27 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40197 after 44 ms (0 ms spent in bootstraps)
24/09/19 20:36:27 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:36:27 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:36:27 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:36:27 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:36:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:36:27 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40197 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:36:27 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/blockmgr-124784a7-29a4-47d8-8d7b-2a4e2038aeb9
24/09/19 20:36:27 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:36:27 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40197
24/09/19 20:36:27 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:36:27 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:36:27 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:36:27 INFO ResourceUtils: ==============================================================
24/09/19 20:36:27 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:36:27 INFO ResourceUtils: ==============================================================
24/09/19 20:36:27 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:36:27 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:36:27 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:36:27 INFO Executor: Java version 17.0.12
24/09/19 20:36:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43565.
24/09/19 20:36:27 INFO NettyBlockTransferService: Server created on 172.22.0.4:43565
24/09/19 20:36:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:36:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 43565, None)
24/09/19 20:36:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 43565, None)
24/09/19 20:36:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 43565, None)
24/09/19 20:36:27 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:36:27 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:36:27 INFO Executor: Fetching spark://dc42800f0e25:40197/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778184832
24/09/19 20:36:28 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40197 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:36:28 INFO Utils: Fetching spark://dc42800f0e25:40197/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/fetchFileTemp14455749471000048422.tmp
24/09/19 20:36:28 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/-5334511351726778184832_cache to /opt/bitnami/spark/work/app-20240919203625-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:36:28 INFO Executor: Fetching spark://dc42800f0e25:40197/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778184832
24/09/19 20:36:28 INFO Utils: Fetching spark://dc42800f0e25:40197/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/fetchFileTemp2948989888923822407.tmp
24/09/19 20:36:28 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/-16635496791726778184832_cache to /opt/bitnami/spark/work/app-20240919203625-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:36:28 INFO Executor: Fetching spark://dc42800f0e25:40197/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778184832
24/09/19 20:36:28 INFO Utils: Fetching spark://dc42800f0e25:40197/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/fetchFileTemp12481106672414267556.tmp
24/09/19 20:36:28 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/3741749101726778184832_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203625-0003/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:36:28 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203625-0003/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:36:28 INFO Executor: Fetching spark://dc42800f0e25:40197/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778184832
24/09/19 20:36:28 INFO Utils: Fetching spark://dc42800f0e25:40197/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/fetchFileTemp490438447345332348.tmp
24/09/19 20:36:28 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040/3987001421726778184832_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203625-0003/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:36:28 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203625-0003/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:36:29 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:36:29 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:36:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:36:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:36:29 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:36:29 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:36:29 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42371 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:36:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 434.4 MiB)
24/09/19 20:36:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:36:29 INFO TorrentBroadcast: Reading broadcast variable 0 took 98 ms
24/09/19 20:36:29 INFO TorrentBroadcast: Reading broadcast variable 1 took 99 ms
24/09/19 20:36:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:36:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)
24/09/19 20:36:29 INFO JDBCRDD: closed connection
24/09/19 20:36:29 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)
org.postgresql.util.PSQLException: ERROR: column "id" does not exist
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:36:29 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:36:29 INFO Executor: Running task 0.1 in stage 1.0 (TID 2)
24/09/19 20:36:29 INFO JDBCRDD: closed connection
24/09/19 20:36:29 ERROR Executor: Exception in task 0.1 in stage 1.0 (TID 2)
org.postgresql.util.PSQLException: ERROR: column "id" does not exist
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:36:29 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:36:29 INFO Executor: Running task 0.2 in stage 1.0 (TID 3)
24/09/19 20:36:29 INFO JDBCRDD: closed connection
24/09/19 20:36:29 ERROR Executor: Exception in task 0.2 in stage 1.0 (TID 3)
org.postgresql.util.PSQLException: ERROR: column "id" does not exist
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:36:30 INFO CoarseGrainedExecutorBackend: Got assigned task 4
24/09/19 20:36:30 INFO Executor: Running task 0.3 in stage 1.0 (TID 4)
24/09/19 20:36:30 INFO JDBCRDD: closed connection
24/09/19 20:36:30 ERROR Executor: Exception in task 0.3 in stage 1.0 (TID 4)
org.postgresql.util.PSQLException: ERROR: column "id" does not exist
  Position: 8
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2553)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2285)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:323)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:481)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:401)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:164)
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:114)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:275)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:36:30 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled: Job 0 cancelled 
24/09/19 20:36:30 INFO CodeGenerator: Code generated in 212.632219 ms
24/09/19 20:36:30 INFO CodeGenerator: Code generated in 25.571704 ms
24/09/19 20:36:30 INFO JDBCRDD: closed connection
24/09/19 20:36:30 INFO Executor: Executor killed task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled: Job 0 cancelled 
24/09/19 20:36:30 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:36:30 INFO Worker: Asked to kill executor app-20240919203625-0003/0
24/09/19 20:36:30 INFO ExecutorRunner: Runner thread for executor app-20240919203625-0003/0 interrupted
24/09/19 20:36:30 INFO ExecutorRunner: Killing process!
24/09/19 20:36:30 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:36:30 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:36:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-7cbc50f1-7f95-4e62-858d-0a6232387366/spark-e2fd8994-c58b-462f-9cd2-c4d999c03040
24/09/19 20:36:30 INFO MemoryStore: MemoryStore cleared
24/09/19 20:36:30 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40197 disconnected during shutdown
24/09/19 20:36:30 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40197 disconnected during shutdown
24/09/19 20:36:30 INFO BlockManager: BlockManager stopped
24/09/19 20:36:30 INFO Worker: Executor app-20240919203625-0003/0 finished with state KILLED exitStatus 143
24/09/19 20:36:30 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:36:30 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203625-0003, execId=0)
24/09/19 20:36:30 INFO ExternalShuffleBlockResolver: Application app-20240919203625-0003 removed, cleanupLocalDirs = true
24/09/19 20:36:30 INFO Worker: Cleaning up local directories for application app-20240919203625-0003
24/09/19 20:37:13 INFO Worker: Asked to launch executor app-20240919203713-0004/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:37:13 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:37:13 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:37:13 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:13 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:37:13 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44929" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:44929" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203713-0004" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:37:14 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 504@81fa745d0ef3
24/09/19 20:37:14 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:37:14 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:37:14 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:37:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:37:15 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:37:15 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:37:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:37:15 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:44929 after 56 ms (0 ms spent in bootstraps)
24/09/19 20:37:15 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:37:15 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:37:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:37:15 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:44929 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:37:15 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-8a592c9e-c7cb-44b2-983a-8045c76e397c/blockmgr-357c234f-5d6f-45c0-a7ec-9ae8fc275840
24/09/19 20:37:15 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:37:16 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:44929
24/09/19 20:37:16 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:37:16 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:37:16 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:37:16 INFO ResourceUtils: ==============================================================
24/09/19 20:37:16 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:37:16 INFO ResourceUtils: ==============================================================
24/09/19 20:37:16 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:37:16 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:37:16 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:37:16 INFO Executor: Java version 17.0.12
24/09/19 20:37:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40549.
24/09/19 20:37:16 INFO NettyBlockTransferService: Server created on 172.22.0.4:40549
24/09/19 20:37:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:37:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 40549, None)
24/09/19 20:37:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 40549, None)
24/09/19 20:37:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 40549, None)
24/09/19 20:37:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:37:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:37:16 INFO Executor: Fetching spark://dc42800f0e25:44929/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778232792
24/09/19 20:37:16 INFO Worker: Asked to kill executor app-20240919203713-0004/0
24/09/19 20:37:16 INFO ExecutorRunner: Runner thread for executor app-20240919203713-0004/0 interrupted
24/09/19 20:37:16 INFO ExecutorRunner: Killing process!
24/09/19 20:37:16 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:37:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:44929 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:37:16 INFO Utils: Fetching spark://dc42800f0e25:44929/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-8a592c9e-c7cb-44b2-983a-8045c76e397c/spark-19f0d9f8-7bcd-4a76-9d3a-cefac09fa8cb/fetchFileTemp10217347780655275018.tmp
24/09/19 20:37:16 INFO MemoryStore: MemoryStore cleared
24/09/19 20:37:16 INFO BlockManager: BlockManager stopped
24/09/19 20:37:16 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-8a592c9e-c7cb-44b2-983a-8045c76e397c/spark-19f0d9f8-7bcd-4a76-9d3a-cefac09fa8cb/13894037101726778232792_cache to /opt/bitnami/spark/work/app-20240919203713-0004/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:37:16 INFO Executor: Fetching spark://dc42800f0e25:44929/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778232792
24/09/19 20:37:16 INFO TransportClientFactory: Found inactive connection to dc42800f0e25/172.22.0.5:44929, creating a new one.
24/09/19 20:37:16 ERROR Utils: Aborting task
java.io.IOException: Failed to connect to dc42800f0e25/172.22.0.5:44929
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)
	at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:709)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:454)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5(Executor.scala:1136)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5$adapted(Executor.scala:1133)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:273)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at org.apache.spark.executor.Executor.updateDependencies(Executor.scala:1133)
	at org.apache.spark.executor.Executor.<init>(Executor.scala:330)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:181)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dc42800f0e25/172.22.0.5:44929
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:37:16 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Failed to connect to dc42800f0e25/172.22.0.5:44929
java.io.IOException: Failed to connect to dc42800f0e25/172.22.0.5:44929
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:399)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$openChannel$4(NettyRpcEnv.scala:367)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)
	at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:366)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:709)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:454)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5(Executor.scala:1136)
	at org.apache.spark.executor.Executor.$anonfun$updateDependencies$5$adapted(Executor.scala:1133)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:273)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at org.apache.spark.executor.Executor.updateDependencies(Executor.scala:1133)
	at org.apache.spark.executor.Executor.<init>(Executor.scala:330)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:181)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dc42800f0e25/172.22.0.5:44929
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/09/19 20:37:16 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:37:16 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:44929 disconnected during shutdown
24/09/19 20:37:16 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:44929 disconnected during shutdown
24/09/19 20:37:16 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:37:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-8a592c9e-c7cb-44b2-983a-8045c76e397c/spark-19f0d9f8-7bcd-4a76-9d3a-cefac09fa8cb
24/09/19 20:37:16 INFO Worker: Executor app-20240919203713-0004/0 finished with state KILLED exitStatus 143
24/09/19 20:37:16 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:37:16 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203713-0004, execId=0)
24/09/19 20:37:16 INFO ExternalShuffleBlockResolver: Application app-20240919203713-0004 removed, cleanupLocalDirs = true
24/09/19 20:37:16 INFO Worker: Cleaning up local directories for application app-20240919203713-0004
24/09/19 20:37:38 INFO Worker: Asked to launch executor app-20240919203738-0005/0 for DimensaoTempoComIDPortugues
24/09/19 20:37:38 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:37:38 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:37:38 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:38 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:37:38 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33833" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:33833" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203738-0005" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:37:39 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 587@81fa745d0ef3
24/09/19 20:37:39 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:37:39 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:37:39 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:37:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:37:39 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:37:39 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:37:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:37:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:33833 after 53 ms (0 ms spent in bootstraps)
24/09/19 20:37:40 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:37:40 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:37:40 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:37:40 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:37:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:37:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:33833 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:37:40 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/blockmgr-c3cd92ff-16e8-4e33-b623-378f17eb33dc
24/09/19 20:37:40 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:37:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:33833
24/09/19 20:37:40 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:37:40 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:37:40 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:37:40 INFO ResourceUtils: ==============================================================
24/09/19 20:37:40 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:37:40 INFO ResourceUtils: ==============================================================
24/09/19 20:37:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:37:40 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:37:40 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:37:40 INFO Executor: Java version 17.0.12
24/09/19 20:37:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43865.
24/09/19 20:37:40 INFO NettyBlockTransferService: Server created on 172.22.0.4:43865
24/09/19 20:37:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:37:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 43865, None)
24/09/19 20:37:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 43865, None)
24/09/19 20:37:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 43865, None)
24/09/19 20:37:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:37:40 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:37:40 INFO Executor: Fetching spark://dc42800f0e25:33833/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778257511
24/09/19 20:37:40 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:33833 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:37:40 INFO Utils: Fetching spark://dc42800f0e25:33833/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/fetchFileTemp5772926405950003706.tmp
24/09/19 20:37:40 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/-11121964261726778257511_cache to /opt/bitnami/spark/work/app-20240919203738-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:37:40 INFO Executor: Fetching spark://dc42800f0e25:33833/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778257511
24/09/19 20:37:40 INFO Utils: Fetching spark://dc42800f0e25:33833/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/fetchFileTemp8696378416365084978.tmp
24/09/19 20:37:40 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/-10644944901726778257511_cache to /opt/bitnami/spark/work/app-20240919203738-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:37:40 INFO Executor: Fetching spark://dc42800f0e25:33833/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778257511
24/09/19 20:37:40 INFO Utils: Fetching spark://dc42800f0e25:33833/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/fetchFileTemp9774344240645820063.tmp
24/09/19 20:37:40 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/-19737349351726778257511_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203738-0005/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:37:40 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203738-0005/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:37:40 INFO Executor: Fetching spark://dc42800f0e25:33833/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778257511
24/09/19 20:37:40 INFO Utils: Fetching spark://dc42800f0e25:33833/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/fetchFileTemp12816514106981204681.tmp
24/09/19 20:37:41 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f/-15477021511726778257511_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203738-0005/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:37:41 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203738-0005/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:37:42 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:37:42 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:37:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:37:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:37:42 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:37:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40681 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:37:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
24/09/19 20:37:42 INFO TorrentBroadcast: Reading broadcast variable 0 took 84 ms
24/09/19 20:37:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
24/09/19 20:37:43 INFO CodeGenerator: Code generated in 144.603268 ms
24/09/19 20:37:43 INFO PythonRunner: Times: total = 567, boot = 466, init = 100, finish = 1
24/09/19 20:37:43 INFO PythonRunner: Times: total = 565, boot = 463, init = 102, finish = 0
24/09/19 20:37:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2214 bytes result sent to driver
24/09/19 20:37:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2171 bytes result sent to driver
24/09/19 20:37:43 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:37:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 20:37:43 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:37:43 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:37:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 434.4 MiB)
24/09/19 20:37:43 INFO TorrentBroadcast: Reading broadcast variable 1 took 13 ms
24/09/19 20:37:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.1 KiB, free 434.3 MiB)
24/09/19 20:37:44 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:37:44 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:33833)
24/09/19 20:37:44 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:37:44 INFO ShuffleBlockFetcherIterator: Getting 2 (10.4 KiB) non-empty blocks including 2 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:37:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 19.472481 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 19.981071 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 10.472856 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 9.310808 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 6.96655 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 12.141969 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 11.644024 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 7.713983 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 20.052544 ms
24/09/19 20:37:44 INFO CodeGenerator: Code generated in 27.792186 ms
24/09/19 20:37:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4613 bytes result sent to driver
24/09/19 20:37:45 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:37:45 INFO Worker: Asked to kill executor app-20240919203738-0005/0
24/09/19 20:37:45 INFO ExecutorRunner: Runner thread for executor app-20240919203738-0005/0 interrupted
24/09/19 20:37:45 INFO ExecutorRunner: Killing process!
24/09/19 20:37:45 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:37:45 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:37:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-b0a95d81-8899-4f65-bc9a-5043e30db712/spark-af0b9ec8-9ba4-4f85-a0c3-816d89b7152f
24/09/19 20:37:45 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:33833 disconnected during shutdown
24/09/19 20:37:45 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:33833 disconnected during shutdown
24/09/19 20:37:45 INFO Worker: Executor app-20240919203738-0005/0 finished with state KILLED exitStatus 143
24/09/19 20:37:45 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:37:45 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203738-0005, execId=0)
24/09/19 20:37:45 INFO ExternalShuffleBlockResolver: Application app-20240919203738-0005 removed, cleanupLocalDirs = true
24/09/19 20:37:45 INFO Worker: Cleaning up local directories for application app-20240919203738-0005
24/09/19 20:38:04 INFO Worker: Asked to launch executor app-20240919203804-0006/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:38:04 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:38:04 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:38:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:38:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:38:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:38:04 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34013" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:34013" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919203804-0006" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:38:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 693@81fa745d0ef3
24/09/19 20:38:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:38:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:38:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:38:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:38:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:38:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:38:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:38:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:38:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34013 after 52 ms (0 ms spent in bootstraps)
24/09/19 20:38:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:38:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:38:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:38:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:38:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34013 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:38:06 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/blockmgr-dd14d218-8b0a-4150-8d3c-e14fecdb749b
24/09/19 20:38:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:38:06 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:34013
24/09/19 20:38:06 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:38:06 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:38:06 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:38:06 INFO ResourceUtils: ==============================================================
24/09/19 20:38:06 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:38:06 INFO ResourceUtils: ==============================================================
24/09/19 20:38:06 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:38:06 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:38:06 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:38:06 INFO Executor: Java version 17.0.12
24/09/19 20:38:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34905.
24/09/19 20:38:06 INFO NettyBlockTransferService: Server created on 172.22.0.4:34905
24/09/19 20:38:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:38:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34905, None)
24/09/19 20:38:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34905, None)
24/09/19 20:38:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34905, None)
24/09/19 20:38:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:38:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:38:06 INFO Executor: Fetching spark://dc42800f0e25:34013/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778283687
24/09/19 20:38:07 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34013 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:38:07 INFO Utils: Fetching spark://dc42800f0e25:34013/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/fetchFileTemp9584692046676647591.tmp
24/09/19 20:38:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/-6585345771726778283687_cache to /opt/bitnami/spark/work/app-20240919203804-0006/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:38:07 INFO Executor: Fetching spark://dc42800f0e25:34013/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778283687
24/09/19 20:38:07 INFO Utils: Fetching spark://dc42800f0e25:34013/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/fetchFileTemp6866007133369167351.tmp
24/09/19 20:38:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/3545395831726778283687_cache to /opt/bitnami/spark/work/app-20240919203804-0006/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:38:07 INFO Executor: Fetching spark://dc42800f0e25:34013/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778283687
24/09/19 20:38:07 INFO Utils: Fetching spark://dc42800f0e25:34013/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/fetchFileTemp13230683703902179170.tmp
24/09/19 20:38:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/5658923361726778283687_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203804-0006/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:38:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203804-0006/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:38:07 INFO Executor: Fetching spark://dc42800f0e25:34013/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778283687
24/09/19 20:38:07 INFO Utils: Fetching spark://dc42800f0e25:34013/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/fetchFileTemp13087165710890202068.tmp
24/09/19 20:38:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93/4065947521726778283687_cache has been previously copied to /opt/bitnami/spark/work/app-20240919203804-0006/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:38:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919203804-0006/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:38:07 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:38:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:38:07 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:38:07 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36985 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:38:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
24/09/19 20:38:07 INFO TorrentBroadcast: Reading broadcast variable 0 took 89 ms
24/09/19 20:38:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.3 KiB, free 434.4 MiB)
24/09/19 20:38:08 INFO CodeGenerator: Code generated in 171.913039 ms
24/09/19 20:38:08 INFO JDBCRDD: closed connection
24/09/19 20:38:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2200 bytes result sent to driver
24/09/19 20:38:09 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:38:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:38:09 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:38:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 434.4 MiB)
24/09/19 20:38:09 INFO TorrentBroadcast: Reading broadcast variable 1 took 15 ms
24/09/19 20:38:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.9 KiB, free 434.4 MiB)
24/09/19 20:38:09 INFO CodeGenerator: Code generated in 29.324982 ms
24/09/19 20:38:09 INFO JDBCRDD: closed connection
24/09/19 20:38:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2344 bytes result sent to driver
24/09/19 20:38:09 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:38:09 INFO Worker: Asked to kill executor app-20240919203804-0006/0
24/09/19 20:38:09 INFO ExecutorRunner: Runner thread for executor app-20240919203804-0006/0 interrupted
24/09/19 20:38:09 INFO ExecutorRunner: Killing process!
24/09/19 20:38:09 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:38:09 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:38:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-61073947-8728-46a7-b613-8f4a50919286/spark-23f93fe0-9003-46ea-88a9-e428b821aa93
24/09/19 20:38:09 INFO MemoryStore: MemoryStore cleared
24/09/19 20:38:09 INFO BlockManager: BlockManager stopped
24/09/19 20:38:09 INFO Worker: Executor app-20240919203804-0006/0 finished with state KILLED exitStatus 143
24/09/19 20:38:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:38:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919203804-0006, execId=0)
24/09/19 20:38:09 INFO ExternalShuffleBlockResolver: Application app-20240919203804-0006 removed, cleanupLocalDirs = true
24/09/19 20:38:09 INFO Worker: Cleaning up local directories for application app-20240919203804-0006
24/09/19 20:40:14 INFO Worker: Asked to launch executor app-20240919204014-0007/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:40:14 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:40:14 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:40:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:40:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:40:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:40:14 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45461" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:45461" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204014-0007" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:40:15 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 790@81fa745d0ef3
24/09/19 20:40:15 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:40:15 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:40:15 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:40:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:40:15 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:40:15 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:40:15 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:40:15 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:40:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:40:15 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45461 after 89 ms (0 ms spent in bootstraps)
24/09/19 20:40:16 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:40:16 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:40:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:40:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:40:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:40:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45461 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:40:16 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/blockmgr-2e5f7cb2-99b0-4d8a-b86c-b0e3b771caa8
24/09/19 20:40:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:40:16 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:45461
24/09/19 20:40:16 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:40:16 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:40:16 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:40:16 INFO ResourceUtils: ==============================================================
24/09/19 20:40:16 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:40:16 INFO ResourceUtils: ==============================================================
24/09/19 20:40:16 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:40:16 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:40:16 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:40:16 INFO Executor: Java version 17.0.12
24/09/19 20:40:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44441.
24/09/19 20:40:16 INFO NettyBlockTransferService: Server created on 172.22.0.4:44441
24/09/19 20:40:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:40:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44441, None)
24/09/19 20:40:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44441, None)
24/09/19 20:40:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44441, None)
24/09/19 20:40:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:40:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:40:16 INFO Executor: Fetching spark://dc42800f0e25:45461/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778413437
24/09/19 20:40:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45461 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:40:16 INFO Utils: Fetching spark://dc42800f0e25:45461/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/fetchFileTemp10839947857512197853.tmp
24/09/19 20:40:16 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/13768220921726778413437_cache to /opt/bitnami/spark/work/app-20240919204014-0007/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:40:16 INFO Executor: Fetching spark://dc42800f0e25:45461/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778413437
24/09/19 20:40:16 INFO Utils: Fetching spark://dc42800f0e25:45461/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/fetchFileTemp4200045443726674777.tmp
24/09/19 20:40:16 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/-3417552681726778413437_cache to /opt/bitnami/spark/work/app-20240919204014-0007/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:40:16 INFO Executor: Fetching spark://dc42800f0e25:45461/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778413437
24/09/19 20:40:16 INFO Utils: Fetching spark://dc42800f0e25:45461/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/fetchFileTemp4367049421523911516.tmp
24/09/19 20:40:16 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/-2878527811726778413437_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204014-0007/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:40:16 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204014-0007/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:40:16 INFO Executor: Fetching spark://dc42800f0e25:45461/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778413437
24/09/19 20:40:16 INFO Utils: Fetching spark://dc42800f0e25:45461/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/fetchFileTemp1053272637016029208.tmp
24/09/19 20:40:16 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f/7493460831726778413437_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204014-0007/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:40:16 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204014-0007/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:40:17 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:40:17 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:40:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:40:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:40:17 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:40:17 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:40:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:35761 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:40:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:40:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 434.4 MiB)
24/09/19 20:40:17 INFO TorrentBroadcast: Reading broadcast variable 1 took 79 ms
24/09/19 20:40:17 INFO TorrentBroadcast: Reading broadcast variable 0 took 79 ms
24/09/19 20:40:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
24/09/19 20:40:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:40:18 INFO CodeGenerator: Code generated in 176.912888 ms
24/09/19 20:40:18 INFO CodeGenerator: Code generated in 182.395219 ms
24/09/19 20:40:18 INFO CodeGenerator: Code generated in 16.288774 ms
24/09/19 20:40:18 INFO CodeGenerator: Code generated in 16.316544 ms
24/09/19 20:40:19 INFO JDBCRDD: closed connection
24/09/19 20:40:19 INFO JDBCRDD: closed connection
24/09/19 20:40:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2025 bytes result sent to driver
24/09/19 20:40:20 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:40:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
24/09/19 20:40:20 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:40:20 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:40:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.3 MiB)
24/09/19 20:40:20 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 20:40:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)
24/09/19 20:40:20 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:40:20 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:45461)
24/09/19 20:40:20 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:40:20 INFO ShuffleBlockFetcherIterator: Getting 1 (31.0 KiB) non-empty blocks including 1 (31.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:40:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
24/09/19 20:40:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2038 bytes result sent to driver
24/09/19 20:40:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 23839 bytes result sent to driver
24/09/19 20:40:21 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:40:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
24/09/19 20:40:21 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
24/09/19 20:40:21 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:40:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:40:21 INFO TorrentBroadcast: Reading broadcast variable 4 took 14 ms
24/09/19 20:40:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.9 KiB, free 434.4 MiB)
24/09/19 20:40:21 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
24/09/19 20:40:21 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:45461)
24/09/19 20:40:21 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:40:21 INFO ShuffleBlockFetcherIterator: Getting 1 (72.4 KiB) non-empty blocks including 1 (72.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/09/19 20:40:21 INFO CodeGenerator: Code generated in 35.282492 ms
24/09/19 20:40:21 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:40:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 434.4 MiB)
24/09/19 20:40:21 INFO TorrentBroadcast: Reading broadcast variable 3 took 14 ms
24/09/19 20:40:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 MiB, free 426.3 MiB)
24/09/19 20:40:21 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 4193 bytes result sent to driver
24/09/19 20:40:22 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:40:22 INFO Worker: Asked to kill executor app-20240919204014-0007/0
24/09/19 20:40:22 INFO ExecutorRunner: Runner thread for executor app-20240919204014-0007/0 interrupted
24/09/19 20:40:22 INFO ExecutorRunner: Killing process!
24/09/19 20:40:22 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:40:22 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:40:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-0be86182-c113-4328-bd1f-781e374b3f74/spark-87ae56b6-29ff-4db9-b14a-5f6883d0725f
24/09/19 20:40:22 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:45461 disconnected during shutdown
24/09/19 20:40:22 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:45461 disconnected during shutdown
24/09/19 20:40:22 INFO Worker: Executor app-20240919204014-0007/0 finished with state KILLED exitStatus 143
24/09/19 20:40:22 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:40:22 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204014-0007, execId=0)
24/09/19 20:40:22 INFO ExternalShuffleBlockResolver: Application app-20240919204014-0007 removed, cleanupLocalDirs = true
24/09/19 20:40:22 INFO Worker: Cleaning up local directories for application app-20240919204014-0007
24/09/19 20:41:59 INFO Worker: Asked to launch executor app-20240919204159-0008/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:41:59 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:41:59 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:41:59 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:41:59 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:41:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:41:59 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45271" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:45271" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204159-0008" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:42:00 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 896@81fa745d0ef3
24/09/19 20:42:00 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:42:00 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:42:00 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:42:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:42:00 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:42:00 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:42:00 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:42:00 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:42:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:42:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45271 after 49 ms (0 ms spent in bootstraps)
24/09/19 20:42:01 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:42:01 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:42:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:42:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:42:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:42:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45271 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:42:01 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/blockmgr-51158200-21a7-4cf4-bc0f-99b6a804aca3
24/09/19 20:42:01 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:42:01 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:45271
24/09/19 20:42:01 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:42:01 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:42:01 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:42:01 INFO ResourceUtils: ==============================================================
24/09/19 20:42:01 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:42:01 INFO ResourceUtils: ==============================================================
24/09/19 20:42:01 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:42:01 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:42:01 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:42:01 INFO Executor: Java version 17.0.12
24/09/19 20:42:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35767.
24/09/19 20:42:01 INFO NettyBlockTransferService: Server created on 172.22.0.4:35767
24/09/19 20:42:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:42:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 35767, None)
24/09/19 20:42:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 35767, None)
24/09/19 20:42:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 35767, None)
24/09/19 20:42:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:42:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@659aca61 for default.
24/09/19 20:42:01 INFO Executor: Fetching spark://dc42800f0e25:45271/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778518471
24/09/19 20:42:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45271 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:42:01 INFO Utils: Fetching spark://dc42800f0e25:45271/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/fetchFileTemp1594031899374410229.tmp
24/09/19 20:42:01 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/5465631771726778518471_cache to /opt/bitnami/spark/work/app-20240919204159-0008/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:42:02 INFO Executor: Fetching spark://dc42800f0e25:45271/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778518471
24/09/19 20:42:02 INFO Utils: Fetching spark://dc42800f0e25:45271/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/fetchFileTemp15081507602628960288.tmp
24/09/19 20:42:02 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/-164859271726778518471_cache to /opt/bitnami/spark/work/app-20240919204159-0008/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:42:02 INFO Executor: Fetching spark://dc42800f0e25:45271/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778518471
24/09/19 20:42:02 INFO Utils: Fetching spark://dc42800f0e25:45271/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/fetchFileTemp10255565918643705809.tmp
24/09/19 20:42:02 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/-6930022181726778518471_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204159-0008/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:42:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204159-0008/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:42:02 INFO Executor: Fetching spark://dc42800f0e25:45271/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778518471
24/09/19 20:42:02 INFO Utils: Fetching spark://dc42800f0e25:45271/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/fetchFileTemp13975789759301575026.tmp
24/09/19 20:42:02 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183/14153001981726778518471_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204159-0008/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:42:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204159-0008/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:42:03 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:42:03 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:42:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:42:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:42:03 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:42:03 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:42:03 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36015 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:42:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:42:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.4 MiB)
24/09/19 20:42:03 INFO TorrentBroadcast: Reading broadcast variable 1 took 117 ms
24/09/19 20:42:03 INFO TorrentBroadcast: Reading broadcast variable 0 took 117 ms
24/09/19 20:42:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.7 KiB, free 434.4 MiB)
24/09/19 20:42:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:42:03 INFO CodeGenerator: Code generated in 187.911903 ms
24/09/19 20:42:03 INFO CodeGenerator: Code generated in 187.906568 ms
24/09/19 20:42:04 INFO CodeGenerator: Code generated in 14.99399 ms
24/09/19 20:42:04 INFO CodeGenerator: Code generated in 14.92572 ms
24/09/19 20:42:04 INFO JDBCRDD: closed connection
24/09/19 20:42:05 INFO JDBCRDD: closed connection
24/09/19 20:42:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2025 bytes result sent to driver
24/09/19 20:42:05 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:42:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
24/09/19 20:42:05 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:42:05 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
24/09/19 20:42:06 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:45271)
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:42:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2038 bytes result sent to driver
24/09/19 20:42:06 INFO ShuffleBlockFetcherIterator: Getting 1 (31.0 KiB) non-empty blocks including 1 (31.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:42:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
24/09/19 20:42:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 23839 bytes result sent to driver
24/09/19 20:42:06 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:42:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
24/09/19 20:42:06 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.3 MiB)
24/09/19 20:42:06 INFO TorrentBroadcast: Reading broadcast variable 4 took 16 ms
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KiB, free 434.3 MiB)
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:45271)
24/09/19 20:42:06 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:42:06 INFO ShuffleBlockFetcherIterator: Getting 1 (29.0 KiB) non-empty blocks including 1 (29.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:42:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
24/09/19 20:42:06 INFO CodeGenerator: Code generated in 34.671051 ms
24/09/19 20:42:06 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 434.4 MiB)
24/09/19 20:42:06 INFO TorrentBroadcast: Reading broadcast variable 3 took 12 ms
24/09/19 20:42:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 MiB, free 426.3 MiB)
24/09/19 20:42:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 3809 bytes result sent to driver
24/09/19 20:42:07 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:42:07 INFO Worker: Asked to kill executor app-20240919204159-0008/0
24/09/19 20:42:07 INFO ExecutorRunner: Runner thread for executor app-20240919204159-0008/0 interrupted
24/09/19 20:42:07 INFO ExecutorRunner: Killing process!
24/09/19 20:42:07 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:42:07 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:42:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-d9efc3fc-b16b-4244-920d-8922738145e6/spark-0c03c991-7c1d-4b34-93a6-8082841c8183
24/09/19 20:42:07 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:45271 disconnected during shutdown
24/09/19 20:42:07 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:45271 disconnected during shutdown
24/09/19 20:42:07 INFO Worker: Executor app-20240919204159-0008/0 finished with state KILLED exitStatus 143
24/09/19 20:42:07 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:42:07 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204159-0008, execId=0)
24/09/19 20:42:07 INFO ExternalShuffleBlockResolver: Application app-20240919204159-0008 removed, cleanupLocalDirs = true
24/09/19 20:42:07 INFO Worker: Cleaning up local directories for application app-20240919204159-0008
24/09/19 20:43:23 INFO Worker: Asked to launch executor app-20240919204323-0009/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:43:23 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:43:23 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:43:23 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:43:23 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:43:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:43:23 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42939" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:42939" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204323-0009" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:43:24 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 998@81fa745d0ef3
24/09/19 20:43:24 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:43:24 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:43:24 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:43:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:43:24 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:43:24 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:43:24 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:43:24 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:43:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:43:25 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42939 after 48 ms (0 ms spent in bootstraps)
24/09/19 20:43:25 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:43:25 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:43:25 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:43:25 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:43:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:43:25 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:42939 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:43:25 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-e40f97f9-252c-44f5-aab2-651d88f93192/blockmgr-c3c1a3e8-fe5a-42fb-91d3-379ff3616e4a
24/09/19 20:43:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:43:25 INFO Worker: Asked to kill executor app-20240919204323-0009/0
24/09/19 20:43:25 INFO ExecutorRunner: Runner thread for executor app-20240919204323-0009/0 interrupted
24/09/19 20:43:25 INFO ExecutorRunner: Killing process!
24/09/19 20:43:25 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:43:25 INFO DiskBlockManager: Shutdown hook called
24/09/19 20:43:25 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:43:25 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:42939
24/09/19 20:43:25 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:43:25 INFO Worker: Executor app-20240919204323-0009/0 finished with state KILLED exitStatus 143
24/09/19 20:43:25 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:43:25 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204323-0009, execId=0)
24/09/19 20:43:25 INFO ExternalShuffleBlockResolver: Application app-20240919204323-0009 removed, cleanupLocalDirs = true
24/09/19 20:43:25 INFO Worker: Cleaning up local directories for application app-20240919204323-0009
24/09/19 20:43:59 INFO Worker: Asked to launch executor app-20240919204359-0010/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:43:59 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:43:59 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:43:59 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:43:59 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:43:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:43:59 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40431" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:40431" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204359-0010" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:44:00 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1069@81fa745d0ef3
24/09/19 20:44:00 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:44:00 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:44:00 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:44:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:44:00 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:44:00 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:44:00 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:44:00 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:44:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:44:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40431 after 51 ms (0 ms spent in bootstraps)
24/09/19 20:44:01 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:44:01 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:44:01 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:44:01 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:44:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:44:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40431 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:44:01 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/blockmgr-ebfaf3a2-8923-48c0-9f62-71e7c7ca23cf
24/09/19 20:44:01 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:44:01 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:40431
24/09/19 20:44:01 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:44:01 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:44:01 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:44:01 INFO ResourceUtils: ==============================================================
24/09/19 20:44:01 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:44:01 INFO ResourceUtils: ==============================================================
24/09/19 20:44:01 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:44:01 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:44:01 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:44:01 INFO Executor: Java version 17.0.12
24/09/19 20:44:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35127.
24/09/19 20:44:01 INFO NettyBlockTransferService: Server created on 172.22.0.4:35127
24/09/19 20:44:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:44:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 35127, None)
24/09/19 20:44:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 35127, None)
24/09/19 20:44:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 35127, None)
24/09/19 20:44:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:44:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:44:01 INFO Executor: Fetching spark://dc42800f0e25:40431/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778638429
24/09/19 20:44:01 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:40431 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:44:01 INFO Utils: Fetching spark://dc42800f0e25:40431/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/fetchFileTemp854212149660059231.tmp
24/09/19 20:44:01 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/789588681726778638429_cache to /opt/bitnami/spark/work/app-20240919204359-0010/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:44:01 INFO Executor: Fetching spark://dc42800f0e25:40431/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778638429
24/09/19 20:44:01 INFO Utils: Fetching spark://dc42800f0e25:40431/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/fetchFileTemp3248971868142759144.tmp
24/09/19 20:44:01 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/-5443455321726778638429_cache to /opt/bitnami/spark/work/app-20240919204359-0010/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:44:02 INFO Executor: Fetching spark://dc42800f0e25:40431/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778638429
24/09/19 20:44:02 INFO Utils: Fetching spark://dc42800f0e25:40431/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/fetchFileTemp14964061354784730943.tmp
24/09/19 20:44:02 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/16452746991726778638429_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204359-0010/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:44:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204359-0010/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:44:02 INFO Executor: Fetching spark://dc42800f0e25:40431/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778638429
24/09/19 20:44:02 INFO Utils: Fetching spark://dc42800f0e25:40431/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/fetchFileTemp12174288634187450743.tmp
24/09/19 20:44:02 INFO Worker: Asked to kill executor app-20240919204359-0010/0
24/09/19 20:44:02 INFO ExecutorRunner: Runner thread for executor app-20240919204359-0010/0 interrupted
24/09/19 20:44:02 INFO ExecutorRunner: Killing process!
24/09/19 20:44:02 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:44:02 INFO MemoryStore: MemoryStore cleared
24/09/19 20:44:02 INFO BlockManager: BlockManager stopped
24/09/19 20:44:02 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc/2918375311726778638429_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204359-0010/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:44:02 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204359-0010/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:44:02 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:44:02 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40431 disconnected during shutdown
24/09/19 20:44:02 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:40431 disconnected during shutdown
24/09/19 20:44:02 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:44:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-982ff8c9-4b0c-438e-8956-0fa0868ad90c/spark-850c9b2f-718c-4eb8-96c4-f8ffbfcb5fcc
24/09/19 20:44:02 INFO Worker: Executor app-20240919204359-0010/0 finished with state KILLED exitStatus 143
24/09/19 20:44:02 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:44:02 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204359-0010, execId=0)
24/09/19 20:44:02 INFO ExternalShuffleBlockResolver: Application app-20240919204359-0010 removed, cleanupLocalDirs = true
24/09/19 20:44:02 INFO Worker: Cleaning up local directories for application app-20240919204359-0010
24/09/19 20:45:31 INFO Worker: Asked to launch executor app-20240919204531-0011/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:45:31 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:45:31 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:45:31 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:45:31 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:45:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:45:31 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43695" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:43695" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204531-0011" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:45:32 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1159@81fa745d0ef3
24/09/19 20:45:32 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:45:32 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:45:32 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:45:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:45:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:45:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:45:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:45:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:45:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:45:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43695 after 51 ms (0 ms spent in bootstraps)
24/09/19 20:45:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:45:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:45:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:45:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:45:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:45:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43695 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:45:33 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/blockmgr-8269a5fb-a1cb-41db-86d2-69d3544b1cae
24/09/19 20:45:33 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:45:34 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:43695
24/09/19 20:45:34 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:45:34 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:45:34 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:45:34 INFO ResourceUtils: ==============================================================
24/09/19 20:45:34 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:45:34 INFO ResourceUtils: ==============================================================
24/09/19 20:45:34 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:45:34 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:45:34 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:45:34 INFO Executor: Java version 17.0.12
24/09/19 20:45:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35193.
24/09/19 20:45:34 INFO NettyBlockTransferService: Server created on 172.22.0.4:35193
24/09/19 20:45:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:45:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 35193, None)
24/09/19 20:45:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 35193, None)
24/09/19 20:45:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 35193, None)
24/09/19 20:45:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:45:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:45:34 INFO Executor: Fetching spark://dc42800f0e25:43695/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778731109
24/09/19 20:45:34 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43695 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:45:34 INFO Utils: Fetching spark://dc42800f0e25:43695/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/fetchFileTemp9580573843240575136.tmp
24/09/19 20:45:34 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/17714315211726778731109_cache to /opt/bitnami/spark/work/app-20240919204531-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:45:34 INFO Executor: Fetching spark://dc42800f0e25:43695/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778731109
24/09/19 20:45:34 INFO Utils: Fetching spark://dc42800f0e25:43695/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/fetchFileTemp1346501139422374049.tmp
24/09/19 20:45:34 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/16164697451726778731109_cache to /opt/bitnami/spark/work/app-20240919204531-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:45:34 INFO Executor: Fetching spark://dc42800f0e25:43695/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778731109
24/09/19 20:45:34 INFO Utils: Fetching spark://dc42800f0e25:43695/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/fetchFileTemp4379608058278221913.tmp
24/09/19 20:45:34 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/-10509694581726778731109_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204531-0011/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:45:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204531-0011/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:45:34 INFO Executor: Fetching spark://dc42800f0e25:43695/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778731109
24/09/19 20:45:34 INFO Utils: Fetching spark://dc42800f0e25:43695/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/fetchFileTemp12137755023159789092.tmp
24/09/19 20:45:34 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6/-18753226581726778731109_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204531-0011/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:45:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204531-0011/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:45:35 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:45:35 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:45:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:45:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:45:35 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:45:35 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:45:35 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:43853 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:45:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:45:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.4 MiB)
24/09/19 20:45:35 INFO TorrentBroadcast: Reading broadcast variable 1 took 83 ms
24/09/19 20:45:35 INFO TorrentBroadcast: Reading broadcast variable 0 took 83 ms
24/09/19 20:45:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:45:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.7 KiB, free 434.4 MiB)
24/09/19 20:45:36 INFO CodeGenerator: Code generated in 165.720138 ms
24/09/19 20:45:36 INFO CodeGenerator: Code generated in 165.713635 ms
24/09/19 20:45:36 INFO CodeGenerator: Code generated in 17.472467 ms
24/09/19 20:45:36 INFO CodeGenerator: Code generated in 17.458475 ms
24/09/19 20:45:37 INFO JDBCRDD: closed connection
24/09/19 20:45:37 INFO JDBCRDD: closed connection
24/09/19 20:45:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2025 bytes result sent to driver
24/09/19 20:45:38 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:45:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
24/09/19 20:45:38 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:45:38 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:45:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
24/09/19 20:45:38 INFO TorrentBroadcast: Reading broadcast variable 2 took 19 ms
24/09/19 20:45:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KiB, free 434.4 MiB)
24/09/19 20:45:38 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:45:38 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:43695)
24/09/19 20:45:38 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:45:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2038 bytes result sent to driver
24/09/19 20:45:38 INFO ShuffleBlockFetcherIterator: Getting 1 (31.0 KiB) non-empty blocks including 1 (31.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:45:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
24/09/19 20:45:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 23839 bytes result sent to driver
24/09/19 20:45:39 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:45:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
24/09/19 20:45:39 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
24/09/19 20:45:39 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:45:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 434.4 MiB)
24/09/19 20:45:39 INFO TorrentBroadcast: Reading broadcast variable 4 took 16 ms
24/09/19 20:45:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 47.9 KiB, free 434.3 MiB)
24/09/19 20:45:39 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
24/09/19 20:45:39 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:43695)
24/09/19 20:45:39 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:45:39 INFO ShuffleBlockFetcherIterator: Getting 1 (29.0 KiB) non-empty blocks including 1 (29.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:45:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/09/19 20:45:39 INFO CodeGenerator: Code generated in 23.74781 ms
24/09/19 20:45:39 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:45:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 434.3 MiB)
24/09/19 20:45:39 INFO TorrentBroadcast: Reading broadcast variable 3 took 12 ms
24/09/19 20:45:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 MiB, free 426.3 MiB)
24/09/19 20:45:39 INFO CodeGenerator: Code generated in 17.988671 ms
24/09/19 20:45:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 5736 bytes result sent to driver
24/09/19 20:45:39 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:45:39 INFO Worker: Asked to kill executor app-20240919204531-0011/0
24/09/19 20:45:39 INFO ExecutorRunner: Runner thread for executor app-20240919204531-0011/0 interrupted
24/09/19 20:45:39 INFO ExecutorRunner: Killing process!
24/09/19 20:45:39 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:45:39 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:45:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-75cb3d63-e947-453f-8f2b-b0473642b9d2/spark-1d92b051-9349-4398-8b51-03964282edd6
24/09/19 20:45:39 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:43695 disconnected during shutdown
24/09/19 20:45:39 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:43695 disconnected during shutdown
24/09/19 20:45:40 INFO Worker: Executor app-20240919204531-0011/0 finished with state KILLED exitStatus 143
24/09/19 20:45:40 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:45:40 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204531-0011, execId=0)
24/09/19 20:45:40 INFO ExternalShuffleBlockResolver: Application app-20240919204531-0011 removed, cleanupLocalDirs = true
24/09/19 20:45:40 INFO Worker: Cleaning up local directories for application app-20240919204531-0011
24/09/19 20:48:04 INFO Worker: Asked to launch executor app-20240919204804-0012/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:48:04 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:48:04 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:48:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:48:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:48:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:48:04 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46267" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:46267" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919204804-0012" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:48:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1262@81fa745d0ef3
24/09/19 20:48:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:48:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:48:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:48:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:48:05 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:48:05 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:48:05 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:48:05 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:48:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:48:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46267 after 48 ms (0 ms spent in bootstraps)
24/09/19 20:48:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:48:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:48:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:48:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:48:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:48:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46267 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:48:06 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/blockmgr-bf7dac24-bc73-4ad8-a202-8fc3f4c3110a
24/09/19 20:48:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:48:06 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:46267
24/09/19 20:48:06 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:48:06 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:48:06 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:48:06 INFO ResourceUtils: ==============================================================
24/09/19 20:48:06 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:48:06 INFO ResourceUtils: ==============================================================
24/09/19 20:48:06 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:48:06 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:48:06 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:48:06 INFO Executor: Java version 17.0.12
24/09/19 20:48:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36801.
24/09/19 20:48:06 INFO NettyBlockTransferService: Server created on 172.22.0.4:36801
24/09/19 20:48:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:48:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 36801, None)
24/09/19 20:48:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 36801, None)
24/09/19 20:48:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 36801, None)
24/09/19 20:48:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:48:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:48:06 INFO Executor: Fetching spark://dc42800f0e25:46267/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778883530
24/09/19 20:48:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:46267 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:48:06 INFO Utils: Fetching spark://dc42800f0e25:46267/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/fetchFileTemp15991378538979056655.tmp
24/09/19 20:48:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/10849832151726778883530_cache to /opt/bitnami/spark/work/app-20240919204804-0012/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:48:07 INFO Executor: Fetching spark://dc42800f0e25:46267/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778883530
24/09/19 20:48:07 INFO Utils: Fetching spark://dc42800f0e25:46267/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/fetchFileTemp16997944529689672070.tmp
24/09/19 20:48:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/-21384374731726778883530_cache to /opt/bitnami/spark/work/app-20240919204804-0012/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:48:07 INFO Executor: Fetching spark://dc42800f0e25:46267/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726778883530
24/09/19 20:48:07 INFO Utils: Fetching spark://dc42800f0e25:46267/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/fetchFileTemp9107739972457732761.tmp
24/09/19 20:48:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/-8999996001726778883530_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204804-0012/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:48:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204804-0012/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:48:07 INFO Executor: Fetching spark://dc42800f0e25:46267/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726778883530
24/09/19 20:48:07 INFO Utils: Fetching spark://dc42800f0e25:46267/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/fetchFileTemp4791655067190078504.tmp
24/09/19 20:48:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e/-10611833921726778883530_cache has been previously copied to /opt/bitnami/spark/work/app-20240919204804-0012/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:48:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919204804-0012/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:48:08 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:48:08 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:48:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:48:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:48:08 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:48:08 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:48:08 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:45213 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:48:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.4 MiB)
24/09/19 20:48:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:48:08 INFO TorrentBroadcast: Reading broadcast variable 0 took 87 ms
24/09/19 20:48:08 INFO TorrentBroadcast: Reading broadcast variable 1 took 87 ms
24/09/19 20:48:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.7 KiB, free 434.4 MiB)
24/09/19 20:48:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:48:09 INFO CodeGenerator: Code generated in 195.293156 ms
24/09/19 20:48:09 INFO CodeGenerator: Code generated in 195.281723 ms
24/09/19 20:48:09 INFO CodeGenerator: Code generated in 14.803396 ms
24/09/19 20:48:09 INFO CodeGenerator: Code generated in 14.799439 ms
24/09/19 20:48:10 INFO JDBCRDD: closed connection
24/09/19 20:48:10 INFO JDBCRDD: closed connection
24/09/19 20:48:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2025 bytes result sent to driver
24/09/19 20:48:11 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:48:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
24/09/19 20:48:11 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:48:11 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:48:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
24/09/19 20:48:11 INFO TorrentBroadcast: Reading broadcast variable 2 took 15 ms
24/09/19 20:48:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)
24/09/19 20:48:11 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:48:11 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:46267)
24/09/19 20:48:11 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:48:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2038 bytes result sent to driver
24/09/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (31.0 KiB) non-empty blocks including 1 (31.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms
24/09/19 20:48:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 23839 bytes result sent to driver
24/09/19 20:48:11 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:48:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
24/09/19 20:48:11 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
24/09/19 20:48:11 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:48:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 434.3 MiB)
24/09/19 20:48:11 INFO TorrentBroadcast: Reading broadcast variable 4 took 16 ms
24/09/19 20:48:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 47.9 KiB, free 434.3 MiB)
24/09/19 20:48:12 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
24/09/19 20:48:12 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:46267)
24/09/19 20:48:12 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 (29.0 KiB) non-empty blocks including 1 (29.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/09/19 20:48:12 INFO CodeGenerator: Code generated in 21.600424 ms
24/09/19 20:48:12 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:48:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 434.3 MiB)
24/09/19 20:48:12 INFO TorrentBroadcast: Reading broadcast variable 3 took 15 ms
24/09/19 20:48:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 MiB, free 426.3 MiB)
24/09/19 20:48:12 INFO CodeGenerator: Code generated in 22.466156 ms
24/09/19 20:48:12 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 5693 bytes result sent to driver
24/09/19 20:48:12 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:48:12 INFO Worker: Asked to kill executor app-20240919204804-0012/0
24/09/19 20:48:12 INFO ExecutorRunner: Runner thread for executor app-20240919204804-0012/0 interrupted
24/09/19 20:48:12 INFO ExecutorRunner: Killing process!
24/09/19 20:48:12 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:48:12 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:48:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-046c5a62-30f6-45ed-aba3-b3606681d748/spark-18f82f32-7710-4534-9256-aebca2fa999e
24/09/19 20:48:12 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:46267 disconnected during shutdown
24/09/19 20:48:12 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:46267 disconnected during shutdown
24/09/19 20:48:12 INFO Worker: Executor app-20240919204804-0012/0 finished with state KILLED exitStatus 143
24/09/19 20:48:12 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:48:12 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919204804-0012, execId=0)
24/09/19 20:48:12 INFO ExternalShuffleBlockResolver: Application app-20240919204804-0012 removed, cleanupLocalDirs = true
24/09/19 20:48:12 INFO Worker: Cleaning up local directories for application app-20240919204804-0012
24/09/19 20:51:39 INFO Worker: Asked to launch executor app-20240919205139-0013/0 for DimensaoTempoComIDPortugues
24/09/19 20:51:39 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:51:39 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:51:39 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:51:39 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:51:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:51:39 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38465" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:38465" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919205139-0013" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:51:40 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1364@81fa745d0ef3
24/09/19 20:51:40 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:51:40 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:51:40 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:51:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:51:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:51:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:51:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:51:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:51:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:51:41 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38465 after 59 ms (0 ms spent in bootstraps)
24/09/19 20:51:41 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:51:41 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:51:41 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:51:41 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:51:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:51:41 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38465 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:51:41 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/blockmgr-2908ce5e-69cc-467e-8de0-43e203542dd0
24/09/19 20:51:41 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:51:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:38465
24/09/19 20:51:41 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:51:41 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:51:41 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:51:41 INFO ResourceUtils: ==============================================================
24/09/19 20:51:41 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:51:41 INFO ResourceUtils: ==============================================================
24/09/19 20:51:42 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:51:42 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:51:42 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:51:42 INFO Executor: Java version 17.0.12
24/09/19 20:51:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45289.
24/09/19 20:51:42 INFO NettyBlockTransferService: Server created on 172.22.0.4:45289
24/09/19 20:51:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:51:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 45289, None)
24/09/19 20:51:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 45289, None)
24/09/19 20:51:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 45289, None)
24/09/19 20:51:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:51:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@557b121f for default.
24/09/19 20:51:42 INFO Executor: Fetching spark://dc42800f0e25:38465/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779099046
24/09/19 20:51:42 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:38465 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:51:42 INFO Utils: Fetching spark://dc42800f0e25:38465/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/fetchFileTemp1788020698250872695.tmp
24/09/19 20:51:42 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/17853299001726779099046_cache to /opt/bitnami/spark/work/app-20240919205139-0013/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:51:42 INFO Executor: Fetching spark://dc42800f0e25:38465/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779099046
24/09/19 20:51:42 INFO Utils: Fetching spark://dc42800f0e25:38465/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/fetchFileTemp9125292799018270411.tmp
24/09/19 20:51:42 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/5166756121726779099046_cache to /opt/bitnami/spark/work/app-20240919205139-0013/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:51:42 INFO Executor: Fetching spark://dc42800f0e25:38465/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779099046
24/09/19 20:51:42 INFO Utils: Fetching spark://dc42800f0e25:38465/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/fetchFileTemp3186862061613900386.tmp
24/09/19 20:51:42 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/11253118591726779099046_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205139-0013/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:51:42 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205139-0013/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:51:42 INFO Executor: Fetching spark://dc42800f0e25:38465/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779099046
24/09/19 20:51:42 INFO Utils: Fetching spark://dc42800f0e25:38465/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/fetchFileTemp7407650925219781885.tmp
24/09/19 20:51:42 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce/15938077471726779099046_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205139-0013/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:51:42 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205139-0013/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:51:43 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:51:43 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:51:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/09/19 20:51:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:51:43 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:51:43 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:39077 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:51:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
24/09/19 20:51:43 INFO TorrentBroadcast: Reading broadcast variable 0 took 89 ms
24/09/19 20:51:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
24/09/19 20:51:45 INFO CodeGenerator: Code generated in 163.1247 ms
24/09/19 20:51:45 INFO PythonRunner: Times: total = 600, boot = 490, init = 109, finish = 1
24/09/19 20:51:45 INFO PythonRunner: Times: total = 610, boot = 487, init = 123, finish = 0
24/09/19 20:51:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2214 bytes result sent to driver
24/09/19 20:51:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2214 bytes result sent to driver
24/09/19 20:51:45 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:51:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/19 20:51:45 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:51:45 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:51:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 434.4 MiB)
24/09/19 20:51:45 INFO TorrentBroadcast: Reading broadcast variable 1 took 15 ms
24/09/19 20:51:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.1 KiB, free 434.3 MiB)
24/09/19 20:51:45 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:51:45 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:38465)
24/09/19 20:51:45 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:51:45 INFO ShuffleBlockFetcherIterator: Getting 2 (10.4 KiB) non-empty blocks including 2 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
24/09/19 20:51:45 INFO CodeGenerator: Code generated in 21.038306 ms
24/09/19 20:51:45 INFO CodeGenerator: Code generated in 14.813758 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 12.972286 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 10.40964 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 7.540393 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 8.360937 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 9.478503 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 7.782237 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 22.459252 ms
24/09/19 20:51:46 INFO CodeGenerator: Code generated in 25.921452 ms
24/09/19 20:51:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4613 bytes result sent to driver
24/09/19 20:51:47 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:51:47 INFO Worker: Asked to kill executor app-20240919205139-0013/0
24/09/19 20:51:47 INFO ExecutorRunner: Runner thread for executor app-20240919205139-0013/0 interrupted
24/09/19 20:51:47 INFO ExecutorRunner: Killing process!
24/09/19 20:51:47 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:51:47 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:51:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-066500c0-37d3-431c-9ebf-5e6f35001b06/spark-87c566f2-f3dc-4cfb-9dc3-cc27b64d5cce
24/09/19 20:51:47 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:38465 disconnected during shutdown
24/09/19 20:51:47 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:38465 disconnected during shutdown
24/09/19 20:51:47 INFO Worker: Executor app-20240919205139-0013/0 finished with state KILLED exitStatus 143
24/09/19 20:51:47 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:51:47 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919205139-0013, execId=0)
24/09/19 20:51:47 INFO ExternalShuffleBlockResolver: Application app-20240919205139-0013 removed, cleanupLocalDirs = true
24/09/19 20:51:47 INFO Worker: Cleaning up local directories for application app-20240919205139-0013
24/09/19 20:52:04 INFO Worker: Asked to launch executor app-20240919205204-0014/0 for PostgresToGoldSchema
24/09/19 20:52:04 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:52:04 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:52:04 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:04 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:52:04 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=36317" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:36317" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919205204-0014" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:52:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1470@81fa745d0ef3
24/09/19 20:52:05 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:52:05 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:52:05 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:52:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:52:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36317 after 56 ms (0 ms spent in bootstraps)
24/09/19 20:52:06 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:06 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:06 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:06 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:06 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36317 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:52:06 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/blockmgr-b9a9ee79-340e-4b17-a994-ecb67a36bcea
24/09/19 20:52:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:52:07 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:36317
24/09/19 20:52:07 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:52:07 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:07 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:52:07 INFO ResourceUtils: ==============================================================
24/09/19 20:52:07 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:52:07 INFO ResourceUtils: ==============================================================
24/09/19 20:52:07 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:52:07 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:52:07 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:52:07 INFO Executor: Java version 17.0.12
24/09/19 20:52:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39131.
24/09/19 20:52:07 INFO NettyBlockTransferService: Server created on 172.22.0.4:39131
24/09/19 20:52:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:52:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 39131, None)
24/09/19 20:52:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 39131, None)
24/09/19 20:52:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 39131, None)
24/09/19 20:52:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:52:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:52:07 INFO Executor: Fetching spark://dc42800f0e25:36317/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779123816
24/09/19 20:52:07 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36317 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:07 INFO Utils: Fetching spark://dc42800f0e25:36317/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/fetchFileTemp2724619301266894653.tmp
24/09/19 20:52:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/-132789721726779123816_cache to /opt/bitnami/spark/work/app-20240919205204-0014/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:07 INFO Executor: Fetching spark://dc42800f0e25:36317/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779123816
24/09/19 20:52:07 INFO Utils: Fetching spark://dc42800f0e25:36317/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/fetchFileTemp3458128786363181058.tmp
24/09/19 20:52:07 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/3904839241726779123816_cache to /opt/bitnami/spark/work/app-20240919205204-0014/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:07 INFO Executor: Fetching spark://dc42800f0e25:36317/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779123816
24/09/19 20:52:07 INFO Utils: Fetching spark://dc42800f0e25:36317/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/fetchFileTemp1579225613999518642.tmp
24/09/19 20:52:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/9946233871726779123816_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205204-0014/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205204-0014/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:52:07 INFO Executor: Fetching spark://dc42800f0e25:36317/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779123816
24/09/19 20:52:07 INFO Utils: Fetching spark://dc42800f0e25:36317/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/fetchFileTemp11756437378724232234.tmp
24/09/19 20:52:07 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee/-19398247571726779123816_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205204-0014/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:07 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205204-0014/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:52:08 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:52:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:52:08 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:08 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:35091 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.4 MiB)
24/09/19 20:52:08 INFO TorrentBroadcast: Reading broadcast variable 0 took 110 ms
24/09/19 20:52:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 27.8 KiB, free 434.4 MiB)
24/09/19 20:52:08 INFO CodeGenerator: Code generated in 150.240602 ms
24/09/19 20:52:09 INFO CodeGenerator: Code generated in 20.909251 ms
24/09/19 20:52:09 INFO JDBCRDD: closed connection
24/09/19 20:52:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 20:52:09 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:52:09 INFO Worker: Asked to kill executor app-20240919205204-0014/0
24/09/19 20:52:09 INFO ExecutorRunner: Runner thread for executor app-20240919205204-0014/0 interrupted
24/09/19 20:52:09 INFO ExecutorRunner: Killing process!
24/09/19 20:52:09 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:52:09 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:52:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-eb5f76e4-7a16-4c7e-be77-7bd5954a1755/spark-71e4ac9f-16f4-4c24-9d34-889bfccdccee
24/09/19 20:52:09 INFO MemoryStore: MemoryStore cleared
24/09/19 20:52:09 INFO BlockManager: BlockManager stopped
24/09/19 20:52:10 INFO Worker: Executor app-20240919205204-0014/0 finished with state KILLED exitStatus 143
24/09/19 20:52:10 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:52:10 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919205204-0014, execId=0)
24/09/19 20:52:10 INFO ExternalShuffleBlockResolver: Application app-20240919205204-0014 removed, cleanupLocalDirs = true
24/09/19 20:52:10 INFO Worker: Cleaning up local directories for application app-20240919205204-0014
24/09/19 20:52:14 INFO Worker: Asked to launch executor app-20240919205214-0015/0 for PostgresToGoldSchema
24/09/19 20:52:14 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:52:14 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:52:14 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:14 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:52:14 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=37167" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:37167" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919205214-0015" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:52:15 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1563@81fa745d0ef3
24/09/19 20:52:15 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:52:15 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:52:15 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:52:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:52:16 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:16 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:37167 after 48 ms (0 ms spent in bootstraps)
24/09/19 20:52:16 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:16 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:16 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:16 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:16 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:37167 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:16 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/blockmgr-241c3f88-1ea8-4cf6-983c-ddd7494fec0b
24/09/19 20:52:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:52:17 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:37167
24/09/19 20:52:17 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:52:17 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 13 ms (0 ms spent in bootstraps)
24/09/19 20:52:17 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:52:17 INFO ResourceUtils: ==============================================================
24/09/19 20:52:17 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:52:17 INFO ResourceUtils: ==============================================================
24/09/19 20:52:17 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:52:17 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:52:17 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:52:17 INFO Executor: Java version 17.0.12
24/09/19 20:52:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34973.
24/09/19 20:52:17 INFO NettyBlockTransferService: Server created on 172.22.0.4:34973
24/09/19 20:52:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:52:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 34973, None)
24/09/19 20:52:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 34973, None)
24/09/19 20:52:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 34973, None)
24/09/19 20:52:17 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:52:17 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:52:17 INFO Executor: Fetching spark://dc42800f0e25:37167/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779133825
24/09/19 20:52:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:37167 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:52:17 INFO Utils: Fetching spark://dc42800f0e25:37167/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/fetchFileTemp9488121441583220088.tmp
24/09/19 20:52:17 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/-4682873641726779133825_cache to /opt/bitnami/spark/work/app-20240919205214-0015/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:17 INFO Executor: Fetching spark://dc42800f0e25:37167/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779133825
24/09/19 20:52:17 INFO Utils: Fetching spark://dc42800f0e25:37167/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/fetchFileTemp9170995344863038669.tmp
24/09/19 20:52:17 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/913841401726779133825_cache to /opt/bitnami/spark/work/app-20240919205214-0015/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:17 INFO Executor: Fetching spark://dc42800f0e25:37167/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779133825
24/09/19 20:52:17 INFO Utils: Fetching spark://dc42800f0e25:37167/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/fetchFileTemp2491477243318034678.tmp
24/09/19 20:52:17 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/2622548671726779133825_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205214-0015/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:17 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205214-0015/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:52:17 INFO Executor: Fetching spark://dc42800f0e25:37167/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779133825
24/09/19 20:52:17 INFO Utils: Fetching spark://dc42800f0e25:37167/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/fetchFileTemp3368449413040705357.tmp
24/09/19 20:52:17 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4/11235223391726779133825_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205214-0015/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:17 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205214-0015/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:52:17 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:52:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:52:17 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:17 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:44197 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:52:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.4 MiB)
24/09/19 20:52:18 INFO TorrentBroadcast: Reading broadcast variable 0 took 97 ms
24/09/19 20:52:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 27.8 KiB, free 434.4 MiB)
24/09/19 20:52:18 INFO CodeGenerator: Code generated in 160.835674 ms
24/09/19 20:52:19 INFO CodeGenerator: Code generated in 21.164147 ms
24/09/19 20:52:19 INFO JDBCRDD: closed connection
24/09/19 20:52:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1359 bytes result sent to driver
24/09/19 20:52:19 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:52:19 INFO Worker: Asked to kill executor app-20240919205214-0015/0
24/09/19 20:52:19 INFO ExecutorRunner: Runner thread for executor app-20240919205214-0015/0 interrupted
24/09/19 20:52:19 INFO ExecutorRunner: Killing process!
24/09/19 20:52:19 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:52:19 INFO DiskBlockManager: Shutdown hook called
24/09/19 20:52:19 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:52:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-2cdd4554-7418-474b-a6a6-b8189c95d96a/spark-6d7743b0-802f-425c-8b4d-2b2cdc9d7ac4
24/09/19 20:52:19 INFO MemoryStore: MemoryStore cleared
24/09/19 20:52:19 INFO BlockManager: BlockManager stopped
24/09/19 20:52:19 INFO Worker: Executor app-20240919205214-0015/0 finished with state KILLED exitStatus 143
24/09/19 20:52:19 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:52:19 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919205214-0015, execId=0)
24/09/19 20:52:19 INFO ExternalShuffleBlockResolver: Application app-20240919205214-0015 removed, cleanupLocalDirs = true
24/09/19 20:52:19 INFO Worker: Cleaning up local directories for application app-20240919205214-0015
24/09/19 20:52:31 INFO Worker: Asked to launch executor app-20240919205231-0016/0 for SubstituirDataVendaPorIDTempo
24/09/19 20:52:31 INFO SecurityManager: Changing view acls to: root,spark
24/09/19 20:52:31 INFO SecurityManager: Changing modify acls to: root,spark
24/09/19 20:52:31 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:31 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
24/09/19 20:52:31 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34399" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dc42800f0e25:34399" "--executor-id" "0" "--hostname" "172.22.0.4" "--cores" "2" "--app-id" "app-20240919205231-0016" "--worker-url" "spark://Worker@172.22.0.4:40253" "--resourceProfileId" "0"
24/09/19 20:52:32 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1658@81fa745d0ef3
24/09/19 20:52:32 INFO SignalUtils: Registering signal handler for TERM
24/09/19 20:52:32 INFO SignalUtils: Registering signal handler for HUP
24/09/19 20:52:32 INFO SignalUtils: Registering signal handler for INT
24/09/19 20:52:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/19 20:52:32 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:32 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:32 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:32 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34399 after 52 ms (0 ms spent in bootstraps)
24/09/19 20:52:33 INFO SecurityManager: Changing view acls to: root,airflow
24/09/19 20:52:33 INFO SecurityManager: Changing modify acls to: root,airflow
24/09/19 20:52:33 INFO SecurityManager: Changing view acls groups to: 
24/09/19 20:52:33 INFO SecurityManager: Changing modify acls groups to: 
24/09/19 20:52:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, airflow; groups with view permissions: EMPTY; users with modify permissions: root, airflow; groups with modify permissions: EMPTY
24/09/19 20:52:33 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34399 after 3 ms (0 ms spent in bootstraps)
24/09/19 20:52:33 INFO DiskBlockManager: Created local directory at /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/blockmgr-42756608-a074-45f4-b7f6-3c2bd1603b24
24/09/19 20:52:33 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/19 20:52:33 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dc42800f0e25:34399
24/09/19 20:52:33 INFO WorkerWatcher: Connecting to worker spark://Worker@172.22.0.4:40253
24/09/19 20:52:33 INFO TransportClientFactory: Successfully created connection to /172.22.0.4:40253 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:33 INFO WorkerWatcher: Successfully connected to spark://Worker@172.22.0.4:40253
24/09/19 20:52:33 INFO ResourceUtils: ==============================================================
24/09/19 20:52:33 INFO ResourceUtils: No custom resources configured for spark.executor.
24/09/19 20:52:33 INFO ResourceUtils: ==============================================================
24/09/19 20:52:33 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/09/19 20:52:33 INFO Executor: Starting executor ID 0 on host 172.22.0.4
24/09/19 20:52:33 INFO Executor: OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
24/09/19 20:52:33 INFO Executor: Java version 17.0.12
24/09/19 20:52:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44331.
24/09/19 20:52:33 INFO NettyBlockTransferService: Server created on 172.22.0.4:44331
24/09/19 20:52:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/19 20:52:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.22.0.4, 44331, None)
24/09/19 20:52:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.22.0.4, 44331, None)
24/09/19 20:52:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.22.0.4, 44331, None)
24/09/19 20:52:33 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/09/19 20:52:33 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@45b9ca12 for default.
24/09/19 20:52:34 INFO Executor: Fetching spark://dc42800f0e25:34399/files/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779150202
24/09/19 20:52:34 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:34399 after 1 ms (0 ms spent in bootstraps)
24/09/19 20:52:34 INFO Utils: Fetching spark://dc42800f0e25:34399/files/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/fetchFileTemp77522960368687078.tmp
24/09/19 20:52:34 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/-10594912641726779150202_cache to /opt/bitnami/spark/work/app-20240919205231-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:34 INFO Executor: Fetching spark://dc42800f0e25:34399/files/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779150202
24/09/19 20:52:34 INFO Utils: Fetching spark://dc42800f0e25:34399/files/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/fetchFileTemp1191727618971696408.tmp
24/09/19 20:52:34 INFO Utils: Copying /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/-15320355681726779150202_cache to /opt/bitnami/spark/work/app-20240919205231-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:34 INFO Executor: Fetching spark://dc42800f0e25:34399/jars/org.checkerframework_checker-qual-3.5.0.jar with timestamp 1726779150202
24/09/19 20:52:34 INFO Utils: Fetching spark://dc42800f0e25:34399/jars/org.checkerframework_checker-qual-3.5.0.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/fetchFileTemp12620148380365898237.tmp
24/09/19 20:52:34 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/19057517591726779150202_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205231-0016/0/./org.checkerframework_checker-qual-3.5.0.jar
24/09/19 20:52:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205231-0016/0/./org.checkerframework_checker-qual-3.5.0.jar to class loader default
24/09/19 20:52:34 INFO Executor: Fetching spark://dc42800f0e25:34399/jars/org.postgresql_postgresql-42.2.20.jar with timestamp 1726779150202
24/09/19 20:52:34 INFO Utils: Fetching spark://dc42800f0e25:34399/jars/org.postgresql_postgresql-42.2.20.jar to /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/fetchFileTemp14011073015682469890.tmp
24/09/19 20:52:34 INFO Utils: /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8/-14226980171726779150202_cache has been previously copied to /opt/bitnami/spark/work/app-20240919205231-0016/0/./org.postgresql_postgresql-42.2.20.jar
24/09/19 20:52:34 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20240919205231-0016/0/./org.postgresql_postgresql-42.2.20.jar to class loader default
24/09/19 20:52:35 INFO CoarseGrainedExecutorBackend: Got assigned task 0
24/09/19 20:52:35 INFO CoarseGrainedExecutorBackend: Got assigned task 1
24/09/19 20:52:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/19 20:52:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/19 20:52:35 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:35 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:35 INFO TransportClientFactory: Successfully created connection to dc42800f0e25/172.22.0.5:36697 after 2 ms (0 ms spent in bootstraps)
24/09/19 20:52:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.4 MiB)
24/09/19 20:52:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
24/09/19 20:52:35 INFO TorrentBroadcast: Reading broadcast variable 1 took 108 ms
24/09/19 20:52:35 INFO TorrentBroadcast: Reading broadcast variable 0 took 108 ms
24/09/19 20:52:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.7 KiB, free 434.4 MiB)
24/09/19 20:52:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.6 KiB, free 434.4 MiB)
24/09/19 20:52:36 INFO CodeGenerator: Code generated in 198.954975 ms
24/09/19 20:52:36 INFO CodeGenerator: Code generated in 198.959465 ms
24/09/19 20:52:36 INFO CodeGenerator: Code generated in 17.304618 ms
24/09/19 20:52:36 INFO CodeGenerator: Code generated in 17.23187 ms
24/09/19 20:52:37 INFO JDBCRDD: closed connection
24/09/19 20:52:37 INFO JDBCRDD: closed connection
24/09/19 20:52:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2025 bytes result sent to driver
24/09/19 20:52:38 INFO CoarseGrainedExecutorBackend: Got assigned task 2
24/09/19 20:52:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
24/09/19 20:52:38 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
24/09/19 20:52:38 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
24/09/19 20:52:38 INFO TorrentBroadcast: Reading broadcast variable 2 took 12 ms
24/09/19 20:52:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)
24/09/19 20:52:38 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
24/09/19 20:52:38 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:34399)
24/09/19 20:52:38 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:52:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2038 bytes result sent to driver
24/09/19 20:52:38 INFO ShuffleBlockFetcherIterator: Getting 1 (31.0 KiB) non-empty blocks including 1 (31.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:52:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
24/09/19 20:52:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 23839 bytes result sent to driver
24/09/19 20:52:38 INFO CoarseGrainedExecutorBackend: Got assigned task 3
24/09/19 20:52:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
24/09/19 20:52:38 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
24/09/19 20:52:38 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 434.3 MiB)
24/09/19 20:52:38 INFO TorrentBroadcast: Reading broadcast variable 4 took 15 ms
24/09/19 20:52:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 47.9 KiB, free 434.3 MiB)
24/09/19 20:52:39 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
24/09/19 20:52:39 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@dc42800f0e25:34399)
24/09/19 20:52:39 INFO MapOutputTrackerWorker: Got the map output locations
24/09/19 20:52:39 INFO ShuffleBlockFetcherIterator: Getting 1 (29.0 KiB) non-empty blocks including 1 (29.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/09/19 20:52:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/09/19 20:52:39 INFO CodeGenerator: Code generated in 29.648393 ms
24/09/19 20:52:39 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
24/09/19 20:52:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 434.3 MiB)
24/09/19 20:52:39 INFO TorrentBroadcast: Reading broadcast variable 3 took 14 ms
24/09/19 20:52:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 MiB, free 426.3 MiB)
24/09/19 20:52:39 INFO CodeGenerator: Code generated in 16.651464 ms
24/09/19 20:52:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 5736 bytes result sent to driver
24/09/19 20:52:39 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/09/19 20:52:39 INFO Worker: Asked to kill executor app-20240919205231-0016/0
24/09/19 20:52:39 INFO ExecutorRunner: Runner thread for executor app-20240919205231-0016/0 interrupted
24/09/19 20:52:39 INFO ExecutorRunner: Killing process!
24/09/19 20:52:39 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
24/09/19 20:52:39 INFO ShutdownHookManager: Shutdown hook called
24/09/19 20:52:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-481fbbd8-83fe-45d2-860e-fdd9a0d6c358/executor-94371fe1-d0c6-43d1-8e51-3362c9507ea2/spark-41465851-8e6c-42c2-82f1-92d6392bd1d8
24/09/19 20:52:39 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34399 disconnected during shutdown
24/09/19 20:52:39 INFO CoarseGrainedExecutorBackend: Driver from dc42800f0e25:34399 disconnected during shutdown
24/09/19 20:52:39 INFO Worker: Executor app-20240919205231-0016/0 finished with state KILLED exitStatus 143
24/09/19 20:52:39 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/09/19 20:52:39 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240919205231-0016, execId=0)
24/09/19 20:52:39 INFO ExternalShuffleBlockResolver: Application app-20240919205231-0016 removed, cleanupLocalDirs = true
24/09/19 20:52:39 INFO Worker: Cleaning up local directories for application app-20240919205231-0016
